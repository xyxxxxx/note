# 随机变量及概率分布

## 一维随机变量

### 随机变量的概念

（这一节描述了随机变量、确定性变量、随机向量、离散型随机变量、连续型随机变量等概念，阐述了随机变量与随机事件的关系。具体内容请参阅原文，此处略去。）

### 离散型随机变量的分布及重要例子

**定义 1.1** 设 $X$ 为离散型随机变量，其全部可能的取值为 ${a_1,a_2,\cdots}$，则

$$
\begin{equation}
\tag{1.1}
p_i=P(X=a_i),i=1,2,\cdots
\end{equation}
$$

称为 $X$ 的**概率函数**。

显然有

$$
\begin{equation}
\tag{1.2}
p_i\ge 0,p_1+p_2+\cdots=1
\end{equation}
$$

其根据加法定理得到，因为事件 $\{X=a_1,或a_2,\cdots\}$ 是必然事件，而又可以表示为一些互斥事件 $\{X=a_1\},\{X=a_2\},\cdots$ 之和。

因此，概率函数 (1.1) 给出了总概率 1 是如何在其可能值之间分配的。有鉴于此，常把 (1.1) 称为随机变量 $X$ 的**概率分布**。它可以以列表的形式给出：

| 可能值 | $a_1$ | $a_2$ | $\cdots$ | $a_i$ | $\cdots$ |
| ------ | ----- | ----- | -------- | ----- | -------- |
| 概率   | $p_1$ | $p_2$ | $\cdots$ | $p_i$ | $\cdots$ |

对于离散型变量，用概率函数去表达其概率分布是最方便的，但也可以用下面定义的分布函数：

**定义 1.2** 设 $X$ 为一随机变量，则函数

$$
\begin{equation}
\tag{1.5}
P(X\le x)=F(x),-\infty<x<\infty
\end{equation}
$$

称为 $X$ 的分布函数。注意这里并未限定 $X$ 是离散型的：它对于任何随机变量都有定义。对于离散型随机变量而言，概率函数与分布函数在下述意义上是等价的，即知道其中一个即可决定另外一个。事实上，若知道概率函数 (1.1)，则

$$
F(x)=P(X\le x)=\sum_{i:a_i\le x}p_i
$$

反过来，由分布函数也容易决定分布表。

对任何随机变量 $X$，其分布函数 $F(x)$ 具有下面的一般性质：

1. $F(x)$ 是单调非降的：当 $(x_1<x_2)$ 时，有 $F(x_1)\le F(x_2)$。
2. 当 $x\to\infty$ 时，$F(x)\to 1$；当 $x\to-\infty$ 时，$F(x)\to 0$。

@二项分布：设某事件 $A$ 在一次试验中发生的概率为 $p$。现将该试验独立地重复 $n$ 次，以 $X$ 记 $A$ 在这 $n$ 次试验中发生的次数。则 $X$ 可取 $0,1,\cdots,n$ 等值。为确定其概率分布，考虑事件 $\{X=i\}$，要使得这个事件发生，必须在这 $n$ 次试验中，有 $i$ 个 $A$ 和 $n-1$ 个 $\overline{A}$。每个 $A$ 有概率 $p$ 而每个 $\overline{A}$ 有概率 $1-p$。又因为这 $n$ 次试验独立，因此乘法定理给出，每个这样的结果发生的概率为 $p^i(1-p)^{n-1}$。又因为 $A$ 可以占据 $n$ 个位置中的任意 $i$ 个，故一共有 $\begin{pmatrix}n\\i\end{pmatrix}$ 种可能。由此得出

$$
\begin{equation}
\tag{1.6}
p_i=b(i;n,p)=\begin{pmatrix}n\\i\end{pmatrix}p^i(1-p)^{n-1},i=0,1,\cdots,n
\end{equation}
$$

$X$ 所服从的概率分布称为**二项分布**，常记作 $B(n,p)$。$X$ 服从二项分布就记为 $X\sim B(n,p)$。

二项分布是最重要的离散型概率分布之一。上面已指出，变量 $X$ 服从这个分布有两个重要条件：一是各次试验的条件是稳定的，这保证了事件 $A$ 的概率 $p$ 在各次试验中保持不变；二是各次试验的独立性。现实生活中有许多现象不同程度地符合这些条件，虽然不一定分毫不差。例如，某工厂每天生产 $n$ 个产品，若原材料质量、机器设备、工人操作水平等在一段时间内大体保持稳定，且每件产品之合格与否与其他产品合格与否并无显著关联，则每日的废品数 $X$ 大体上服从二项分布。又如一大批产品 $N$ 个，其废品率为 $p$，从其中逐一抽取产品检验其是否为废品，共抽 $n$ 个。若每次抽出检验后又放回，且保证每次抽取时每个产品有同等的 $1/N$ 的机会被抽出，则这 $n$ 个产品中所含废品数 $X$ 就相当理想地服从二项分布 $B(n,p)$ 了。反之，若每抽出一个检验之后不放回去，则下一次抽取时废品率就已经发生了变化，这时 $X$ 就不再服从二项分布了（实际上服从超几何分布）。但是，若 $N>>n$，则即使不放回对废品率的影响也极小，这时 $X$ 仍可近似地作为二项分布来处理。

@泊松分布：若随机变量 $X$ 的可能取值为 $0,1,2,\cdots$，且概率分布为

$$
\begin{equation}
\tag{1.7}
P(X=i)=e^{-\lambda}\lambda^i/i!
\end{equation}
$$

则称 $X$ 服从泊松分布，常记作 $X\sim P(\lambda)$。此处 $\lambda>0$ 是某一常数。(1.7) 右侧对 $i=0,1,\cdots$ 求和的结果为 1，可以从熟知的公式 $e^\lambda=\sum_{i=0}^\infty\lambda^i/i!$ 得出。

这个分布也是最重要的离散型分布之一，它多是出现在当 $X$ 表示在一定的时间或空间内出现的事件个数这种场合。在一定时间内某交通路口所发生的事故个数，就是一个典型的例子。该分布产生的机制也可以通过这个例子来解释。为方便起见，设所观察的这段时间为 $[0,1)$，取一个很大的自然数 $n$，将时间段 $[0,1)$ 分为等长的 $n$ 段：

$$
l_1=[0,\frac{1}{n}),l_2=[\frac{1}{n},\frac{2}{n}),\cdots,l_i=[\frac{i-1}{n},\frac{i}{n}),\cdots,l_n=[\frac{n-1}{n},1)
$$

作几个假定：

1. 在每段 $l_i$ 内，恰好发生一个事故的概率，近似地与这段时间的长度 $1/n$ 成正比，即可取 $\lambda/n$。又假定当 $n$ 很大因而 $1/n$ 很小时，在 $l_i$ 这么短暂的一段时间内，要发生两次火更多的事故是不可能的。因此，在 $l_i$ 时段内不发生事故的概率是 $1-1/n$。
2. $l_1,\cdots,l_n$ 各段是否发生事故是独立的。

将在 $[0,1)$ 时段内发生的事故数 $X$ 视作在 $n$ 个小时段 $l_1,\cdots,l_n$ 内有事故的时段数，则按照上述两条假定，$X$ 应服从二项分布 $B(n, \lambda/n)$，于是

$$
\begin{equation}
\tag{1.8}
P(X=i)=\begin{pmatrix}n\\i\end{pmatrix}(\frac{\lambda}{n})^i(1-\frac{\lambda}{n})^(n-i)
\end{equation}
$$

严格地讲，(1.8) 只是近似成立而非严格取等，因为在假定 1 中，在每个时段内发生一次事故的概率只是近似地为 $\lambda/n$。当 $n\to\infty$ 取极限时，就得到确切的答案。注意当 $n\to\infty$ 时

$$
\begin{pmatrix}n\\i\end{pmatrix}/n^i\to 1/i!,(1-\frac{\lambda}{n})^n\to e^{-\lambda}
$$

得知 (1.8) 右侧以 $e^{-\lambda}\lambda^4/i!$ 为极限，由此得出 (1.7)。

从上述推导可以看出：泊松分布可以作为二项分布的极限得到。一般地说，若 $X\sim B(n,p)$，其中 $n$ 很大，$p$ 很小，且 $np=\lambda$ 不太大，则 $X$ 的分布接近于泊松分布 $P(\lambda)$。这个事实在所述条件下可以将较难计算的二项分布转换为泊松分布去计算。

@现在需要 100 个符合规格的元件。从市场上购买的该元件废品率为 0.01，故如只购买 100 个，则它们全都符合规格的机会恐怕不大，为此我们购买 $100+a$ 个。$a$ 的取值需要使得“在这 $100+a$ 个元件中至少有 100 个符合规格”这个事件 $A$ 的概率不小于 0.95。问 $a$ 至少要多大？

在此，我们自然假定各元件是否合格是独立的。以 $X$ 记这 $100+a$ 个元件中所含废品数，则 $X\sim B(100+a,0.01)$。事件 $A$ 即事件 $\{X\le a\}$，于是 $A$ 的概率为

$$
P(A)=\sum_{i=0}^aP(X=i)=\sum_{i=0}^a\begin{pmatrix}100+a\\i\end{pmatrix}0.01^i0.99^{100+a-i}
$$

为确定最小的 $a$ 使得 $P(A)\ge 0.95$，我们需要对 $a=0,1,2,\cdots$ 依次计算 (1.9) 右侧的值，直到算出 $\ge 0.95$ 的结果为止。这很麻烦。

由于 $100+a$ 这个数较大而 0.01 很小，$(100+a)0.01\approx 1$，$X$ 近似地服从泊松分布 $P(1)$，因而

$$
P(X\le a)\approx\sum_{i=0}^ae^{-1}/i!
$$

计算出当 $a=0,1,2,3$ 时，上式右边分别为 0.368、0.736、0.920 和 0.981。故取 $a=3$ 就够了。

除了二项和泊松这两个最重要的离散型分布外，还有几个离散型分布，其重要性略次一些，但也很常用。其中有超几何分布和负二项分布。

@超几何分布：一批产品共 $N$ 个，其中废品有 $M$ 个。现从中随机取出 $n$ 个，以 $X$ 记其中所含废品数，$X$ 的分布为

$$
\begin{equation}
\tag{1.10}
P(X=m)=\begin{pmatrix}M\\m\end{pmatrix}\begin{pmatrix}N-M\\n-m\end{pmatrix}/\begin{pmatrix}N\\n\end{pmatrix}
\end{equation}
$$

至于 $m$ 的取值范围，必须有 $0\le m\le M$ 以及 $n-m\le N-M$。(1.10) 称为**超几何分布**，因为其形式与“超几何函数”的级数展开式的系数有关。

这个分布在涉及抽样的问题中常用，特别当 $N$ 不大时。因为在抽样时，多是像本例这样无放回的，这就与把 $n$ 个同时抽出的效果相同。如果有放回地抽，则结果是二项分布。若 $n/N$ 很小，则有放回和无放回的区别不大，在这种情况下超几何分布应与二项分布很接近。确切地说，若 $X$ 服从超几何分布 (1.10)，则当 $n$ 固定，$M/N=p$ 固定，$N\to\infty$ 时，$X$ 近似地服从二项分布 $B(n,p)$。

@为了检查某工厂产品的废品率 $p$ 大小，有两个试验方案可以采取：一个方案是从产品中抽出若干个，检查其中的废品数 $X$，这一方案导致二项分布，已于前述。另一个方案是先指定一个自然数 $r$，然后一个一个地从产品中抽样检查，直到发现第 $r$ 个废品为止。以 $X$ 记到当时为止已检出的合格品个数。

为计算 $X$ 的分布，假定各次抽取的结果（是废品与否）是独立的，并且每次抽得废品的概率固定为 $p$。考察 $\{X=i\}$ 这个事件，为使这个事件发生，需要以下两个事件同时发生：①在前 $i+r-1$ 次抽取中，恰好有 $r-1$ 个废品；②第 $i+r$ 次抽出废品。按照所作假定，这两个事件的概率分别为 $b(r-1;i+r-1,p)$ 和 $p$，再由独立性，即得

$$
\begin{equation}
\tag{1.11}
P(X=i)=b(r-1;i+r-1,p)p=\begin{pmatrix}i+r-1\\r-1\end{pmatrix}p^r(1-p)^i,i=0,1,2,\cdots
\end{equation}
$$

这个分布称为**负二项分布**。这名称的来由，一是因为“负指数二项展开式”

$$
(1-x)^{-r}=\sum_{i=0}^\infty\begin{pmatrix}-r\\i\end{pmatrix}(-x)^i=\sum_{i=0}^\infty\begin{pmatrix}i+r-i\\i\end{pmatrix}x^i=\sum_{i=0}^\infty\begin{pmatrix}i+r-i\\r-1\end{pmatrix}x^i
$$

!!! note "说明"
    上式由二项式的麦克劳林级数得到，对 $\forall x:|x|<1,\forall \alpha\in\mathbb{C}$ 成立。参见[二项式级数](https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0#%E4%BA%8C%E9%A1%B9%E5%BC%8F%E7%BA%A7%E6%95%B0)。

令 $x=1-p$ 并两侧同乘 $p^r$，得到

$$
1=p^r(1-(1-p))^{-r}=\sum_{i=0}^\infty\begin{pmatrix}i+r-1\\r-1\end{pmatrix}p^r(1-p)^i
$$

这验证了负二项分布 (1.11) 满足 (1.2)。

二是因为例中所描述的试验方式，与二项分布相比是“反其道而行之”：二项分布是定下总抽样个数 $n$ 而将废品个数 $X$ 作为变量；负二项分布则是定下废品个数 $r$ 而将总抽样次数减去 $r$ 作为变量。

一个重要的特例是 $r=1$，这时 (1.11) 成为

$$
\begin{equation}
\tag{1.12}
P(X=i)=p(1-p)^i,i=0,1,2,\cdots
\end{equation}
$$

概率 $p,p(1-p),p(1-p)^2,\cdots$ 呈公比为 $1-p$ 的几何级数，故分布 (1.12) 常称为**几何分布**。

### 连续型随机变量的分布及重要例子

设连续型随机变量 $X$ 有概率分布函数 $F(x)$，则 $F(x)$ 的导数 $f(x)=F'(x)$ 称为 $X$ 的**概率密度函数**。

**密度函数**这个名词的来由可以解释如下。给定一个点 $x$，则按照分布函数的定义，事件 $\{x<X\le x+h\}$ （$h>0$）的概率应为 $F(x+h)-F(x)$。所以，比值 $(F(x+h)-F(x))/h$ 可以解释为在 $x$ 点附近长为 $h$ 的区间 $(x,x+h)$ 内，单位长度所占有的概率。令 $h\to 0$，则这个比值的极限，即 $F'(x)=f(x)$，也就是在 $x$ 点位置单位长度的概率。

连续型随机变量 $X$ 的密度函数 $f(x)$ 具有以下三条基本性质：

1. $f(x)\ge 0$
2. $\int_{-\infty}^\infty f(x){\rm d}x=1$
3. 对任意常数 $a<b$，有

    $$
    \begin{equation}
    \tag{1.13}
    P(a\le X\le b)=F(b)-F(a)=\int_a^bf(x){\rm d}x
    \end{equation}
    $$

1. 显然；2. 表示“全部概率为 1”；3. 时微积分的基本定理的直接应用。实际上，2. 是 3. 在 $a=-\infty$ 和 $b=\infty$ 的特例。

@正态分布（高斯分布）：如果一个随机变量具有概率密度函数

$$
\begin{equation}
\tag{1.14}
f(x)=(\sqrt{2\pi}\sigma)^{-1}e^{-(x-\mu)^2/2\sigma^2},-\infty<x<\infty
\end{equation}
$$

则称 $X$ 服从正态分布并记为 $X\sim N(\mu,\sigma^2)$。这里 $N$ 为“Normal”一词的首字母。$\mu$ 和 $\sigma^2$ 都是常数，$\mu$ 可以取任何实数值而 $0<\sigma^2<\infty$。它们称为这个分布的“参数”。

需要证明 $f(x)$ 的确可以作为一个概率密度。为此须验证 $f(x)\ge 0,\int_{-\infty}^\infty f(x){\rm d}x=1$。前者显然；为证明后者，作变量代换 $t=(x-\mu)/\sigma$，转化为证明

$$
\begin{equation}
\tag{1.15}
I=\int_{-\infty}^\infty e^{-t^2/2}{\rm d}t=\sqrt{2\pi}
\end{equation}
$$

为证明此式，考虑

$$
I^2=\int_{-\infty}^\infty e^{-t^2/2}{\rm d}t\int_{-\infty}^\infty e^{-u^2/2}{\rm d}u=\iint_{-\infty}^\infty=e^{-(t^2+u^2)/2}{\rm d}t{\rm d}u
$$

转化为极坐标 $t=r\cos\theta,u=r\sin\theta$，上式转化为

$$
I^2=\int_0^2\pi{\rm d}\theta\int_{-\infty}^\infty e^{-r^2/2}r{\rm d}r=2\pi
$$

得证。

函数 (1.14) 的图形关于点 $\mu$ 对称，而后往两个方向衰减，属于“两头低，中间高”这种正常情况下一般事物所处的状态。例如一群人的身高或体重，特大和特小的较少而中间状态的居多。举凡人的收入，大批制造的同一产品的某一指标等，都在不同程度上符合这一分布。这不但说明了“正态”这一名称的来由，也说明了这种分布的重要性。

当 $\mu=1,\sigma^2=1$ 时，(1.14) 成为

$$
f(x)=e^{-x^2/2}/\sqrt{2\pi}
$$

它是正态分布 $N(0,1)$ 的密度函数。$N(0,1)$ 称为**标准正态分布**。在概率论著作中，其密度函数和分布函数常分别记作 $\varphi(x)$ 和 $\Phi(x)$，并附有很详细的表。本书也附有一个简单的 $\Phi(x)$ 的表。标准正态分布之所以重要，一个原因在于：任意的正态分布 $N(\mu,\sigma^2)$ 的计算很容易转化为标准正态分布 $N(0,1)$。容易证明：

$$
\begin{equation}
\tag{1.17}
若 X\sim N(\mu,\sigma^2)，则 Y=(X-\mu)/\sigma\sim N(0,1)
\end{equation}
$$

事实上：

$$
\begin{align}
P(Y\le x)&=P((X-\mu)/\sigma\le x)=P(X\le \mu+\sigma x)\\
&=(\sqrt{2\pi}\sigma)^{-1}\int_{-\infty}^{\mu+\sigma x}e^{-(t-\mu)^2/2\sigma^2}{\rm d}t\\
&=(\sqrt{2\pi})^{-1}\int_{-\infty}^xe^{-u^2/2}{\rm d}u\\
\end{align}
$$

其导数，即 $Y$ 的密度函数，正是 $(\sqrt{2\pi})^{-1}e^{-x^2/2}$，这证明了 (1.17)。

例如，$X\sim N(1.5,2^2)$，要计算 $P(-1\le X\le 2)$，则因为 $(X-1.5)/2\sim N(0,1)$，故

$$
\begin{align}
P(-1\le X\le 2)&=P(\frac{-1-1.5}{2}\le \frac{X-1.5}{2}\le \frac{2-1.5}{2})\\
&=P(-1.25\le \frac{X-1.5}{2}\le 0.25)\\
&=\Phi(0.25)-\Phi(-1.25)
\end{align}
$$

然后查标准正态分布 $\Phi$ 的表，表上只有 $\Phi(x)$ 当 $x\ge 0$ 的值。对 $x<0$，可利用公式

$$
\begin{equation}
\tag{1.19}
\Phi(x)=1-\Phi(-x)
\end{equation}
$$

而转化为 $x>0$ 的情况。(1.19) 的证明很简单：

$$
\begin{align}
\Phi(x)&=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^xe^{-t^2/2}{\rm d}t=\frac{1}{\sqrt{2\pi}}\int_{-x}^\infty e^{-t^2/2}{\rm d}t\\
&=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{-t^2/2}{\rm d}t-\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{-x}e^{-t^2/2}{\rm d}t\\
&=1-\Phi(-x)
\end{align}
$$

因此

$$
P(-1\le X\le 2)=\Phi(0.25)+\Phi(1.25)-1
$$

查表得到 $\Phi(0.25)=0.5987,\Phi(1.25)=0.8944$，于是得到 $P(-1\le X\le 2)=0.4931$。

@指数分布：若随机变量 $X$ 有概率密度函数

$$
f(x)=\begin{cases}\lambda e^{-\lambda x},& x>0\\
0,& x\le 0
\end{cases}
$$

则称 $X$ 服从指数分布。其中 $\lambda>0$ 为参数，其意义将在后面阐明。

由于 $f(x)=0,x\le 0$，表示随机变量取负值的概率为 0：$X$ 只取正值。$f(x)$ 在 $x=0_+$ 处之值 $\lambda>0$，故密度函数 $f(x)$ 在 $x=0$ 处不连续。

变量 $X$ 的分布函数易求得为

$$
\begin{equation}
\tag{1.21}
F(x)=\int_{-\infty}^xf(t){\rm d}t=\begin{cases}
0,& x\le 0\\
1-e^{-\lambda x},& x>0
\end{cases}
\end{equation}
$$

指数分布最常见的一个场合是寿命分布。设想一种大批生产的电子元件，其寿命 $X$ 是随机变量。以 $F(x)$ 记 $X$ 的分布函数。我们来证明，在一定的条件下，$F(x)$ 就是 (1.21)。

我们要作的假定，从技术上说就是“无老化”，也就是说：元件在时刻 $x$ 尚能正常工作的情况下，其失效率总保持为某个常数 $\lambda>0$，与 $x$ 无关。失效率就是单位长度时间内失效的概率。用条件概率的形式，上述假定可以表示为

$$
P(x\le X\le x+h|X>x)/h=\lambda,h\to 0
$$

该式解释如下：元件在时刻 $x$ 尚正常工作，表示其寿命大于 $x$，即 $X>x$。在 $x$ 时刻，长为 $h$ 的时间段内失效，即 $x\le X\le x+h$。将这个条件概率除以时间段的长度 $h$，即得在 $x$ 时刻的平均失效率。再令 $h\to 0$，得到瞬时失效率，按照假定，它应为常数 $\lambda$。

按照条件概率定义，注意到 $P(X>x)=1-F(x)$，有

$$
\displaylines{
P(x\le X\le x+h|X>x)/h=P(x<X\le x+h)/(1-F(x))/h=(F(x+h)-F(x))/h/(1-F(x))\\
\Rightarrow F'(x)/(1-F(x))=\lambda
}
$$

这个微分方程的通解为 $F(x)=1-Ce^{-\lambda x},x>0$（当 $x\le 0$ 时 $F(x)=0$）。常数 $C$ 可用初始条件 $F(0)=0$ 定出为 1，这样就得到 (1.21)。

从这个推导也可以窥见参数 $\lambda$ 的意义。$\lambda$ 为失效率，失效率越高，平均寿命就越小。

由本例可见，指数分布描述了无老化时的寿命分布，但“无老化”是不可能的，因而只是一种近似。对于一些寿命长的元件，在初期阶段老化现象很小，在这一阶段指数分布比较确切地描述了其寿命分布情况。

@威布尔分布：若考虑老化，则应取失效率随时间上升，不应为常数，而应取为一个 $x$ 的增函数，例如 $\lambda x^m$，对于常数 $\lambda>0,m>0$。在这个条件下，按照上例的推理，将得出：寿命分布 $F(x)$ 满足微分方程 $F'(x)/(1-F(x))=\lambda x^m$，此与初始条件 $F(0)=0$ 结合，得出

$$
F(x)=1-e^{-(\lambda/m+1)x^{m+1}}
$$

取 $a=m+1(a>1)$，并把 $\lambda/(m+1)$ 记为 $\lambda$，得到

$$
\begin{equation}
\tag{1.22}
F(x)=1-e^{-\lambda}x^{a},x>0
\end{equation}
$$

此分布之密度函数为

$$
\begin{equation}
\tag{1.23}
f(x)=\begin{cases}
\lambda ax^{a-1}e^{-\lambda x^a},& x>0\\
0,& x\le 0
\end{cases}
\end{equation}
$$

(1.22) 和 (1.23) 分别称为威布尔分布函数和威布尔密度函数。它和指数分布一样，在可靠性统计分析中占据重要的地位。实际上指数分布是威布尔分布在 $a=1$ 时的特例。

@均匀分布：设随机变量 $X$ 有概率密度函数

$$
f(x)=\begin{cases}
1/(b-a),& a\le x\le b\\
0,& 其他x
\end{cases}
$$

则称 $X$ 服从区间 $[a,b]$ 上的均匀分布，并常记作 $X\sim R(a,b)$。这里 $a,b$ 都是常数，$-\infty<a<b<\infty$。均匀分布这个名称的来由很明显：因为密度函数 $f$ 在区间 $[a,b]$ 上为常数，故在此区间上，概率在各处的密集程度相同。或者说，概率均匀地分布在此区间上。均匀分布 $R(a,b)$ 的分布函数是

$$
F(x)=\begin{cases}
0,& x\le a\\
(x-a)/(b-a),& a<x<b\\
1,& x\ge b
\end{cases}
$$

在计算时因四舍五入而产生的误差，若以被舍入的那一位的前一位为单位大小，则可认为这个舍入误差服从均匀分布 $R(-1/2,1/2)$。均匀分布的一个好处是，借助它容易实现对分布的模拟。首先，若以某种方法产生“随机数”（即 $0,1,\cdots,9$ 这是个数字出现的概率都是 1/10 的那种数字，它可以用“摸球”等方式来实现。实用上用计算机程序可在短时间内产生大量随机数——严格地说，计算机产生的随机数并非完全随机，但很接近，故有时称为伪随机数），则如取 $n$ 足够大，而独立地产生 $n$ 个随机数字 $a_1,\cdots,a_n$ 时，$X=0\cdot a_1a_2\cdots a_n$ 就很接近于 [0,1] 均匀分布 $R(0,1)$。对于一般的分布函数 $F(x)$，若 $F(x)$ 处处连续且严格上升，则其反函数 $G$ 存在，这时有，若 $X\sim R(0,1)$，则 $G(X)\sim F$。事实上，$\{G(X)\le x\}$ 这个事件，就是 $\{F(G(X))\le F(x)\}$ 即 $\{X\le F(x)\}$，因而（注意到 $R(0,1)$ 的分布函数为 $F(x)=x,0<x<1$）

$$
P(G(X)\le x)=P(X\le F(x))=F(x)
$$

这证明了 $G(X)\sim F$。这样，用上述模拟方法产生 $X$ 的模拟值后，代入 $G$ 中即得到分布 $F$ 的模拟值。这个方法在模拟研究中常用，从而显示了均匀分布的重要性。

还有几个在统计应用上很重要的连续型分布，留待[后面](#随机变量的函数的概率分布)讨论。

## 多维随机变量（随机向量）

### 离散型随机向量的分布

一个随机向量 $X=(X_1,\cdots,X_n)$，如果其每一个分量 $X_i$ 都是一维离散型随机变量，则称 $X$ 是离散型的。

**定义 2.1** 以 $\{a_{i1},a_{i2},\cdots\}$ 记 $X_i$ 的全部可能值，$i=1,2,\cdots$，则事件 $\{X_1=a_{1j_1},X_2=a_{2j_2},\cdots,X_n=a_{nj_n}\}$ 的概率

$$
\begin{equation}
\tag{2.1}
p(j_1,j_2,\cdots,j_n)=P(X_1=a_{1j_1},X_2=a_{2j_2},\cdots,X_n=a_{nj_n}),j_k=1,2,\cdots,k=1,2,\cdots,n
\end{equation}
$$

称为随机向量 $X=(X_1,\cdots,X_n)$ 的概率函数或概率分布，概率函数应满足条件

$$
\begin{equation}
\tag{2.2}
p(j_1,j_2,\cdots,j_n)\ge 0,\sum_{j_n}\cdots\sum_{j_2}\sum_{j_1}p(j_1,j_2,\cdots,j_n)=1
\end{equation}
$$

@下图所示的二维离散型随机向量 $X=(X_1,X_2)$ 的概率分布为

$$
\displaylines{
P(X_1=2,X_2=1)=1/3\\
P(X_1=2,X_2=2.5)=1/4\\
P(X_1=5,X_2=3)=5/12
}
$$

![](https://s2.loli.net/2023/01/10/oV5gtPhS4mQEUzs.png)

从图上看出，$X_1$ 的可能取值为 2 和 5，$X_2$ 的可能取值为 1、2.5 和 3，故从形式上看，$X=(X_1,X_2)$ 应有 6 组可能取值。但 $X$ 的概率分布告诉我们，实际上只有 3 组是真正的可能值，但这并没有关系：对于一组不可能的值，只要把它的概率定为 0 就可以了。这一做法使我们可以把离散型分布统一写成 (2.1) 的格式，在理论上有其方便之处。自然，在具体例子中，如本例并无必要硬凑成这种形式，只需要指出概率大于 0 的那部分就可以了。

@多项分布：设 $A_1,A_2,\cdots,A_n$ 是某一试验之下的完备事件群，分别以 $p_1,p_2,\cdots,p_n$ 记事件 $A_1,A_2,\cdots,A_n$ 的概率。现在将试验独立地重复 $N$ 次，而以 $X_i$ 记在这 $N$ 次试验中事件 $A_i$ 出现的次数，$i=1,\cdots,n$，则 $X=(X_1,\cdots,X_n)$ 是一个 $n$ 维随机向量，它的取值范围是：$X_1,\cdots,X_n$ 都是非负整数且和为 $N$。$X$ 的概率分布就叫做多项分布，有时记为 $M(N;p_1,\cdots,p_n)$。为定出这个分布，要计算事件

$$
B=\{X_1=k_1,X_2=k_2,\cdots,X_n=k_n\}
$$

的概率，只需考虑 $k_i$ 都是非负整数且 $k_1+\cdots+k_n=N$ 的情况，否则 $P(B)=0$。从 $N$ 次试验的原始结果 $j_1j_2\cdots j_N$ 出发，它表示第一次试验事件 $A_{j_1}$ 发生，第二次试验事件 $A_{j_2}$ 发生，依此类推。为使事件 $B$ 发生，在 $j_1,j_2,\cdots,j_N$ 中应有 $k_1$ 个 1，$k_2$ 个 2，依此类推。这种序列的数目，等于把 $N$ 个相异物品分成 $n$ 堆，各堆依次有 $k_1,k_2,\cdots,k_n$ 件的不同分法，应有 $N!/(k_1!\cdots k_n!)$ 种。其次，由于独立性，利用乘法定理知，每个适合上述条件的原始结果序列 $j_1j_2\cdots j_n$ 出现的概率，应为 $p_1^{k_1}p_2^{k_2}\cdots p_n^{k_n}$，于是得到

$$
\begin{equation}
\tag{2.3}
P(X_1=k_1,X_2=k_2,\cdots,X_n=k_n)=\frac{N!}{k_1!k_2!\cdots k_n!}p_1^{k_1}p_2^{k_2}\cdots p_n^{k_n}
\end{equation}
$$

(2.3) 就是多项分布，名称的来由是因多项展开式

$$
\begin{equation}
\tag{2.4}
(x_1+x_2+\cdots+x_n)^N=\sum^*\frac{N!}{k_1!k_2!\cdots k_n!}x_1^{k_1}x_2^{k_2}\cdots x_n^{k_n}
\end{equation}
$$

$\sum^*$ 表示求和的范围是：$k_i$ 为非负整数，$k_1+\cdots+k_n=N$。在 (2.4) 中令 $x_i=p_i$，并利用 $p_1+\cdots+p_n=1$，得

$$
\sum^*\frac{N!}{k_1!k_2!\cdots k_n!}p_1^{k_1}p_2^{k_2}\cdots p_n^{k_n}=1
$$

这说明分布 (2.3) 符合条件 (2.2)。

多项分布是最重要的离散型多维分布，其在实用上颇为常见：当一个物品按照某种属性分成几类时，就会涉及到这个分布。例如，一种产品分成一等品（$A_1$）、二等品（$A_2$）、三等品（$A_3$）和不合格品（$A_4$）四类。若生产该产品的某工厂，其一、二、三等品和不合格品的比率分别为 0.15、0.70、0.10 和 0.05，从该工厂产品中抽出 $N$ 个。若这 $N$ 个只占产品的极少一部分，则可以把这 $N$ 个看成一个一个独立地抽出，且在抽取过程中各等品的概率不变。在这种情况下，若分别以 $X_1,\cdots,X_4$ 记这 $N$ 个产品中一、二、三等和不合格品的个数，则 $X=(X_1,\cdots,X_4)$ 将服从多项分布 $M(N;0.15,0.70,0.10,0.05)$。又如在医学上，一种疾病的患者可按严重程度分期等等，都属于这种情况。

如果 $n=2$，即只有 $A_1,A_2$ 两种可能，这时 $A_2$ 就是 $A_1$ 的对立事件。由于这时有 $X_1+X_2=N$，$X_1$ 唯一决定了 $X_2$（即随机向量 $X$ 只有一个自由度），我们只需要考虑 $X_1$，从而回到二项分布的情形。

### 连续型随机向量的分布

设 $X=(X_1,\cdots,X_n)$ 是一个 $n$ 维随机向量，其取值可视为 $n$ 维欧氏空间 $\mathbb{R}^n$ 中的一个点。如果 $X$ 的全部取值能充满 $\mathbb{R}^n$ 中的某一区域，则称它是连续型的。

与一维连续型变量一样，描述多维随机变量的概率分布，最方便的是实用概率密度函数。为此我们引入一个记号：$X\in A$，其中 $A$ 是 $\mathbb{R}^n$ 中的集合。$\{X\in A\}$ 是一个随机事件，因为做了试验之后，$X$ 的值就知道了，因而也就知道它是否落在 $A$ 内。

**定义 2.2** 若 $f(x_1,\cdots,x_n)$ 是定义在 $\mathbb{R}^n$ 上的非负函数，使对 $\mathbb{R}^n$ 中的任何集合 $A$，有

$$
\begin{equation}
\tag{2.5}
P(X\in A)=\int_A\cdots\int f(x_1,\cdots,x_n){\rm d}x_1\cdots{\rm d}x_n
\end{equation}
$$

则称 $f$ 是 $X 的概率密度函数。

如果把 $A$ 取为全空间 $\mathbb{R}^n$，则 $\{X\in A\}$ 为必然事件，其概率为 1，因此应有

$$
\begin{equation}
\tag{2.6}
\int_{-\infty}^\infty\cdots\int f(x_1,\cdots,x_n){\rm d}x_1\cdots{\rm d}x_n=1
\end{equation}
$$

这是一个概率密度函数必须满足的条件。

@考虑二维随机向量 $X=(X_1,X_2)$，其概率密度函数为

$$
f(x_1,x_2)=\begin{cases}
1/((b-a)(d-c)),& a\le x_1\le b,c\le x_2\le d\\
0,& 其他情况
\end{cases}
$$

则 $f$ 非负且条件 (2.6) 满足。从 $f$ 的形状看出，它下图中那个矩形之外为 0，说明 $(X_1,X_2)$ 只能取该矩形内的点的值。在这个矩形内，密度各处相同，因而全部概率均匀地分布在该矩形内。从公式 (2.5) 看出：若集合 $A$ 在矩形内，则“$X$ 落在 $A$ 内”的概率 $P(X\in A)$，与 $A$ 的面积成正比而与其位置和形状无关，这是均匀性的另一种说法。因为这样的缘故，本例中 $X$ 的分布被称为该矩形上的均匀分布。

![](https://s2.loli.net/2023/01/11/x56O2A9YuiNaQTV.png)

@向一个无限平面靶射击，设命中点 $X=(X_1,X_2)$ 有概率密度

$$
f(x_1,x_2)=\pi^{-1}(1+x_1^2+x_2^2)^{-2}
$$

从这个函数看出：命中点的密度只与该点到靶心的距离 $r$ 有关，越接近靶心，越有机会命中。

为验证 (2.6) 只需转换到极坐标，得

$$
\iint_{-\infty}^\infty f(x_1,x_2){\rm d}x_1{\rm d}x_2=\int_0^{2\pi}{\rm d}\theta\int_0^\infty\pi^{-1}(1+r^2)^{-2}r{\rm d}r=2\pi\cdot\pi^{-1}\int_0^\infty(1+t)^{-2}{\rm d}t/2=1
$$

而“命中点与靶心的距离不超过 $r_0$”这个事件 $A$ 的概率为

$$
\iint_{x_1^2+x_2^2\le r_0^2}f(x_1,x_2){\rm d}x_1{\rm d}x_2=\int_0^{2\pi}{\rm d}\theta\int_0^{r_0}\pi^{-1}(1+r^2)^{-2}r{\rm d}r=r_0^2/(1+r_0^2)
$$

@二维正态分布：最重要的多维连续型分布是多维正态分布。对二维的情况，其概率密度函数有形式

$$
\begin{equation}
\tag{2.7}
f(x_1,x_2)=\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp(-\frac{1}{2(1-\rho^2)}(\frac{(x_1-a)^2}{\sigma_1^2}-\frac{2\rho(x_1-a)(x_2-b)}{\sigma_1\sigma_2}+\frac{(x_2-b)^2}{\sigma_2^2}))
\end{equation}
$$

$f$ 中包含了 5 个常数：$a$、$b$、$\sigma_1^2$、$\sigma_2^2$ 和 $\rho$，它们是这个分布的参数，取值范围为

$$
-\infty<a<\infty,-\infty<b<\infty,\sigma_1>0,\sigma_2>0,-1<\rho<1
$$

常把这个分布记作 $N(a,b,\sigma_1^2,\sigma_2^2,\rho)$。这个函数在三维空间中的图形，好像一个椭圆切面的

为了证明 (2.7) 确实是一个密度函数，还需要证明 (2.6) 成立。为此，作变数代换

$$
u=(1-\rho^2)^{-1/2}\frac{x_1-a}{\sigma_1},v=(1-\rho^2)^{-1/2}\frac{x_2-b}{\sigma_2}
$$

得

$$
\iint_{-\infty}^\infty f(x_1,x_2){\rm d}x_1{\rm d}x_2=\frac{1}{2\pi}\sqrt{1-\rho^2}\iint_{-\infty}^\infty\exp(-\frac{1}{2}(u^2-2\rho uv+v^2)){\rm d}u{\rm d}v
$$

再作变数代换 $t_1=u-\rho v,t_2=\sqrt{1-\rho^2}v$。注意到 $t_1^2+t_2^2=(u-\rho v)^2+(1-\rho^2)v^2=u^2-2\rho uv+v^2$，且变换的 Jacobi 行列式为

$$
\begin{vmatrix}\partial t_1/\partial u& \partial t_1/\partial v\\
\partial t_2/\partial u& \partial t_2/\partial v\end{vmatrix}
=\begin{vmatrix}1& -\rho\\
0& \sqrt{1-\rho^2}\end{vmatrix}
=\sqrt{1-\rho^2}
$$

得到

$$
\begin{align}
\iint_{-\infty}^\infty f(x_1,x_2){\rm d}x_1{\rm d}x_2&=\frac{1}{2\pi}\sqrt{1-\rho^2}(\sqrt{1-\rho^2})^{-1}\iint_{-\infty}^\infty\exp(-\frac{1}{2}(t_1^2+t_2^2)){\rm d}t_1{\rm d}t_2\\
&=\frac{1}{2\pi}\int_{-\infty}^\infty e^{-t_1^2/2}{\rm d}t_1\int_{-\infty}^\infty e^{-t_2^2/2}{\rm d}t_2\\
&=\frac{1}{2\pi}\sqrt{2\pi}\sqrt{2\pi}=1
\end{align}
$$

这里用到 (1.15)。

类似地可以定义 $n$ 维正态分布的概率密度函数，这里不再展开。

最后在这里指出几点重要事项：

1. 不论一维或多维，在定义连续型随机变量时，实质的点在于它有概率密度函数存在，即存在函数 $f$，满足 (1.13) 或 (2.5)。在概率论理论上，把这一点作为连续型随机变量的定义：连续型随机变量就是有密度函数的随机变量。至于它可以在一个区间或区域内“连续“取值倒不是本质的，甚至也不是确切的。
2. 与离散型随机向量的定义不同，连续型随机向量不能简单地定义为“其各个分量都是一维连续型随机变量的随机向量”。举一个例子：设 $X_1\sim R(0,1),X_2=X_1$，则随机向量 $(X_1,X_2)$ 的两个分量 $X_1,X_2$ 都是连续型的，但 $(X_1,X_2)$ 却只能在下图所示的单位正方形的对角线上取值。因而不可能存在一个函数 $f(x_1,x_2)$ 满足 (2.6)（二元函数在平面上任一线段上的积分都是 0），即 $(X_1,X_2)$ 的概率密度函数不存在。

    ![](https://s2.loli.net/2023/01/16/J6QqbrCMNitDvk3.png)

3. 和一维情况一样，也可以用概率分布函数去描述多维随机向量的概率分布，其定义为

    $$
    F(x_1,x_2,\cdots,x_n)=P(X_1\le x_1,X_2\le x_2,\cdots,X_n\le x_n)
    $$

    然而在多维情况下，分布函数极少应用。

### 边缘分布

设 $X=(X_1,\cdots,X_n)$ 是 $n$ 维随机向量。$X$ 有一定的分布 $F$，这是一个 $n$ 维分布。同时 $X$ 的每个分量 $X_i$ 都是一维随机变量，因此它们都有各自的分布 $F_i,i=1,\cdots,n$，这些都是一维分布，称为随机向量 $X$ 或其分布 $F$ 的**边缘分布**。

@下表展示了一个二维随机向量 $X=(X_1,X_2)$ 的概率分布：

![](https://s2.loli.net/2023/01/16/cfSpUngAPh89Fqj.png)

现在如果想要求 $X_1$ 的分布，则先注意到，$X_1$ 只有两个可能值，即 1 和 3，而 $\{X_1=1\}$ 这个事件可以分解为三个互斥事件

$$
\{X_1=1,X_2=-1\},\{X_1=1,X_2=0\},\{X_1=1,X_2=5\}
$$

之和，故其概率应为上述三个事件概率之和，即

$$
P(X_1=1)=0.17+0.05+0.21=0.43
$$

类似地有 $P(X_1=3)=0.04+0.28+0.25=0.57$。用同样的方法确定 $X_2$ 的概率分布为

$$
P(X_2=-1)=0.21,P(X_2=0)=0.33,P(X_2=5)=0.46
$$

注意这两个分布正好是表的中央部分的行和与列和。它们都处在表的边缘位置上，由此得到边缘分布这个名词，也称为边际分布。

从这个例子不难悟出，在一般的离散型情况下，如何去求边缘分布。回到 (2.1) 的记号，以 $X_1$ 为例，它的全部可能值为 $a_{11},a_{12},a_{13},\cdots$。例如我们要求 $P(X_1=a_{1k})$，它等于把 (2.1) 那样的概率全部加起来，但限定 $j_1=k$，得

$$
\begin{equation}
\tag{2.8}
P(X_1=a_{1k})=\sum_{j_2,\cdots,j_n}p(k,j_2,\cdots,j_n),k=1,2,\cdots
\end{equation}
$$

@设 $X=(X_1,\cdots,X_n)$ 服从多项分布 $M(N;p_1,\cdots,p_n)$，要求其边缘分布。例如，考虑分量 $X_1$，我们把事件 $A_1$ 作为一方，事件 $A_2+\cdots+A_n$ 作为另一方（也就是 $\overline{A}_1$），那么 $X_1$ 就是在 $N$ 次独立试验中事件 $A_1$ 发生的次数，而在每次试验中 $A_1$ 发生的概率都是 $p_1$。经过这一分析，无需计算就可以知道：$X_1$ 的分布就是二项分布 $B(N,p_1)$。应用 (2.8) 也可以得到这个结果：按照 (2.8)，注意到多项分布的形式 (2.3)，有

$$
P(X_1=k)=\sum_{k_2,\cdots,k_n}'\frac{N!}{k_2!\cdots k_n!}p_2^{k_2}\cdots p_n^{k_n}\cdot\frac{p_1^k}{k!}
$$

这里，$\sum_{k_2,\cdots,k_n}'$ 表示求和的范围为：$k_2,\cdots,k_n$ 都是非负整数，它们的和为 $N-k$，令

$$
p_2'=p_2/(1-p_1),\cdots,p_n'=p_n/(1-p_1)
$$

则 $p_2'+\cdots+p_n'=1$，可把上式改写为

$$
P(X_1=k)=\sum_{k_2,\cdots,k_n}'\frac{(N-k)!}{k_2!\cdots k_n!}p_2'^{k_2}\cdots p_n'^{k_n}\cdot\frac{N!}{k!(N-k)!}p_1^k(1-p_1)^{N-k}
$$

根据多项展开式 (2.4)，上式右侧的第一个因子为

$$
(p_2'+\cdots+p_n')^{N-k}=1^{N-k}=1
$$

于是得到

$$
P(X_1=k)=\frac{N!}{k!(N-k)!}p_1^k(1-p_1)^{N-k}=b(k;N,p_1),k=0,1,\cdots,N
$$

正是二项分布 $B(N,p_1)$。

现在考虑连续型随机向量的边缘分布。为便于书写，先考虑二维的情况，设 $X=(X_1,X_2)$ 有概率密度函数 $f(x_1,x_2)$。我们来证明，$X_1$ 和 $X_2$ 都具有概率密度函数。

考虑 $X_1$ 的分布函数 $F_1(x_1)=P(X_1\le x_1)$，它可以写为 $P(X_1\le x_1,X_2<\infty)$，注意到 (2.5)，有

$$
F_1(x_1)=P(X_1\le x_1)=\int_{-\infty}^{x_1}{\rm d}t_1\int_{-\infty}^\infty f(t_1,t_2){\rm d}t_2
$$

$\int_{-\infty}^\infty f(t_1,t_2){\rm d}t_2$ 是 $t_1$ 的函数，将其记作 $f_1(t_1)$，于是上式可写为

$$
F_1(x_1)=\int_{-\infty}^{x_1}f_1(t_1){\rm d}t_1
$$

两边对 $x_1$ 求导数，得到 $X_1$ 的概率密度函数为

$$
\begin{equation}
\tag{2.9}
\frac{{\rm d}F_1(x_1)}{{\rm d}x_1}=f_1(x_1)=\int_{-\infty}^\infty f(x_1,x_2){\rm d}x_2
\end{equation}
$$

这不仅证明了 $X_1$ 的密度函数的存在，而且还推出了其公式。同理求出 $X_2$ 的密度函数为

$$
\begin{equation}
\tag{2.10}
f_2(x_2)=\int_{-\infty}^\infty f(x_1,x_2){\rm d}x_1
\end{equation}
$$

这个结果很容易推广到 $n$ 维的情形：设 $X=(X_1,\cdots,X_n)$ 有概率密度函数 $f(x_1,\cdots,x_n)$。为求某分量 $X_i$ 的概率密度函数，只需把 $f(x_1,\cdots,x_n)$ 中的 $x_i$ 固定，然后对 $x_1,\cdots,x_{i-1},x_{i+1},\cdots,x_n$ 在 $-\infty$ 到 $\infty$ 之间作定积分。例如，$X_1$ 的密度函数为

$$
f_1(x_1)=\int_{-\infty}^\infty\cdots\int_{-\infty}^\infty f(x_1,x_2,\cdots,x_n){\rm d}x_2\cdots{\rm d}x_n
$$

@再次考虑二维随机向量 $X=(X_1,X_2)$，其概率密度函数为

$$
f(x_1,x_2)=\begin{cases}
1/((b-a)(d-c)),& a\le x_1\le b,c\le x_2\le d\\
0,& 其他情况
\end{cases}
$$

由 (2.9) 和 (2.10) 容易确定，$X_1,X_2$ 的边缘分布分别是均匀分布 $R(a,b)$ 和 $R(c,d)$。

@再次考虑二维随机向量 $X=(X_1,X_2)$，其概率密度函数为

$$
f(x_1,x_2)=\pi^{-1}(1+x_1^2+x_2^2)^{-2}
$$

按照 (2.9)，$X_1$ 的边缘密度函数为

$$
f_1(x_1)=\pi^{-1}\int_{-\infty}^\infty(1+x_1^2+x_2^2)^{-2}{\rm d}x_2
$$

作变数代换 $t=x_2/\sqrt{1+x_1^2}$，得

$$
f_1(x_1)=\pi^{-1}(1+x_1^2)^{-3/2}\int_{-\infty}^\infty(1+t^2)^{-2}{\rm d}t=\frac{1}{2}(1+x_1^2)^{-3/2}
$$

@若 $(X_1,X_2)$ 服从二维正态分布 $N(a,b,\sigma_1^2,\sigma_2^2,\rho)$，证明 $X_1,X_2$ 的边缘分布分别是一维正态分布 $N(a,\sigma_1^2)$ 和 $N(b,\sigma_2^2)$。

为计算 $\int_{-\infty}^\infty f(x_1,x_2){\rm d}x_2$，其中 $f$ 由 (2.7) 定义，注意到

$$
\begin{align}
\frac{(x_1-a)^2}{\sigma_1^2}-\frac{2\rho(x_1-a)(x_2-b)}{\sigma_1\sigma_2}+\frac{(x_2-b)^2}{\sigma_2^2}
=(1-\rho^2)\frac{(x_1-a)^2}{\sigma_1^2}+(\rho\frac{x_1-a}{\sigma_1}-\frac{x_2-b}{\sigma_2})^2
\end{align}
$$

得到

$$
f_1(x_1)=\int_{-\infty}^\infty f(x_1,x_2){\rm d}x_2=\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp(-\frac{(x_1-a)^2}{2\sigma_1^2})C
$$

其中

$$
C=\int_{-\infty}^\infty\exp(-\frac{1}{2(1-\rho^2)}(\rho\frac{x_1-a}{\sigma_1}-\frac{x_2-b}{\sigma_2})^2){\rm d}x_2
$$

作变数代换

$$
t=(\frac{x_2-b}{\sigma_2}-\rho\frac{x_1-a}{\sigma_1})/\sqrt{1-\rho^2}
$$

得

$$
C=\int_{-\infty}^\infty\exp(-t^2/2){\rm d}t\cdot\sigma_2\sqrt{1-\rho^2}=\sqrt{2\pi}\sigma_2\sqrt{1-\rho^2}
$$

代入前式，即得

$$
f_1(x_1)=\frac{1}{\sqrt{2\pi}\sigma_1}\exp(-\frac{(x_1-a)^2}{2\sigma_1^2})
$$

这正是 $N(a,\sigma_1^2)$ 的概率密度函数。

从这个例子可以看出一个事实：虽然一个随机向量 $X=(X_1,\cdots,X_n)$ 的分布 $F$ 可以决定其任一分量 $X_i$ 的（边缘）分布 $F_i$，但反过来不成立：即使知道了所有 $X_i$ 的边缘分布 $F_i,i=1,\cdots,n$，也不足以决定 $X$ 的分布 $F$。例如，考虑两个二维正态分布

$$
N(0,0,1,1,1/3) 和 N(0,0,1,1,2/3)
$$

它们的任一边缘分布都是标准正态分布 $N(0,1)$，但这两个二维分布是不同的分布，因为 $\rho$ 的值不同。这个现象的解释是：边缘分布只分别考虑了单个变量 $X_i$ 的情况，而未涉及它们之间的关系，而这个信息却是包含在 $(X_1,\cdots,X_n)$ 的分布之内的。就本例来说，在下一章将指出：$\rho$ 这个参数正好刻画了两个分量 $X_1$ 和 $X_2$ 之间的关系。

在结束这一节之前，我们再次指出：边缘分布就是通常的分布，并无任何特殊的含义。它只是强调了，这个分布是由于 $X_i$ 作为随机向量 $(X_1,\cdots,X_n)$ 的一个分量，从后者的分布派生出的分布而已，别无其他含义。

与此相应，为了强调 $(X_1,\cdots,X_n)$ 的分布是把 $X_1,\cdots,X_n$ 作为一个有联系的整体来考虑，有时把它称为 $X_1,\cdots,X_n$ 的**联合分布**。

另外，边缘分布也可以不只是单个分量。例如 $X=(X_1,X_2,X_3)$ 的分布也决定了其任一部分，例如 $(X_1,X_3)$ 的二维分布，这也称为边缘分布。有关公式也不难导出，这里不再展开。

## 条件概率分布与随机变量的独立性

### 条件概率分布的概念

（这一节描述了条件概率分布的概念，具体内容请参阅原文，此处略去。）

### 离散型随机变量的条件概率分布

这一种情况比较简单，实际上无非是第一章讲过的条件概率的概念在另一种形式下的重复。设 $(X_1,X_2)$ 是一个二维离散型随机向量，$X_1$ 的全部可能值为 $a_1,a_2,\cdots$，$X_2$ 的全部可能值为 $b_1,b_2,\cdots$，而 $(X_1,X_2)$ 的联合概率分布为

$$
p_{ij}=P(X_1=a_i,X_2=b_j),i,j=1,2,\cdots
$$

现考虑 $X_1$ 在给定 $X_2=b_j$ 的条件下的条件分布，那无非是找条件概率 $P(X_1=a|X_2=b_j)$。依条件概率的定义，有

$$
P(X_1=a_i|X_2=b_j)=P(X_1=a_i,X_2=b_j)/P(X_2=b_j)=p_{ij}/P(X_2=b_j)
$$

再据 (2.8)（$n=2$ 的情形），有 $P(X_2=b_j)=\sum_{k}p_{kj}$，于是

$$
\begin{equation}
\tag{3.1}
P(X_1=a_i|X_2=b_j)=p_{ij}/\sum_{k}p_{kj},i=1,2,\cdots
\end{equation}
$$

类似地有

$$
\begin{equation}
\tag{3.2}
P(X_2=b_j|X_1=a_i)=p_{ij}/\sum_{k}p_{ik},j=1,2,\cdots
\end{equation}
$$

@设 $(X_1,X_2,\cdots,X_n)$ 服从多项分布 $M(N;p_1,\cdots,p_n)$，试求在给定 $X_2=k_2$ 的条件下 $X_1$ 的条件分布。

先计算概率 $P(X_1=k_1,X_2=k_2)$。这里假定 $k_1,k_2$ 都是非负整数，且 $k_1\le N-k_2$，按照 (2.3)，有

$$
P(X_1=k_1,X_2=k_2)=\sum_{k_3,\cdots,k_n}'\frac{N!}{k_1!k_2!k_3!\cdots k_n!}p_1^{k_1}p_2^{k_2}p_3^{k_3}\cdots p_n^{k_n}
$$

这里 $\sum_{k_3,\cdots,k_n}'$ 表示求和的范围为 $k_3,\cdots,k_n$ 都是非负整数，且 $k_3+\cdots+k_n=N-(k_1+k_2)$。令 $p_i'=p_i/(1-p_1-p_2),i\ge 3$，有

$$
P(X_1=k_1,X_2=k_2)=\frac{N!}{k_1!k_2!(N-k_1-k_2)!}\cdot p_1^{k_1}p_2^{k_2}(1-p_1-p_2)^{N-k_1-k_2}C
$$

其中

$$
C=\sum_{k_3,\cdots,k_n}'\frac{(N-k_1-k_2)!}{k_3!\cdots k_n!}p_3'^{k_3}\cdots p_n'^{k_n}
$$

由于 $p_3'+\cdots+p_n'=1$，考虑到上式求和的范围和多项展开式 (2.4)，即有 $C=1$，因此

$$
P(X_1=k_1,X_2=k_2)=\frac{N!}{k_1!k_2!(N-k_1-k_2)!}\cdot p_1^{k_1}p_2^{k_2}(1-p_1-p_2)^{N-k_1-k_2}
$$

再根据“多项分布的边缘分布就是二项分布”这一结论，$X_2$ 的分布就是二项分布 $B(N,p_2)$，因此

$$
\displaylines{
P(X_1=k_1|X_2=k_2)\\
=P(X_1=k_1,X_2=k_2)/P(X_2=k_2)\\
=\frac{N!}{k_1!k_2!(N-k_1-k_2)!}\cdot p_1^{k_1}p_2^{k_2}(1-p_1-p_2)^{N-k_1-k_2}/\frac{N!}{k_2!(N-k_2)!}p_2^{k_2}(1-p_2)^{N-k_2}\\
=\frac{(N-k_2)!}{(k_1!(N-k_1-k_2)!)}(\frac{p_1}{1-p_2})^{k_1}(1-\frac{p_1}{1-p_2})^{N-k_1-k_2}\\
=b(k_1;N-k_2,\frac{p_1}{1-p_2}),k=0,1,\cdots,N-k_2
}
$$

由此可知：在给定 $X_2=k_2$ 的条件下，$X_1$ 的条件分布就是分布 $B(N-k_2,\frac{p_1}{1-p_2})$。

## 随机变量的函数的概率分布

设二维随机向量 $X=(X_1,X_2)$ 有概率密度函数 $f(x_1,x_2)$。先来考虑在限定 $a\le x_2\le b$ 的条件下，$X_1$ 的条件分布，有

$$
P(X_1le x_1|a\le X_2\le b)=P(X_1le x_1,a\le X_2\le b)/P(a\le X_2\le b)
$$

$X_2$ 的边缘分布的密度函数 $f_2$ 由 (2.10) 给出，有

$$
\displaylines{
P(X_1le x_1,a\le X_2\le b)=\int_{-\infty}^{x_1}{\rm d}t_1\int_a^bf(t_1,t_2){\rm d}t_2\\
P(a\le X_2\le b)=\int_a^bf_2(t_2){\rm d}t_2
}
$$

由此得到

$$
P(X_1\le x_1|a\le X_2\le b)=\int_{-\infty}^{x_1}{\rm d}t_1\int_a^bf(t_1,t_2){\rm d}t_2/\int_a^bf_2(t_2){\rm d}t_2
$$

这是 $X_1$ 的条件分布函数。对 $x_1$ 求导数，得到条件密度函数为

$$
\begin{equation}
\tag{3.3}
f_1(x_1|a\le X_2\le b)=\int_a^bf(x_1,t_2){\rm d}t_2/\int_a^bf_2(t_2){\rm d}t_2
\end{equation}
$$

更有兴趣的是 $a=b$ 的情况，即在给定 $X_2$ 等于一个值之下，$X_1$ 的条件密度函数。这不能通过直接在 (3.3) 中令 $a=b$ 得出，但可以使用极限：

$$
\begin{align}
f_1(x_1|x_2)&=f_1(x_1|X_2=x_2)\\
&=\lim_{h\to 0}f_1(x_1|x_2\le X_2\le x_2+h)\\
&=\lim_{h\to 0}\frac{1}{h}\int_{x_2}^{x_2+h}f(x_1,t_2){\rm d}t_2/\lim_{h\to 0}\frac{1}{h}\int_{x_2}^{x_2+h}f_2(t_2){\rm d}t_2\\
&=f(x_1,x_2)/f_2(x_2)\quad\quad\quad\quad\quad\quad\quad\quad (3.4)
\end{align}
$$

这就是在给定 $X_2=x_2$ 的条件下，$X_1$ 的条件密度函数。此式当然只有在 $f_2(x_2)>0$ 时才有意义。在上述取极限的过程中，还得假定函数 $f_2$ 在 $x_2$ 点连续，以及 $f(x_1,t_2)$ 作为 $t_2$ 的函数，在 $t_2=x_2$ 处连续。然而，用高等概率论的知识，可以在没有这种连续的假定下证明 (3.4)。

(3.4) 可改写为

$$
\begin{equation}
\tag{3.5}
f(x_1,x_2)=f_2(x_2)f_1(x_1|x_2)
\end{equation}
$$

就是说：两个随机变量 $X_1$ 和 $X_2$ 的联合概率密度，等于其中之一的概率密度乘以在给定这一下之下另一个的条件概率密度。这个公式相应于条件概率的公式 $P(AB)=P(B)P(A|B)$。除 (3.5) 外，当然也有

$$
\begin{equation}
\tag{3.6}
f(x_1,x_2)=f_1(x_1)f_2(x_2|x_1)
\end{equation}
$$

其中 $f_1$ 为 $x_1$ 的边缘密度，而

$$
\begin{equation}
\tag{3.7}
f_2(x_2|x_1)=f(x_1,x_2)/f_1(x_1)
\end{equation}
$$

则是在给定 $X_1=x_1$ 的条件下，$X_2$ 的条件密度。这些公式反映的实质可推广到任意多个变量的场合：设有 $n$ 维随机向量 $(X_1,\cdots,X_n)$，其概率密度函数为 $f(x_1,\cdots,x_n)$，则

$$
\begin{equation}
\tag{3.8}
f(x_1,\cdots,x_n)=g(x_1,\cdots,x_k)h(x_{k+1},\cdots,x_n|x_1,\cdots,x_k)
\end{equation}
$$

其中 $g$ 是 $(X_1,\cdots,X_k)$ 的边缘概率密度，而 $h$ 则是在给定 $X_1=x_1,\cdots,X_k=x_k$ 的条件下，$X_{k+1},\cdots,X_n$ 的条件概率密度。(3.8) 可视为 (3.6) 的直接推广，又可视为 $h(x_{k+1},\cdots,x_n|x_1,\cdots,x_k)$ 的定义。

@设 $(X_1,X_2)$ 服从二维正态分布 $N(a,b,\sigma_1^2,\sigma_2^2,\rho)$。求在给定 $X_1=x_1$ 的条件下，$X_2$ 的条件密度函数 $f_2(x_2|x_1)$。

利用 (3.7)、(2.7) 和 (2.12)，经过简单的计算，得到

$$
\begin{equation}
\tag{3.9}
f_2(x_2|x_1)=\frac{1}{\sqrt{2\pi}\sigma_2\sqrt{1-\rho^2}}\exp(-\frac{(x_2-(b+\rho\sigma_2\sigma_1^{-1}(x_1-a)))^2}{2(1-\rho^2)\sigma_2^2})
\end{equation}
$$

这正是正态分布 $N(b+\rho\sigma_2\sigma_1^{-1}(x_1-a),\sigma_2^2(1-\rho^2))$ 的概率密度函数（注意在上式中，$x_1$ 当作常数看）。因此，正态变量的条件分布仍为正态，这是正态分布的一个重要性质。

正态分布 (3.9) 的中心位置在

$$
\begin{equation}
\tag{3.10}
m(x_1)=b+\rho\sigma_2\sigma_1^{-1}(x_1-a)
\end{equation}
$$

处，由这里可以看出 $\rho$ 刻画了 $X_1,X_2$ 之间的相依关系。其解释如下：若 $\rho>0$，则 $X_2$（在 $X_1=x_1$ 之下）的条件分布的中心点 $m(x_1)$ 随 $x_1$ 的增加而增加，即 $X_2$ 有随着 $X_1$ 的增加而增加的倾向（如体重和身高的关系那样）。反之，若 $\rho<0$，则 $X_2$ 有随着 $X_1$ 增加而减少的倾向。由于这个原因，通常把 $\rho>0$ 的情况称为**正相关**，$\rho<0$ 的情况称为**负相关**。这一点在下一章中还要谈到。

把 (3.5) 两边两边对 $x_2$ 积分，得

$$
\begin{equation}
\tag{3.11}
f_1(x_1)=\int_{-\infty}^\infty f(x_1,x_2){\rm d}x_2=\int_{-\infty}^\infty f_1(x_1|x_2)f_2(x_2){\rm d}x_2
\end{equation}
$$

这个公式可解释为：$X_1$ 的无条件密度 $f_1(x_1)$，是其条件密度 $f_1(x_1|x_2)$ 对条件 $x_2$ 的平均。更确切地说，是按其概率大小为权的加权平均，因为 $f_2(x_2){\rm d}x_2$ 正是 $X_2$ 在 $x_2$ 附近 ${\rm d}x_2$ 这么长的区间内的概率。从直观上看这应当是很自然的。比如说，$(X_1,X_2)$ 代表一大群人中随机抽出的一个人的体重和身高，$X_1$（体重）有其（无条件）分布，这可以看作为各种不同的身高综合之后所呈现的分布，而不同于固定身高 $X_2=x_2$ 时的条件分布。但把各种身高时体重的条件分布进行平均，也就实现了上述综合，即得到无条件分布。(3.11) 正好从数学上反映了这种综合（或平均）的过程。

还要注意，(3.11) 也可以看作是全概率公式在概率密度这种情况下的表现形式。在这里，$f_1(x_1)$ 相当于全概率公式中的 $P(A)$，$f_1(x_1|x_2)$ 相当于条件概率 $P(A|B_i)$，而积分就相当于以 $P(B_i)$ 为权重的加权和。

### 随机变量的独立性

先考虑两个变量 $X_1,X_2$ 的情况，并设 $(X_1,X_2)$ 为连续型。如前，分别以 $f(x_1,x_2),f_1(x_1),f_2(x_2),f_1(x_1|x_2),f_2(x_2|x_1)$ 记联合、边缘与条件概率密度。

一般，$f_1(x_1|x_2)$ 随 $x_2$ 的变化而变化，这反映了 $X_1$ 与 $X_2$ 在概率上有相依关系的事实，即 $X_1$ 的（条件）分布如何，取决于另一变量的值。

如果 $f_1(x_1|x_2)$ 不依赖于 $x_2$，因而只是 $x_1$ 的函数，暂记为 $g(x_1)$，则表示 $X_1$ 的分布情况与 $X_2$ 取何值完全无关，这时就称 $X_1,X_2$ 这两个随机变量独立。此概念与事件独立的概念完全相似。

把 $f_1(x_1|x_2)=g(x_1)$ 代入 (3.11)，得

$$
\begin{align}
f_1(x_1)&=\int_{-\infty}^\infty g(x_1)f_2(x_2){\rm d}x_2\\
&=g(x_1)\int_{-\infty}^\infty f_2(x_2){\rm d}x_2\\
&=g(x_1)
\end{align}
$$

因此，$X_1$ 的无条件密度 $f_1(x_1)$ 就等于其条件密度 $f_1(x_1|x_2)$，这也可作为独立性的定义。

再次，把 $f_1(x_1)=f_1(x_1|x_2)$ 代入 (3.5)，得

$$
\begin{equation}
\tag{3.12}
f(x_1,x_2)=f_1(x_1)f_2(x_2)
\end{equation}
$$

即 $(X_1,X_2)$ 的联合密度，等于其各分量的密度之积。这也可作为 $X_1,X_2$ 独立的定义，相比上述定义，它有其优越性：一是其形式关于两个变量对称，二是它总有意义，而在用条件密度去定义时，可能碰到条件密度在个别点无法定义（分母为 0）的情况。

这个形式的另一个好处是它可以直接推广到任意多个变量的情形，我们就把它作为一般情况下的正式定义：

**定义 3.1** 设 $n$ 维随机向量 $(X_1,\cdots,X_n)$ 的联合密度函数为 $f(x_1,\cdots,x_n)$，而 $X_i$ 的（边缘）密度函数为 $f_i(x_i),i=1,\cdots,n$。如果

$$
\begin{equation}
\tag{3.13}
f(x_1,\cdots,x_n)=f_1(x_1)\cdots f_n(x_n)
\end{equation}
$$

就称随机变量 $X_1,\cdots,X_n$ 相互独立或简称独立。

变量独立性的概念还可以从另外的角度去考察。按照前面的分析，它含有这种意思：如果 $X_1,\cdots,X_n$ 独立，则各变量取值的概率如何，完全不受其他变量的影响，因此若考察 $n$ 个事件

$$
\begin{equation}
\tag{3.14}
A_1=\{a_1\le X_1\le b_1\},\cdots,A_n=\{a_n\le X_n\le b_n\}
\end{equation}
$$

则因各事件只涉及一个变量，它们应当是相互独立的事件，我们可以把这个要求取为变量 $X_1,\cdots,X_n$ 独立的定义。下面的定义证明，这与定义，这与定义 3.1 是等价的，即同一件事的两种不同的说法。

**定理 3.1** 如果连续变量 $X_1,\cdots,X_n$ 独立，则 $\forall a_i<b_i,i=1,\cdots,n$，由 (3.14) 定义的 $n$ 个事件 $A_1,\cdots,A_n$ 也独立。

反之，若 $\forall a_i<b_i,i=1,\cdots,n$，事件 $A_1,\cdots,A_n$ 独立，则变量 $X_1,\cdots,X_n$ 也独立。

证明略。

下面再给出两个关于独立性的有用结果。

**定理 3.2** 若连续型随机向量 $(X_1,\cdots,X_n)$ 的概率密度函数 $f(x_1,\cdots,x_n)$ 可表示为 $n$ 个函数 $g_1,\cdots,g_n$ 之积，其中 $g_i$ 只依赖于 $x_i$，即

$$
\begin{equation}
\tag{3.15}
f(x_1,\cdots,x_n)=g_1(x_1)\cdots g_n(x_n)
\end{equation}
$$

则 $X_1,\cdots,X_n$ 相互独立，且 $X_i$ 的边缘密度函数 $f_i(x_i)$ 与 $g_i(x_i)$ 只相差一个常数因子。

证明略。

**定理 3.3** 若 $X_1,\cdots,X_n$ 相互独立，而

$$
Y_1=g_1(X_1,\cdots,X_m),Y_2=g_2(X_{m+1},\cdots,X_n)
$$

则 $Y_1$ 和 $Y_2$ 独立。

证明略。

以上讨论都是关于连续型变量的独立性，至于离散型变量则更为简单。

**定义 3.2** 设 $X_1,\cdots,X_n$ 都是离散型随机变量。若对任意常数 $a_1,\cdots,a_n$，都有

$$
P(X_1=a_1,\cdots,X_n=a_n)=P(X_1=a_1)\cdots P(X_n=a_n)
$$

则称 $X_1,\cdots,X_n$ 相互独立。

所有关于独立性的定理，如定理 3.1-3.3，都适用于离散型变量。唯一的变动是，凡事在这些定理中提到“密度函数”的地方，都要改为“概率函数”。

@设 $(X_1,X_2)$ 服从二维正态分布 $N(a,b,\sigma_1^2,\sigma_2^2,\rho)$。由其联合密度函数 $f(x_1,x_2)$ 的形式 (2.7) 看出：当且仅当 $\rho=0$ 时，$f(x_1,x_2)$ 才可以表示为两个边缘密度 $f_1(x_1)$ 和 $f_2(x_2)$ 之积。因此，当且仅当 $\rho=0$ 时，$X_1$ 和 $X_2$ 独立。这进一步反映了我们之前提及的一点事实：$\rho$ 这个参数与 $X_1,X_2$ 的相依性有关。

@再次考虑二维随机向量 $X=(X_1,X_2)$，其概率密度函数为

$$
f(x_1,x_2)=\pi^{-1}(1+x_1^2+x_2^2)^{-2}
$$

$X_1,X_2$ 的边缘密度函数分别为

$$
\displaylines{
f_1(x_1)=\frac{1}{2}(1+x_1^2)^{-3/2}\\
f_2(x_2)=\frac{1}{2}(1+x_2^2)^{-3/2}
}
$$

容易看出 $f(x_1,x_2)\neq f_1(x_1)f_2(x_2)$，故 $X_1,X_2$ 不独立。

与事件的独立性一样，在实际问题中，变量的独立性往往不是从其数学定义去验证出来的。相反，常是从变量产生的实际背景判断它们独立（或者其相依性很微弱因而可近似地认为是独立），然后再使用独立性定义中所赋予的性质和独立性的有关定理。例如，一城市中两个相距较远的路段在一定时间内各自发生的交通事故数，一个人的姓氏笔划与其智商。在实际中，$n$ 个变量 $X_1,\cdots,X_n$ 的独立性通常是这样产生的：有 $n$ 个彼此无关联的试验 $E_1,\cdots,E_n$，而 $X_i$ 只依赖于试验 $E_i$ 的结果。形式上我们可以构造一个复合试验 $E=(E_1,\cdots,E_n)$，以把这 $n$ 个变量都包容在这个试验 $E$ 之下。这种观点在讲事件独立性时已经提到过了。

然而，在主要是理论的情况下，需要直接借助定义来验证变量的独立性。

@设 $X_1,X_2$ 独立，都服从标准正态分布 $N(0,1)$。把点 $(X_1,X_2)$ 的极坐标记作 $(R,\Theta),0\le R<\infty,0\le \Theta<2\pi$。求证：$R$ 和 $\Theta$ 独立（如下图）。

![](https://s2.loli.net/2023/01/22/qduv7VImErtzkaN.png)

取 $r_0>0,0<\theta_0<2\pi$，考虑事件 $B=\{0\le R\le r_0,0\le\Theta\le\theta_0\}$。由于 $X_1,X_2$ 独立且各自的密度函数分别为 $\sqrt{2\pi}^{-1}\cdot e^{-x_1^2/2}$ 和 $\sqrt{2\pi}^{-1}\cdot e^{-x_2^2/2}$，由独立性定义知 $(X_1,X_2)$ 的联合密度为 $(2\pi)^{-1}\exp(-\frac{1}{2}(x_1^2+x_2^2))$。因此，按照密度函数的定义，有

$$
P(B)=\iint_A(2\pi)^{-1}\exp(-\frac{1}{2}(x_1^2+x_2^2)){\rm d}x_1{\rm d}x_2
$$

化为极坐标，得

$$
P(0\le R\le r_0,0\le\Theta\le\theta_0)=(2\pi)^{-1}\int_0^{\theta_0}\int_0^{r_0}e^{-r^2/2}r{\rm d}r{\rm d}\theta
$$

由这个等式直接看出，$(R,\Theta)$ 的概率密度函数就是 $(2\pi)^{-1}e^{-r^2/2}r$（当 $0\le r<\infty,0\le\theta<2\pi$，其他位置为 0）。它是下面两个函数的乘积：

$$
f_1(r)=\begin{cases}
e^{-r^2/2}r,& 当 r\ge 0\\
0,& 当 r<0
\end{cases},f_2(\theta)=\begin{cases}
1/2\pi,& 当 0\le\theta<2\pi\\
0,& 其他情况
\end{cases}
$$

按照定理 3.2，即得知 $R$ 与 $\Theta$ 独立，且 $R$ 与 $\Theta$ 的密度函数分别是 $f_1(r)$ 和 $f_2(\theta)$。

离散型变量独立性的一个重要例子涉及事件独立性与随机变量独立性之间的关系。

@设有 $n$ 个事件 $A_1,A_2,\cdots,A_n$，针对每个事件 $A_i$，可以定义一个随机变量 $X_i$ 如下：

$$
X_i=1,当事件A发生;X_i=0,当A不发生
$$

常把 $X_i$ 称为事件 $A$ 的指示变量、指示函数或示性函数（indicator），意思是其值指示了 $A$ 是否发生。这个写法表明：事件可视为随机变量的一种特例。

不难证明：若事件 $A_1,\cdots,A_n$ 独立，则其指示变量 $X_1,\cdots,X_n$ 独立。反之亦成立。

@设 $(X_1,\cdots,X_n)$ 服从多项分布 $M(N;p_1,\cdots,p_n),p_i>0,i=1,\cdots,n$。$\forall u\neq v$，$X_u$ 和 $X_v$ 不独立。

证明略。

## 随机变量的函数的概率分布

在理论和应用上，经常碰到这种情况：已知某个或某些随机变量 $X_1,\cdots,X_n$ 的分布，现另有一随机变量 $Y_1,\cdots,Y_m$，它们都是 $X_1,\cdots,X_m$ 的函数：

$$
Y_i=g_i(X_1,\cdots,X_n),i=1,\cdots,m
$$

要求 $(Y_1,\cdots,Y_m)$ 的概率分布。

在数理统计学中经常碰到这个问题。在那里，$X_1,\cdots,X_n$ 是原始的观察或试验数据，$Y_1,\cdots,Y_m$ 则是为某种目的将这些数据“加工”而得到的量，称为**统计量**。例如，$X_1,\cdots,X_n$ 可能是对某个未知量 $a$ 作 $n$ 次测量的结果，测量有误差，因此我们决定用 $X_1,\cdots,X_n$ 的算术平均数 $\overline{X}=(X_1+\cdots+X_n)/n$ 去估计未知量 $a$，这里 $\overline{X}$ 就是 $X_1,\cdots,X_n$ 的函数。

### 离散型分布的情况

这种情况比较简单，故只需稍加解释。例如变量 $X$ 取 6 个值 $-2,-1,0,1,2,3$，其概率分别为 $1/12,3/12,3/12,2/12,1/12$ 和 $2/12$，而 $Y=X^3$，则 $Y$ 取 $-8,-1,0,1,8,27$ 这 6 个值，它们互相不重合，故取这些值的概率仍如上所述。

但若考虑 $Y=X^2$，则情况有所不同。相应于 $X$ 的 6 个值的 $Y$ 值分别为 $4,1,0,1,4,9$，其中有重合的。重合值的概率需要合并起来：

$$
\displaylines{
P(Y=0)=P(X=0)=3/12\\
P(Y=1)=P(X=1)+P(X=-1)=2/12+3/12=5/12\\
P(Y=4)=P(X=2)+P(X=-2)=1/12+1/12=2/12\\
P(Y=9)=P(X=3)=2/12
}
$$

一般情况在原则上也一样：把 $Y=g(X_1,\cdots,X_n)$ 可以取的不同值找出来，再把与某个值相应的全部 $(X_1,\cdots,X_n)$ 值的概率加起来，即得到 $Y$ 取这个值的概率。当然，在实际做的时候，涉及的计算可能并不简单。

@设 $(X_1,X_2,\cdots,X_n)$ 服从多项分布 $M(N;p_1,\cdots,p_n),n\ge 3$，试求 $Y=X_1+X_2$ 的分布。

对于指定的 $k$，有

$$
P(Y=k)=\sum'\frac{N!}{k_1!k_2!\cdots k_n!}p_1^{k_1}p_2^{k_2}\cdots p_n^{k_n}
$$

这里 $\sum'$ 表示求和的范围为：$k_1$ 为非负整数，$k_1+k_2=k$，$k_1+\cdots+k_n=N$。

记 $p_i'=p/(1-p_1-p_2),i=3,\cdots,n$，则 $p_3'+\cdots+p_n'=1$。将上式写为

$$
P(Y=k)=\frac{N!}{k!(N-k)!}(1-p_1-p_2)^{N-k}\sum''\frac{k!}{k_1!k_2!}p_1^{k_1}p_2^{k_2}\sum'''\frac{(N-k)!}{k_3!\cdots k_n!}p_3'^{k_3}\cdots p_n'^{k_n}
$$

这里 $\sum''$ 求和的范围为：$k_1,k_2$ 为非负整数，$k_1+k_2=k$；$\sum'''$ 求和的范围为：$k_3,\codts,k_n$ 为非负整数，$k_3+\cdots+k_n=N-k$。由于 $p_3'+\cdots+p_n'=1$，由 (2.4) 知 $\sum'''$ 这个和的值为 1，而 $\sum''$ 这个和的值为 $(p_1+p_2)^k$，于是得到

$$
P(Y=k)=\frac{N!}{k!(N-k)!}(p_1+p_2)^k(1-p_1-p_2)^{N-k}=b(k;N,p_1+p_2)
$$

即 $Y$ 服从二项分布 $B(N,p_1+p_2)$。

如果从概率意义的角度去考虑，这个结果不用计算就可以知道：在定义多项分布时有 $n$ 个事件 $A_1,A_2,\cdots,A_n$，$X_1,X_2,\cdots,X_n$ 分别是它们在 $N$ 次试验中发生的次数。现若记 $A=A_1+A_2$，则事件 $A,A_3,\cdots,A_n$ 仍构成一个完备事件群，其概率分别为 $p_1+p_2,p_3,\cdots,p_n$，记 $Y=X_1+X_2$，则 $(Y,X_3,\cdots,X_n)$ 构成多项分布 $M(N;p_1+p_2,p_3,\cdots,p_n)$，而 $Y$ 成为这个多项分布的一个边缘分布。

这就是我们前面几个地方都提及的概率思维。概率论中有不少结果可以用纯分析方法证明，但如利用概率思维，有时证明可以简化。学习概率论的一个要素就在于锻炼这种概率思维。

@设 $X_1$ 和 $X_2$ 独立，分别服从二项分布 $B(n_1,p)$ 和 $B(n_2,p)$，求 $Y=X_1+X_2$ 的分布。

$Y$ 的可能取值为 $0,1,\cdots,n_1+n_2$，固定 $k$ 于上述范围内，由独立性假定，有

$$
\begin{align}
P(Y=k)&=\sum'P(X_1=k_1,X_2=k_2)\\
&=\sum'\begin{pmatrix}n_1\\k_1\end{pmatrix}p^{k_1}(1-p)^{n_1-k_1}\begin{pmatrix}n_2\\k_2\end{pmatrix}p^{k_2}(1-p)^{n_2-k_2}\\
&=\sum'\begin{pmatrix}n_1\\k_1\end{pmatrix}\begin{pmatrix}n_2\\k_2\end{pmatrix}p^k(1-p)^{n_1+n_2-k}\\
&={pmatrix}n_1+n_2\\k\end{pmatrix}p^k(1-p)^{n_1+n_2-k}\\
&=b(k;n_1+n_2,p)
\end{align}
$$

（其中 $\sum'$ 求和的范围为：$k_1,k_2$ 为非负整数，$k_1+k_2=k$）

即 $Y$ 服从二项分布 $B(n_1+n_2,p)$。这个结果很容易推广到多个变量的情形：若 $X_i\sim B(n_i,p),i=1,\cdots,m$，而 $X_1,\cdots,X_m$ 独立，则 $X_1+\cdots+X_m\sim B(n_1+\cdots+n_m,p)$。证明不难用归纳法作出，此处略去。 

上述结论如用“概率思维”，则不证自明：按照二项分布的定义，若 $X\sim B(n,p)$，则 $X$ 是在 $n$ 次独立试验中事件 $A$ 出现的次数，而在每次试验中 $A$ 的概率都保持为 $p$。现 $X_i$ 是在 $n_i$ 次试验中 $A$ 出现的次数，每次试验 $A$ 出现的概率保持为 $p$，故 $Y=X_1+\cdots+X_m$ 是在 $n_1+\cdots+n_m$ 次独立试验中 $A$ 出现的次数，而在每次试验中 $A$ 出现的概率保持为 $p$，故按照定义即得 $Y\sim B(n_1+\cdots+n_m,p)$。

@设 $X_1,X_2$ 独立，分别服从泊松分布 $P(\lambda_1)$ 和 $P(\lambda_2)$。证明 $Y=X_1+X_2$ 服从泊松分布 $P(\lambda_1+\lambda_2)$。

$Y$ 的可能取值仍为一切非负整数，固定 $k$ 于上述范围内，则由独立性假定以及泊松分布的形式，有

$$
\begin{align}
P(Y=k)&=\sum'P(X_1=k_1,X_2=k_2)\\
&=\sum'P(X_1=k_1)P(X_2=k_2)\\
&=\sum'e^{-\lambda_1}\lambda_1^{k_1}/k_1!\cdot e^{-\lambda_2}\lambda_2^{k_2}/k_2!\\
&=e^{-(\lambda_1+\lambda_2)}/k!\sum'\frac{k!}{k_1!k_2!}\lambda_1^{k_1}\lambda_2^{k_2}\\
&=e^{-(\lambda_1+\lambda_2)}(\lambda_1+\lambda_2)^k/k!
\end{align}
$$

（其中 $\sum'$ 的求和范围与上例相同）

因而证明了所要的结果。这一结果也可以自然地推广到多个的情形。

之前我们提到，泊松分布可以视作二项分布的极限形式，利用这一理解，无需计算即可看出上述结论。

### 连续型分布的情况：一般讨论

接下来将讨论更令人感兴趣的连续型情况。

先考虑一个变量的情况。设 $X$ 有密度函数 $f(x)$。设 $Y=g(X)$，$g$ 是一个严格单调递增的函数，又设 $g$ 的导数 $g'$ 存在，由于 $g$ 的严格递增性，其反函数 $X=h(Y)$ 存在且 $h$ 的导数 $h'$ 也存在。

任取实数 $y$。因 $g$ 严格递增，有

$$
P(Y\le y)=P(g(X)\le y)=P(X\le h(y))=\int_{-\infty}^{h(y)}f(t){\rm d}t
$$

$Y$ 的密度函数 $l(y)$，即是这个表达式对 $y$ 求导数，有

$$
\begin{equation}
\tag{4.2}
l(y)=f(h(y))h'(y)
\end{equation}
$$

如果 $Y=g(X)$ 而 $g$ 是严格单调递减，则 $\{g(X)\le y\}$ 相当于 $\{X\le h(Y)\}$，于是

$$
P(Y\le y)=P(g(X)\le y)=P(X\ge h(y))=\int_{h(y)}^{\infty}f(t){\rm d}t
$$

对 $y$ 求导数，得到 $Y$ 的密度函数

$$
\begin{equation}
\tag{4.3}
l(y)=-f(h(y))h'(y)
\end{equation}
$$

因为当 $g$ 严格递减时，其反函数 $h$ 也严格递减，故 $h'(y)<0$，这样 $l(y)$ 仍为非负的。总结 (4.2) 和 (4.3)，得知在 $g$ 严格单调的情况下，总有 $g(X)$ 的密度函数 $l(y)$ 为

$$
\begin{equation}
\tag{4.4}
l(y)=|f(h(y))h'(y)|
\end{equation}
$$

@$Y=aX+b,a\neq 0$，反函数为 $X=(Y-b)/a$。由 (4.4) 得到：$Y$ 的密度函数为

$$
\begin{equation}
\tag{4.5}
l(y)=f((y-b)/a)/|a|
\end{equation}
$$

若 $X$ 服从正态分布 $N(\mu,\sigma^2)$，则根据正态密度函数的表达式 (1.14) 和 (4.5)，易算出 $aX+b$ 服从正态分布 $N(a\mu+b,a^2\sigma^2)$。特别地，当 $Y=(X-\mu)/\sigma$ 时，有 $Y\sim N(0,1)$。

当 $Y=g(X)$ 而 $g$ 不为严格单调时，情况复杂一些，但并无原则性困难。我们不去考虑一般情况，而只注意一个特例 $Y=X^2$，仍以 $f$ 记 $X$ 的概率密度。因为 $Y$ 非负，当 $y\le 0$，有 $P(Y\le y)=0$；当 $y>0$，则有

$$
P(Y\le y)=P(X^2\le y)=P(-\sqrt{y}\le X\le\sqrt{y})=\int_{-\sqrt{y}}^{\sqrt{y}}f(t){\rm d}t
$$

对 $y$ 求导数，得到 $Y$ 的密度函数 $l(y)$ 为

$$
l(y)=\frac{1}{2}y^{-1/2}(f(\sqrt{y}+f(-\sqrt{y}))),y>0
$$

当 $y\le 0$ 时 $l(y)=0$。

@若 $X\sim N(0,1)$，求 $Y=X^2$ 的密度函数。

以 $f(x)=(\sqrt{2\pi})^{-1}e^{-x^2/2}$ 代入上式，得

$$
l(y)=(\sqrt{2\pi y})^{-1}e^{-y/2},y>0
$$

现在考虑多个变量的函数的情况，以两个为例。设 $(X_1,X_2)$ 的密度函数为 $f(x_1,x_2)$，$Y_1,Y_2$ 都是 $(X_1,X_2)$ 的函数：

$$
\begin{equation}
\tag{4.7}
Y_1=g_1(X_1,X_2),Y_2=g_2(X_1,X_2)
\end{equation}
$$

要求 $(Y_1,Y_2)$ 的概率密度函数 $l(y_1,y_2)$。在此，我们要假定 (4.7) 是 $(X_1,X_2)$ 到 $(Y_1,Y_2)$ 的一一对应变换，因而有逆变换

$$
\begin{equation}
\tag{4.8}
X_1=h_1(Y_1,Y_2),X_2=h_2(Y_1,Y_2)
\end{equation}
$$

又假定 $g_1,g_2$ 都有一阶连续偏导数，这时 $h_1,h_2$ 也有一阶连续偏导数，且在一一对应变换的假定下，Jacobi 行列式

$$
J(y_1,y_2)=\begin{vmatrix}\frac{\partial h_1}{\partial y_1}&\frac{\partial h_1}{\partial y_2}\\
\frac{\partial h_2}{\partial y_1}&\frac{\partial h_2}{\partial y_2}
\end{vmatrix}
$$

不为 0。

现在我们在 $(Y_1,Y_2)$ 的平面上任取一个区域 $A$，在变换 (4.8) 之下，该区域对应到 $(X_1,X_2)$ 平面上的区域 $B$。也就是说，事件 $\{(Y_1,Y_2)\in A\}$ 等于事件 $\{(X_1,X_2)\in B\}$。考虑到 $f$ 是 $(X_1,X_2)$ 的密度函数，有

$$
P((Y_1,Y_2)\in A)=P((X_1,X_2)\in B)=\iint_B f(x_1,x_2){\rm d}x_1{\rm d}x_2
$$

使用重积分变数代换的公式，在变换 (4.8) 之下，上式最后一项的重积分变换为

$$
P((Y_1,Y_2)\in A)=\iint_A f(h_1(y_1,y_2),h_2(y_1,y_2))\cdot |J(y_1,y_2)|{\rm d}y_1{\rm d}y_2
$$

此式对 $(Y_1,Y_2)$ 平面上的任意区域 $A$ 都成立。于是按照定义 2.2，即得 $(Y_1,Y_2)$ 的密度函数为

$$
l(y_1,y_2)=f(h_1(y_1,y_2),h_2(y_1,y_2))\cdot |J(y_1,y_2)|
$$

一个重要的特例是线性变换

$$
\begin{bmatrix}Y_1\\Y_2\end{bmatrix}=\begin{bmatrix}a_{11}&a_{12}\\a_{21}&a_{22}\end{bmatrix}\begin{bmatrix}X_1\\X_2\end{bmatrix}
$$

假定变换的行列式 $a_{11}a_{22}-a_{12}a_{21}\neq 0$，则逆变换 (4.8) 存在且仍为线性变换

$$
\begin{bmatrix}X_1\\X_2\end{bmatrix}=\begin{bmatrix}b_{11}&b_{12}\\b_{21}&b_{22}\end{bmatrix}\begin{bmatrix}Y_1\\Y_2\end{bmatrix}
$$

此变换的 Jacobi 行列式为常数

$$
J(y_1,y_2)=J=b_{11}b_{22}-b_{12}b_{21}=(a_{11}a_{22}-a_{12}a_{21})^{-1}
$$



