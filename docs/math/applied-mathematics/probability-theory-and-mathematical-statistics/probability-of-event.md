# 事件的概率

## 概率是什么

（这一节描述了概率、试验、事件、基本事件、随机事件、必然事件、不可能事件、等可能等概念，定义了古典概率，概率公理，阐述了概率公理。具体内容请参阅原文，此处略去。）

## 古典概率计算

（古典概率的计算主要涉及排列组合，这一部分应归于组合数学，此处略去。）

## 事件的运算、条件概率与独立性

### 事件的蕴含、包含和相等

在同一试验下的两事件 $A$ 和 $B$，如果当 $A$ 发生时 $B$ 一定发生，则称 $A$ **蕴含** $B$，或称 $B$ **包含** $A$，记作 $A\subset B$。若 $A,B$ 相互蕴含，即 $A\subset B$ 且 $B\subset A$，则称 $A,B$ 两事件**相等**，记作 $A=B$。

### 事件的互斥和对立

若两事件 $A,B$ 不能在同一次试验中都发生，则称它们是**互斥**的。如果一些事件中的任意两个都互斥，则称这些事件是两两互斥的，或简称互斥的。

互斥事件的一种特殊情况是对立事件，若 $A$ 为一事件，则事件 $B=\{A 不发生\}$ 称为 $A$ 的**对立事件**，记作 $\overline{A}$。

### 事件的和、积、差

设有两事件 $A,B$，定义事件

$$
\{A 发生或 B 发生\}
$$

称为 $A,B$ 的**和**（或**并**），记作 $A+B$。推广到多个事件的情形，设有若干个事件 $A_1,A_2,\cdots,A_n$，定义事件

$$
\{A_1 发生,或 A_2 发生,\cdots,或 A_n 发生\}
$$

称为这些事件的和，记作 $\sum_{i=1}^nA_i$（或 $\bigcap_{i=1}^nA_i$）。

**定理 3.1** 若干个互斥事件之和的概率，等于各事件的概率之和：

$$
P(A_1+A_2+\cdots)=P(A_1)+P(A_2)+\cdots
$$

事件个数可以是有限的或无限的，此定理就称为（概率的）加法定理，其重要条件是各事件必须两两互斥。

设有两事件 $A,B$，定义事件

$$
\{A,B 都发生\}
$$

称为 $A,B$ 的**积**（或**交**），记作 $AB$。推广到多个事件的情形，设有若干个事件 $A_1,A_2,\cdots,A_n$，定义事件

$$
\{A_1,A_2,\cdots,A_n 都发生\}
$$

称为这些事件的积，记作 $\prod_{i=1}^nA_i$（或 $\bigcup_{i=1}^nA_i$）。

两事件 $A,B$ 的**差**，记作 $A-B$，定义为

$$
\{A 发生,B 不发生\}
$$

显然有

$$
A-B=A\overline{B}
$$

因此，差可以通过积来定义。

我们对事件引入了和差积等运算，借用了算术中的名词。但应注意，算术的法则不一定适用于事件运算。有些规则是成立的，例如 $A+B=B+A,AB=BA,(AB)C=A(BC),A(B-C)=AB-AC$，但另外一些关系不符合算术法则，例如 $A+A=A,AA=A,(A-B)+B=A+B$。

### 条件概率

**定义 3.1** 设有两事件 $A,B$ 而 $P(B)\neq 0$，则给定 B 发生的条件下 A 的**条件概率**，记作 $P(A|B)$，定义为

$$
\begin{equation}
\tag{3.6}
P(A|B)=P(AB)/P(B)
\end{equation}
$$

### 事件的独立性

设有两事件 $A,B$，$A$ 的无条件概率 $P(A)$ 与其在给定 $B$ 发生之下的条件概率 $P(A|B)$，一般是有差异的。这反映了两个事件之间存在着一些关联。例如，若 $P(A|B)>P(A)$，则 $B$ 的发生使 $A$ 发生的可能性增大了，即 $B$ 促进了 $A$ 的发生。

反之，若 $P(A)=P(A|B)$，则 $B$ 的发生与否对 $A$ 发生的可能性没有影响，这时在概率论上就称 $A,B$ 两事件独立，而由 (3.6) 得到

$$
\begin{equation}
\tag{3.7}
P(AB)=P(A)P(B)
\end{equation}
$$

用此式来刻画独立性，比用 $P(A)=P(A|B)$ 更好，因为它不受 $P(B)\neq 0$ 的制约。因此我们取如下定义：

**定义 3.2** 两事件 $A,B$ 若满足 (3.7)，则称 $A,B$ **独立**。

**定理 3.2** 两独立事件 $A,B$ 的积 $AB$ 的概率 $P(AB)$ 等于其各自概率之积 $P(A)P(B)$。

在实际问题中，我们并不常用 (3.7) 去判断两事件 $A,B$ 是否独立，而是相反：从事件的实际角度去分析判断其不应存在关联因而是独立的，然后就可以使用 (3.7)。

如果试验的内容是单一的，那么在这种试验下两事件独立是较少出现的例外。因为，两个事件既然都依赖同一批结果，彼此之间势必会有影响。对于这种单一性试验，(3.7) 作为验证独立性的工具还是有用的。

!!! note "说明"
    未能理解这里“单一”的含义。可能表示的是，试验的内容相对简单，而所有事件基本上都涉及了全部这些内容。

**例** 掷两枚均匀骰子，以 $A_i$ 记“点数和为 $i$ 的倍数”，$i=2,3,5$。通过 (3.7) 验证可知，$A_2$ 与 $A_3$ 独立，但 $A_2$ 与 $A_5$ 不独立。

推广到多个事件的情形：

**定义 3.3** 设 $A_1,A_2,\cdots$ 为有限或无限个事件，如果从中任意去除有限个 $A_{i_1},A_{i_2},\cdots,A_{i_m}$ 都成立

$$
\begin{equation}
\tag{3.8}
P(A_{i_1}A_{i_2}\cdots A_{i_m})=P(A_{i_1})P(A_{i_2})\cdots P(A_{i_m})
\end{equation}
$$

则称事件 $A_1,A_2,\cdots$ **相互独立**，或简称独立。这个定义与从条件概率出发的定义也是等价的。

由独立性的定义可以得到下面的乘法定理：

**定理 3.3** 若干个独立事件 $A_1,\cdots,A_n$ 之积的概率，等于各事件概率的乘积：

$$
\begin{equation}
\tag{3.10}
P(A_1\cdots A_n)=P(A_1)\cdots P(A_n)
\end{equation}
$$

乘法定理的作用和加法定理一样：把复杂事件的概率的计算归结为更简单的事件概率的计算。这当然附有条件：相加是互斥，相乘是独立。

由独立性的定义可以得到下面三条重要推论：

1. 独立事件的任意一部分也独立。例如，$A,B,C,D$ 相互独立，则 $A,C$，或 $A,B,D$ 等，都是相互独立的。

    可以直接由独立性的定义得到。

2. 由独立事件决定的事件也独立。例如，$A_1,\cdots,A_6$ 相互独立，则 $A_1+A_2,A_3-A_4,A_5A_6$ 这三个事件是相互独立的。

    这从直观上很显然……

3. 将独立事件的任意一部分改为对立事件，得到的事件仍相互独立。例如，$A_1,A_2,A_3$ 相互独立，则 $\overline{A_1},A_2,A_3$，$\overline{A_1},A_2,\overline{A_3}$，或 $\overline{A_1},\overline{A_2},\overline{A_3}$ 等，都是相互独立的。

    这从直观上也很显然，证明可以使用数学归纳法，对所包含对立事件的个数进行归纳。

除了相互独立之外，还有两两独立的概念。设 $A_1,A_2,\cdots$ 为有限或无限个事件，如果其中任意两个都独立，则称它们两两独立。由相互独立可以推出两两独立，反过来不一定对。数学上，这表示由 (3.8) 对 $m=2$ 和任何 $i_1\neq i_2$ 成立，不必能推出该式对 $m>2$ 也都成立。下面是一个简单的例子：

**例 3.3** 有四个大小质地一样的球，分别写有数字 1、2、3 和“1 2 3”。引入三个事件：

$$
A_i=\{随机抽出一个球,球上有数字 i\},i=1,2,3
$$

显然有 $P(A_1)=P(A_2)=P(A_3)=1/2$，因为要使 $A_1$ 发生，必须抽出第一个球或第四个球。又有 $P(A_1A_2)=P(A_1A_3)=P(A_2A_3)=1/4$，因为要使 $A_1,A_2$ 同时发生，必须抽出第四个球。这样对 $A_1,A_2,A_3$ 中的任意一对事件 $A_i,A_j$，都有 $P(A_iA_j)=P(A_i)P(A_j)=1/4$，从而 $A_1,A_2,A_3$ 两两独立。

但 $A_1,A_2,A_3$ 并不互相独立，因为显然有 $P(A_1A_2A_3)=1/4$，而 $P(A_1)P(A_2)P(A_3)=1/8$，二者不相等。

!!! note "说明"
    在现实生活中，难以想象两两独立而不相互独立的情况。可以这样想，独立性毕竟是一个数学概念，是现实世界中通常理解的“独立性”的一种数学抽象，它与通常理解的“独立性”并不完全相同。

**例 3.4** 向一架飞机射击，事件 $E$ 是击落这架飞机。设这架飞机有一名驾驶员，两个发动机 $G_1$ 和 $G_2$，又设当击中驾驶员，或者同时击中两个发动机时，飞机才被击落，记事件

$$
E_0=击中驾驶员,E_i=击中 G_i,i=1,2
$$

则 $E$ 可以表示为

$$
E=E_0+E_1E_2
$$

设 $E_0,E_1,E_2$ 独立，这个假定从实际角度看还算合理。记 $E_0,E_1,E_2$ 的概率分别为 $p_0,p_1,p_2$。为计算 $P(E)$，不能直接用加法定理，因为 $E_0$ 与 $E_1E_2$ 并非互斥。考虑 $\overline{E}$，易见 $\overline{E}=\overline{E_0}\overline{E_1E_2}$。因 $E_0,E_1,E_2$ 独立，按照独立性的推论有 $\overline{E_0}$ 和 $\overline{E_1E_2}$ 独立，故

$$
\begin{align}
P(E)&=1-P(\overline{E})\\
&=1-P(\overline{E_0})P(\overline{E_1E_2})\\
&=1-(1-p_0)(1-p_1p_2)\\
&=p_0+p_1p_2-p_0p_1p_2
\end{align}
$$

**例 3.5** 甲、乙二人下象棋，每一局甲胜的概率为 $a$，乙胜的概率为 $b$，为简化问题，假设没有和局的情况，这意味着 $a+b=1$。

设甲的棋艺高于乙，即 $a>b$。考虑到这一点，他们商定最终胜负的规则如下：若甲连胜三局，则甲获胜；若乙连胜两局，则乙获胜。现在要求“甲获胜”这一事件 $A$ 的概率 $P(A)$，以及“乙获胜”这一事件 $B$ 的概率 $P(B)$。

将甲、乙在特定的一局取胜的事件分别记作 $E$ 和 $F$，有 $P(E)=a,P(F)=b$。现考虑“甲获胜”这一事件 $A$，分两种情况：

1. 第一局甲胜

    这一情况可以分解为多个阶段，最后一个阶段是 $EEE$，在此之前的每个阶段是 $EF$ 或 $EEF$（因为两个相邻的 $F$ 之间的 $E$ 的数量大于 0 且小于 3）。

    每个阶段不是 $EF$ 就是 $EEF$，这两种情况互斥，又由每一局的独立性，知每个阶段的概率为 $ab+aab=ab(1+a)$。再由每个阶段的独立性，知 $n$ 个阶段后甲获胜的概率为 $(ab(1+a))^{n-1}a^3$，其中 $n=1,2,\cdots$，不同的 $n$ 互斥。于是这部分概率总和为

    $$
    p=a^3\sum_{n=1}^\infty(ab(1+a))^{n-1}=a^3/(1-ab(1+a))
    $$

2. 第一局乙胜

    第一局为 $F$，则第二局必定为 $E$，故从第二局开始，我们回到了情况 1，从而这部分的概率为 $bp$。

综合这两种情况（它们互斥），用加法定理，得到

$$
P(A)=a^3(1+b)/(1-ab(1+a))
$$

再考虑“乙获胜”这一事件 $B$，分三种情况：

1. 第一局乙胜

    这一情况也可以分解为多个阶段，最后一个阶段是 $FF$，在此之前的每个阶段是 $FE$ 或 $FEE$（因为两个相邻的 $F$ 之间的 $E$ 的数量大于 0 且小于 3）。

    和前面的分析类似地，有

    $$
    p=b^2\sum_{n=1}^\infty(ab(1+a))^{n-1}=b^2/(1-ab(1+a))
    $$

2. 第一局甲胜，第二局乙胜

    从第二局开始，我们回到了情况 1，从而这部分的概率为 $ap$。

3. 前两局甲胜，第三局乙胜

    从第三局开始，我们回到了情况 1，从而这部分的概率为 $a^2p$。

综合这三种情况（它们互斥），用加法定理，得到

$$
P(A)=b^2(1+a+a^2)/(1-ab(1+a))
$$

由于 $a+b=1$，容易验证 $P(A)+P(B)=1$。

!!! note "说明"
    这个例子值得细心品味。第一，它提供了一个涉及到无穷个事件的情况，以及在无穷个事件时使用加法定理。第二，本例告诉我们，在面对一个复杂事件时，主要的方法是冷静地分析以设法将它拆分成一些互斥的简单情况，这里必须细心确保互斥性又无遗漏。

### 全概率公式与贝叶斯公式

设 $B_1,B_2,\cdots$ 为有限或无限个事件，它们两两互斥且在每次试验中至少发生一个，用公式表示为

$$
\displaylines{
B_iB_j=\varnothing(不可能事件),当 i\neq j\\
B_1+B_2+\cdots=\Omega(必然事件)
}
$$

有时把具有这些性质的一组事件称为一个**完备事件群**。特别地，任一事件 $B$ 及其对立事件组成一个完备事件群。

现考虑任一事件 $A$，因 $\Omega$ 为必然事件，有 $A=A\Omega=AB_1+AB_2+\cdots$。因 $B_1,B_2,\cdots$ 两两互斥，显然 $AB_1,AB_2,\cdots$ 也两两互斥。故依加法定理，有

$$
P(A)=P(AB_1)+P(AB_2)+\cdots
$$

再由条件概率的定义，有 $P(AB_i)=P(B_i)P(A|B_i)$，代入上式得

$$
\begin{equation}
\tag{3.18}
P(A)=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+\cdots
\end{equation}
$$

公式 (3.18) 就称为**全概率公式**。这名称的来由，从 (3.18) 可以悟出：“全部”概率 $P(A)$ 被分解成了许多部分之和。它的理论和实用意义在于：在较复杂的情况下直接计算 $P(A)$ 不易，但 $A$ 总是随某个 $B_i$ 伴出，适当去构造这一组 $B_i$ 往往可以简化计算。

这个公式还可以从另一个角度去理解：把 $B_i$ 看作导致事件 $A$ 发生的一种可能途径。对于不同途径，$A$ 发生的概率即条件概率 $P(A|B)$ 各不相同，而采取哪种途径却是随机的。直观上容易理解：在这种机制下，$A$ 的综合概率 $P(A)$ 应在最小的 $P(A|B_i)$ 和最大的 $P(A|B_i)$ 之间，它应该是所有 $P(A|B_i)$ 以 $P(B_i)$ 为权重的加权平均。

**例 3.7** 设一个家庭有 $k$ 个小孩的概率为 $p_k,k=0,1,2,\cdots$，又设各个小孩的性别独立，且生男孩、女孩的概率各为 $1/2$。试求事件 $A=\{家庭中所有小孩为同一性别的概率\}$。

引入事件 $B_k=\{家庭中有 k 个小孩\}$，则 $B_0,B_1,\cdots$ 构成完备事件群，$P(B_k)=p_k$，现考虑 $P(A|B_k)$。约定当 $k=0$ 时其值为 1；若 $k\ge 1$，则 $k$ 个小孩性别全部相同有两种可能：全为男孩，概率为 $(1/2)^k$，全为女孩，概率也为 $(1/2)^k$。因

$$
P(A|B_k)=2(1/2)^k=1/2^{k-1},k\ge 1
$$

由全概率公式，得出

$$
P(A)=p_0+\sum_{k=1}^\infty p_k/2^{k-1}
$$

在全概率公式的假定之下，有

$$
\begin{equation}
\tag{3.19}
P(B_i|A)=P(AB_i)/P(A)=P(B_i)P(A|B_i)/\sum_jP(B_j)P(A|B_j)
\end{equation}
$$

这个公式就叫做**贝叶斯公式**，是概率论中的一个著名公式。

从形式推导上看，这个公式平淡无奇，它不过是条件概率定义与全概率公式的简单推论。其之所以著名，在于其现实以至哲理意义的解释上：先看 $P(B_i)$，它是在没有进一步信息（不知道事件 $A$ 是否发生）的情况下，人们对事件 $B_i$ 发生可能性大小的认识。现在有了新的信息（知道 $A$ 发生），人们对 $B_i$ 发生可能性大小有了新的评估。这种情况在日常生活中也是屡见不鲜：原以为不甚可能的一种情况，可以因为某种事件的发生而变得甚为可能，或者相反。贝叶斯公式从数量上刻画了这种变化。

如果我们把事件 $A$ 看成“结果”，而把事件 $B_i$ 看成导致结果的可能的“原因”，则可以形象地把全概率公式看成“由原因推结果”，而贝叶斯公式则恰好相反，其作用在于“由结果推原因”：现在结果 $A$ 已经发生，在众多可能的原因中，到底是哪一个导致了该结果？

由以上的讨论也不难看出此公式在统计上的作用。在统计学中，我们依靠收集的数据（相当于此处的事件 $A$）去寻找感兴趣的问题的答案。这是一个“由结果推原因”性质的过程，因而贝叶斯公式有用武之地。事实上，依托这个公式的思想发展了一整套统计推断方法，称为“贝叶斯统计”。

**例 3.8** 有三个盒子 $C_1,C_2,C_3$，各有 100 个球，其中 $C_1$ 含白球 80 个，红球 10 个，黑球 10 个；$C_2$ 为白 10、红 80、黑 10；$C_3$ 为白 10、红 10、黑 80。现从这三个盒子中随机地抽出一个，然后从抽出的盒子中随机地抽出一个球，结果抽出白球。问该白球是从 $C_i$ 盒子中抽出的可能性有多大？这里 $i=1,2,3$。

记 $B_i=\{抽出的为 C_i 盒\},i=1,2,3$，$A=\{抽出白球\}$，待求的是条件概率 $P(B_i|A)$，按假定有

$$
\displaylines{
P(B_1)=P(B_2)=P(B_3)=1/3\\
P(A|B_1)=0.8,P(A|B_2)=0.1,P(A|B_3)=0.1
}
$$

代入 (3.18)，算出

$$
P(B_1|A)=0.8,P(B_2|A)=0.1,P(B_3|A)=0.1
$$

**例 3.9** 设某种病毒在人口中的感染率为 0.03。当检查时，由于技术和操作不完善以及种种特殊原因，使感染者未必检出阳性，而未感染者也可能检出阳性，假定

$$
\displaylines{
P(阳性|感染)=0.99,P(阴性|感染)=0.99\\
P(阳性|未感染)=0.05,P(阴性|未感染)=0.95
}
$$

现设某人检出阳性，问他感染的概率是多少？

记 $B_1=\{感染\},B_2=\{未感染\},A=\{阳性\}$，则

$$
\displaylines{
P(B_1)=0.03,P(B_2)=0.97\\
P(A|B_1)=0.99,P(A|B_2)=0.05
}
$$

代入 (3.18)，算出

$$
P(B_1|A)=0.380
$$
