# 朴素贝叶斯和情感分类

许多语言处理任务都包含分类任务。本章我们将介绍朴素贝叶斯算法并将其应用到**文本分类（text categorization）**任务中。

我们聚焦于一种常见的文本分类任务：**情感分析（sentiment analysis）**，即作者都某个对象表达出正面或负面观点。互联网上对于电影、商品、餐厅等评价都包含了评价者的情感倾向，报纸上的社论等也包含了作者对于政治事件或人物的褒贬态度。提取消费者或公众的情感与从市场营销到政治学的多个领域密切相关。

最简单的情感分析任务是二分类，并且评价中的词就已经给出了很好的提示。考虑下列从电影和餐厅评价中提取的文本片段，词 `great`、`richly`、`awesome`、`pathetic`、`awful` 和 `ridiculously` 都是非常具有信息量的提示：

<pre>
​    + ...zany characters and richly applied satire, and some great plot twists
​    - It was pathetic. The worst part about it was the boxing scenes...
​    + ...awesome caramel sauce and sweet toasty almonds. I love this place!
​    - ...awful pizza and ridiculously overpriced...
</pre>

**垃圾邮件检测（spam detection）**是另一个重要的商业应用，其二分类模型为一封邮件贴上 `spam` 或 `not-spam` 的标签。许多词汇的特征和其他一些特征被用到，例如当邮件中包含类似“WITHOUT ANY COST”或“Dear Winner”这样的短语时，我们就有理由怀疑它。垃圾邮件检测任务是朴素贝叶斯在文本分类上最早的应用之一（Sahami et al.，1998）。

我们还会想要知道一段文本使用的是什么语言。例如，社交媒体上的文本可能使用了多种语言，我们需要针对不同的语言应用不同的处理。**语言识别（language id）**任务因此成为大部分语言处理流水线的第一步。相关的文本分类任务，例如**作者划归（thorship attribution）**（确定一段文本的作者），也与数字人文、社会科学和法律语言学密切相关。

另一个文本分类的经典任务是为一段文本贴上图书馆分类标签，这是信息检索的一个重要部分。实际上，朴素贝叶斯算法于 1961 年被发明就是为了学科分类任务。

分类在句子或者词级别的任务中也十分重要，例如我们已经见过的点号消歧义（period disambiguation）和分词都是分类任务。甚至语言模型本身就可以视作是一种分类：词汇表中的每个词都视作一类，因此预测下一个词相当于将上文划分到下一个词对应的类中。一个词性标注器负责将句子中的每一个词分类为名词、动词等。

总的来说，分类的目标就是取单次观测，提取出有用的特征，然后将该观测分类为若干个离散的类之一。

人为设定规则在 NLP 的分类任务中十分重要，许多领域中基于人工规则的分类器都是最先进 NLP 系统的重要部分。尽管如此，随着场景或数据随时间变化，人工规则也可能变得脆弱；对于一些任务，人可能想不出好的规则。因此语言处理中的大部分分类任务都由有监督机器学习完成。对于文本分类，我们用 $(d_1,c_1),\cdots,(d_N,c_N)$ 表示有监督学习的训练集，其中 $d_i$ 为文本，$c_i$ 为手工标注的正确类别，共 N 个样本。一个概率分类器（probabilistic classifier）还告诉我们文本属于各个类别的概率，这样一个完整的分布会为下游决策提供有用的信息；避免过早地做出离散的决定对于构建系统十分重要。

本章介绍的朴素贝叶斯算法和下一章介绍的逻辑回归算法分别代表了两种分类的思路：以朴素贝叶斯为代表的生成式（generative）分类器对一个类如何生成一些输入数据构建模型；给定一次观测，它返回的是最可能生成这次观测的类。区分式（discriminative）分类器学习输入数据的何种特征最有助于在可能的类别中进行区分。尽管区分式系统更加准确也因此更为常用，生成式分类器也仍然有自己的位置。

## 朴素贝叶斯分类器

朴素贝叶斯分类器在特征间相互作用的方式上做了简化，其想法源于**词袋（bag-of-words）**模型（见下图），即将一段文本简单地视作词加上频率：

![](https://i.loli.net/2020/12/28/asg6SXbzpKhrnyj.png)

朴素贝叶斯是一种概率分类器，即对于特定文本 $d$，从所有类别 $c\in C$ 中返回具有最大后验概率的类别 $\hat{c}$。我们使用帽子记号来表示“我们估计的正确类别”。

$$
\hat{c}=\arg\max_{c\in C} P(c|d)
$$

Mosteller and Wallace（1964）最早将贝叶斯推断应用于文本分类，其直观想法是将贝叶斯公式应用于计算上述条件概率：

$$
\hat{c}=\arg\max_{c\in C} P(c|d)=\arg\max_{c\in C} \frac{P(d|c)P(c)}{P(d)}=\arg\max_{c\in C} P(d|c)P(c)
$$

上式去掉分母的原因是文本是给定的，因此 $P(d)$ 是定值。于是后验概率被拆分为**先验概率（prior probability）** $P(c)$ 和**似然（likelihood）** $P(d|c)$ 的积。

!!! note "说明"
    我们将朴素贝叶斯称为生成式模型是因为我们可以将上式理解为关于一段文本是如何生成的隐含假设：首先从 $P(c)$ 采样一个类，然后从 $P(d|c)$ 采样以生成文本（其实我们可以想象，生成人工文本就是按照这一过程）。

尽管如此，上式还是难以直接计算，朴素贝叶斯分类器因此做了两个简化假定：

1. **词袋假定（bag of words assumption）**：词的位置不重要，词出现在任何位置的效果都一样。
2. **朴素贝叶斯假定（naive Bayes assumption）**：文本各个特征条件独立，即 $P(f_i|c)$ 独立，有：

    $$
    P(d|c)=P(f_1,f_2,\cdots,f_n|c)=P(f_1|c)\cdot P(f_2|c)\cdots P(f_n|c)
    $$

朴素贝叶斯分类器的最终计算公式如下：

$$
c_{NB}=\arg\max_{c\in C} P(c)\prod_{f\in F} P(f|c)=\arg\max_{c\in C} P(c)\prod_{i} P(w_i|c)
$$

与语言模型的计算类似，朴素贝叶斯的计算也都使用对数概率，以防止下溢和提高速度：

$$
c_{NB}=\arg\max_{c\in C}(\log P(c)+\sum_{i}\log P(w_i|c))
$$

上式也可以看作是多分类的（对于对数条件概率的）线性分类器。

## 训练朴素贝叶斯分类器

那么我们如何得到 $P(c)$ 和 $P(w_i|c)$？最直接的方法是最大似然估计法，即使用训练集上的频率作为概率：

$$
\displaylines{\hat{P}(c)=\frac{N_c}{N_{all}}\\
\hat{P}(w_i|c)=\frac{{\rm count}(w_i,c)}{\sum_{w\in V}{\rm count}(w,c)}
}
$$

其中词汇表 $V$ 是所有类别的所有文本的词汇表。

这种方法存在一个问题：设想我们正在尝试估计词“fantastic”的似然，给定类别为正面，但训练集中正面类别下的文本均不包含词 `fantastic`，反而是负面类别下有一个文本包含 `fantastic`（可能是讽刺？），此时计算有：

$$
\hat{P}({\rm fantastic}|{\rm positive})=\frac{{\rm count}({\rm fantastic,positive})}{\sum_{w\in V}{\rm count}(w,{\rm positive})}=0
$$

!!! note "说明"
    注意如果负面类别下的文本也均不包含词 `fantastic`，那么 `fantastic` 不会进入词汇表，该词将作为未知词处理。

既然朴素贝叶斯对所有似然求积，那么测试集有一个文本包含词 `fantastic` 将导致该文本属于正面的概率直接为 0，不管文本的其他部分如何。

最简单的解决方法依然是拉普拉斯平滑。尽管在语言模型中拉普拉斯平滑已经基本上被更复杂的平滑算法替代，但在朴素贝叶斯分类器中依然普遍使用：

$$
\hat{P}(w_i|c)=\frac{{\rm count}(w_i,c)+1}{\sum_{w\in V}({\rm count}(w,c)+1)}=\frac{{\rm count}(w_i,c)+1}{\sum_{w\in V}{\rm count}(w,c)+|V|}
$$

如果测试集中出现了不在词汇表中的词，即**未知词（unknown word）**，处理方法是直接从文本中删除该词。

此外，一些模型也选择完全忽略一类高频词，称为**停用词（stop word）**，如 `a`、`the` 等。既可以选择词汇表中频率最高的 10~100 个词作为停用词，也可以使用预定义的停用词表。然后直接移除掉训练集和测试集中出现的每一个停用词。但实践证明，在大部分文本分类应用下，使用停用词都无法改善模型效果，因此现在更常见的是不使用。

下面展示了朴素贝叶斯算法（使用拉普拉斯平滑）的完整流程：

![](https://i.loli.net/2020/12/28/ZE4TNDYLtp6gMV1.png)

## 示例

下面是一个训练和测试朴素贝叶斯模型（使用拉普拉斯平滑）的示例，样本分为正面和负面两类，从真实影评简化而来的训练集和测试集都非常迷你：

![](https://i.loli.net/2020/12/28/Y4tIlCWkvZ2NBRq.png)

计算类别的先验概率：

$$
P(-)=\frac{3}{5},\ P(+)=\frac{2}{5}\\
$$

测试文本中的 `with` 在训练集中未出现，直接删除；计算剩余词的似然：

$$
\displaylines{P({\rm predictable}|-)=\frac{1+1}{14+20},\ P({\rm predictable}|+)=\frac{0+1}{9+20}\\
P({\rm no}|-)=\frac{1+1}{14+20},\ P({\rm no}|+)=\frac{0+1}{9+20}\\
P({\rm fun}|-)=\frac{0+1}{14+20},\ P({\rm fun}|+)=\frac{1+1}{9+20}
}
$$

其中 14 为所有负面文本的长度之和，9 为所有正面文本的长度之和，20 为词汇表规模。由此计算后验：

$$
\displaylines{P(-)P(S|-)=\frac{3}{5}\cdot\frac{2\cdot2\cdot1}{34^3}=6.1\times 10^{-5}\\
P(+)P(S|+)=\frac{2}{5}\cdot\frac{1\cdot1\cdot2}{29^3}=3.2\times 10^{-5}
}
$$

因此预测测试文本为负面。

## 对情感分析进行优化

尽管标准的朴素贝叶斯算法可以很好地进行情感分析，一些小的改进仍然被普遍采用以提升表现。

首先，对于情感分析和一些其他的文本分类任务，一个词在文本中是否出现似乎要比这个词出现了多少次更加重要（也就是认为同一个词的反复使用不会产生太大影响）。因此一种改进方法是将一个文本中出现的所有词的词频设为 1，这种方法称为**二元多项式朴素贝叶斯（binary multinomial naive Bayes）**或**二元朴素贝叶斯（binary NB）**。实现方法是对于每个文本，移除所有重复出现的词。下面的示例中包含 4 个重映射到二元的文本，修改前后的计数显示在右边的表中。该示例没有使用拉普拉斯平滑，以使得差异更清晰。注意词的二元计数可以大于 1，只要它出现在多个文本中。

![](https://s2.loli.net/2022/12/02/I45ZjwShBE3mWQY.png)

第二个重要的改进是处理否定式。否定式可以让一个正面的句子完全翻转为负面，也可以反过来。一个情感分析中常用的简单的基线方法是：在文本归一化过程中，为否定式的 token（n't、not、no、never）之后的每一个词加上前缀 `NOT_`。这样，新形成的 `NOT_like`、`NOT_recommend` 这样的词就会更多地出现在负面文本中，从而与 `like`、`recommend` 区分开。

最后，在某些场景下我们可能没有足够的人工标记的训练数据来训练准确的朴素贝叶斯分类器，以至于模型无法使用词汇表的很多词来预测正面或负面的情感。在这种情况下我们可以借助外部的**情感词汇表（sentiment lexicon）**，其中各词汇都被预先标注了正面或负面的情感。4 个最流行的情感词汇表分别是 General Inquirer（Stone et al., 1966）、LIWC（Pennebaker et al., 2007）、the opinion lexicon of Hu and Liu（2004a）和 the MPQA Subjectivity Lexicon（Wilson et al., 2005）。

例如 MPQA Subjectivity Lexicon 包括 6885 个词，其中 2718 个正面的词，4912 个负面的词，每个词都标注了情感的强弱，下面是一些示例：

<pre>
​    + admirable, beautiful, confident, dazzling, ecstatic, favor, glee, great
​    -  awful, bad, bias, catastrophe, cheat, deny, envious, foul, harsh, hate
</pre>

在朴素贝叶斯分类器中使用这种词汇表的通常方法是增加两个特征：文本中被词汇表标记为正面/负面的总词数。如果我们有非常多的训练数据，并且测试数据与训练数据一致，仅使用这两个特征的效果不如使用所有词作为特征；但如果训练数据较少或者测试数据与训练数据有一些差别，仅使用这两个密集特征的泛化效果更好。

## 朴素贝叶斯应用于其他文本分类任务

在上一节中我们指出，朴素贝叶斯没有要求我们的分类器要把训练数据中的所有词都作为特征使用。实际上朴素贝叶斯中的特征可以表示文本的任何属性。

例如在垃圾邮件检测任务中，常用的方法并非将每一个词作为独立的特征，而是预定义一些可能出现的词和短语作为特征，并且还包含一些不纯粹是语言的特征。例如开源的 SpamAssassin 工具预定义了类似于 `one hundred percent guaranteed` 这样的短语、可疑的大数额金钱（使用正则表达式匹配）等作为特征，此外还包括一些其他特征：

* 发送地址有垃圾邮件发送记录
* HTML 的文本比例太低（相对于图片）
* HTML 有不平衡的 `<head>` 标签
* 邮件标题全是大写字母
* 声称收件人可能会被从名单中移除
* ……

而对于语言识别（language id）这样的任务，最有效的朴素贝叶斯特征并非词，而是**字符 n 元序列（character n-gram）**，例如二元序列（“zw”）、三元序列（“nya”、“ Vo”）、四元序列（“ie z”、“thei”）等，或者甚至是更简单的**字节 n 元序列（byte n-gram）**（直接使用生字节，而非 UTF-8 等解码之后的 Unicode 码点）。由于空格也算作一个字节，字节 n 元序列可以对关于词的开始和结束的统计信息进行建模。一个广泛使用的朴素贝叶斯模型 `langid.py`（Lui and Baldwin，2012）首先提取文本的所有长度 1-4 的字符 n 元序列，然后使用特征选择方法筛选最终的 7000 个最有信息量的特征。

语言识别模型在多语言文本上进行训练，例如维基百科或新闻网。为了保证这样的多语言文本正确反映了不同的地区、方言和社会经济阶层，模型也加入了许多语言的推特文本（同一语言还需要选择不同地区，这对于获取世界上的多种英语方言尤为重要）、圣经和可兰经的译本、俚语网站例如都市词典（Urban Dictionary）等等（Jurgens et al., 2017）。

## 朴素贝叶斯作为一种语言模型

正如我们在上一节所看到的，朴素贝叶斯可以使用任何类型的特征：词典、URL、电子邮件地址、网络特征、短语等等。但如果我们像上一节那样，仅使用单个词的特征，并且使用文本中的所有词，那么朴素贝叶斯和语言建模就有一个非常重要的相似性。具体地，一个朴素贝叶斯模型可以被视为一组类别特定的一元序列语言模型，即模型对于每一个类别都初始化一个一元序列语言模型。

既然朴素贝叶斯模型的似然为每一个词赋一个概率 $P(w|c)$，那么模型也可以为每一句话赋一个概率：

$$
P(s|c) = \prod_{i\in sentence} P(w_i|c)
$$

于是考虑一个分正面（+）和负面（-）两类并且有如下参数的朴素贝叶斯模型：

<img src="https://s2.loli.net/2022/12/04/EkXDxtLwzUIrJYi.png" style="zoom:50%;" />

这两列中的每一列都初始化了一个语言模型，可以为句子“I love this fun film”赋一个概率：

$$
\displaylines{P({\rm I love this fun film}|+)=0.1×0.1×0.01×0.05×0.1=0.0000005\\
P({\rm I love this fun film}|-)=0.2×0.001×0.01×0.005×0.1=0.000000001
}
$$

可以看到，正面模型为这个句子赋了一个更高的概率。注意这只是朴素贝叶斯模型的似然部分，一旦我们乘上先验之后，完整的贝叶斯模型可能就会做出一个完全不同的选择。

## 评估：精确率，召回率和F-值

要评估一个二分类模型，我们需要构建一个如下的**混淆矩阵（confusion matrix）**：

![](https://s2.loli.net/2022/12/04/wlQYAnhTRP53fWp.png)

**精确率（precision）**定义为：

$$
P=\frac{TP}{TP+FP}
$$

**召回率（recall）**定义为：

$$
R=\frac{TP}{TP+FN}
$$

**F 值（F-measure）**定义为：

$$
F=\frac{(1+\beta^2)PR}{\beta^2P+ R}
$$

$\beta$ 参数用于衡量精确率和召回率之间的相对重要性，主要基于应用的需求。当 $\beta=1$ 时，精确率和召回率被同等重视，F 值称为 F1 值，是精确率和召回率的调和平均数：

$$
F_1=\frac{2PR}{P+R}
$$

!!! note "说明"
    假定上述混淆矩阵中，阳性代表新型冠状病毒检测呈阳性，那么精确率可以适当牺牲而召回率一定要保证（因为隔离未患病的人代价较小而放走患病的人代价巨大）。

    假定上述混淆矩阵中，阳性代表邮件为垃圾邮件，那么精确率一定要保证而召回率可以适当牺牲（因为将正常邮件归入垃圾邮件的代价较大而将垃圾邮件归入正常邮件的代价较小）；若阳性代表邮件为正常邮件，则结论相反，召回率一定要保证而精确率可以适当牺牲。

    通过上面两个例子可以看到，精确率和召回率哪一个更重要取决于具体问题的具体形式。

!!! note "说明"
   F 值使用调和平均数（而不是算术平均数、几何平均数等）是因为这是一个相对保守的指标：两个值的调和平均数更接近于他们的较小值。

多分类情况下的精确率和召回率定义如下图：

![](https://i.loli.net/2020/12/28/o2BdK9bWU1J4nYf.png)

**宏平均（macroaveraging）**和**微平均（microaveraging）**的定义如下图：

![](https://i.loli.net/2020/12/28/XjdxBMm7kg98Nvw.png)

可以看到，微平均受高频类别（spam）的影响最大，而宏平均则一视同仁。应根据具体情况选择指标。

## 测试集和交叉验证*

## 统计显著性测试**
