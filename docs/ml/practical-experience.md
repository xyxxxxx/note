[toc]

# 实践经验

## 数据集

### 划分

确保训练集，验证集与测试集的划分是随机的：可以采用打乱数据集或随机抽样的任意一种方法实现。否则可能导致训练集、验证集和测试集的数据不对应于同一个问题。

测试是投入生产之前的一次模拟，相应地测试集就是一套模拟测试题。测试指标对于评估模型性能、进行比较竞赛等都具有非常重要的意义（反过来说，操纵数据也是一件非常容易的事情，但我们应当秉持负责任的态度完成这一过程）。在开始测试之前不应以任何方式窥探或使用测试集的数据，并且也不应频繁进行测试（以防止对于测试集产生过拟合）。应在建立并训练好一个模型且对其具有信心时进行测试，在此之前应使用验证集初步判断模型的性能以及拟合程度。

### 预处理

对于所有的预处理变换，都应该只在训练集上拟合，而不包含测试集（因为测试集的数据不应在测试之前被窥探或使用）。然后将这一变换同时应用于训练集和测试集。

#### one-hot 编码

如果类型属性包含大量可能的类型，那么对其进行 one-hot 编码将造成大量的输入特征，从而减慢训练或降低性能。如有可能，考虑量化该类型属性为数值特征，或者将其嵌入到低维空间。

### 归一化



## 过拟合与欠拟合

过拟合与欠拟合发生在几乎每个机器学习问题中，其来源于优化与泛化之间的矛盾。优化指训练模型以在训练集上有最好的表现（即拟合最好），而泛化指模型在从未见过的数据上的表现。我们的目标是好的泛化，但只能通过控制优化来间接控制泛化。

训练开始时，优化和泛化的方向是相同的：训练集的损失降低，验证集的损失也降低，此时称模型欠拟合；经过一些训练后，优化和泛化分道扬镳：训练集的损失降低，验证集的损失反而升高，此时称模型过拟合。

神经网络模型比较容易就能较好地拟合训练集，但是记住：真正的挑战是泛化，而非优化。

为了防止模型过拟合，最佳方案是**获取尽可能多的数据**，这会使模型自然地泛化更好。其次是限制模型的容量（参数数量），使其仅记忆一些最重要的模式。

### 降低网络规模

模型的容量不应过大，也不应过小。若过大，则模型将非常快地进入过拟合，且在整个过程中表现不稳定；若过小，则模型将非常慢地训练，甚至没有足够的拟合能力。

目前仅能凭经验确定层数和层规模。找到合适的模型的通常流程是从很少的层数和规模开始，逐渐增加层数和规模直到过拟合成为限制模型表现的主要原因。

### 正则化

正则化可以有效地限制参数的取值。

正则化会降低模型的拟合能力，意味着也降低模型的过拟合能力。

### 遗忘

遗忘会降低训练速度，但能够提高模型的拟合能力，同时降低模型的过拟合能力。

## 调参

这将是最耗费时间的一步：调整模型，训练，测试，再调整模型……直到模型的表现尽可能好。在这个过程中你应该尝试：

+ 增加遗忘
+ 增加或减少层数和层规模
+ 增加 L1 或 L2 正则化
+ 尝试不同的超参数
+ 回到特征工程

需要注意，如果多次使用同一个验证集，那么将导致模型也会对于这个验证集过拟合。

## 梯度爆炸与梯度消失

无论是梯度消失还是梯度爆炸，从本质上来讲都是因为梯度反向传播中的连乘效应。

前馈神经网络的梯度消失会造成前面层的参数无法更新；循环神经网络的梯度消失会造成前面层的隐状态不影响参数的更新。

梯度爆炸会造成参数剧烈变化，使得学习不稳定甚至中断。

## LSTM, GRU

如果将无用的特征拼接到输入向量中，可能不仅不能提高，反而会降低模型的效果。

