虽然神经网络具有非常强的表达能力，但是当应用神经网络模型到机器学习时依然存在一些难点问题。主要分为两大类：

1. 优化问题：深度神经网络的优化十分困难。首先，神经网络的损失函数是一个非凸函数，找到全局最优解通常比较困难；其次，深度神经网络的参数通常非常多，训练数据也比较大，因此也无法使用计算代价很高的二阶优化方法，而一阶优化方法的训练效率通常比较低。此外，深度神经网络存在梯度消失或爆炸问题，导致基于梯度的优化方法经常失效。

2. 泛化问题：由于深度神经网络的复杂度比较高，并且拟合能力很强，很容易在训练集上产生过拟合。因此在训练深度神经网络时，同时也需要通过一定的正则化方法来改进网络的泛化能力。

目前，研究者从大量的实践中总结了一些经验方法，在神经网络的表示能力、复杂度、学习效率和泛化能力之间找到比较好的平衡，并得到一个好的网络模型。

# 网络优化

网络优化是指寻找一个神经网络模型来使得经验（或结构）风险最小化的过程，包括模型选择以及参数学习等。深度神经网络是一个高度非线性的模型，其风险函数是一个非凸函数，因此风险最小化是一个非凸优化问题。此外， 深度神经网络还存在梯度消失和梯度爆炸问题。因此，深度神经网络的优化是一个具有挑战性的问题。

## 网络结构多样性

神经网络的种类非常多，比如卷积网络、循环网络、图网络等。不同网络的结构也非常不同，有些比较深，有些比较宽。不同参数在网络中的作用也有很大的差异，比如连接权重和偏置的不同，以及循环网络中循环连接上的权重和其他权重的不同。

由于网络结构的多样性，我们<u>很难找到一种通用的优化方法</u>。<u>不同优化方法在不同网络结构上的表现也有比较大的差异</u>。

此外，网络的超参数一般比较多，这也给优化带来很大的挑战。

## 高维变量的非凸优化

低维空间的非凸优化问题主要是存在一些局部最优点。基于梯度下降的优化方法会陷入局部最优点，因此在低维空间中非凸优化的主要难点是如何选择初始化参数和逃离局部最优点。深度神经网络的参数非常多，其参数学习是在非常高维空间中的非凸优化问题，其挑战和在低维空间中的非凸优化问题有所不同。

**鞍点**

在高维空间中，非凸优化的难点并不在于如何逃离局部最优点，而是如何逃离**鞍点(saddle point)** [Dauphin et al., 2014]。鞍点的梯度是 0 ，但是在一些维度上是极大值，在另一些维度上是极小值，如下图所示。

![](https://i.loli.net/2020/12/03/FiWPmMYr8VOf6Ja.png)

在高维空间中，**局部最小值(local minima)**要求在每一维度上都是最低点，这种概率非常低。假设网络有 10000 维参数，梯度为 0 的点（即**驻点(stationary point)**）在某一维上是局部最小值的概率为 $p$ （在一般的非凸问题中， $p\approx 0.5$ ），那么在整个参数空间中，驻点是局部最优点的概率是 $p^{10000}$，这种可能性非常小。也就是说，在高维空间中大部分驻点都是鞍点。

> 函数的海森矩阵在梯度为0的位置上的特征值全为正时，该函数得到局部最小值。根据随机矩阵理论，对于一个大的高斯随机矩阵来说，任一特征值是正或者是负的概率都是0.5 。

基于梯度下降的优化方法会在鞍点附近接近于停滞，很难从这些鞍点中逃离。因此，<u>随机梯度下降</u>对于高维空间中的非凸优化问题十分重要，通过<u>在梯度方向上引入随机性，可以有效地逃离鞍点</u>。

**平坦最小值**

深度神经网络的参数非常多，并且有一定的冗余性，这使得每单个参数对最终损失的影响都比较小，因此会导致损失函数在局部最小解附近通常是一个平坦的区域，称为**平坦最小值(flat minima)** [Hochreiter et al., 1997; Li et al., 2017a]。下图给出了平坦最小值和**尖锐最小值(sharp minima)**的示例。

![](https://i.loli.net/2020/12/03/pOBKqjsDebZMy4t.png)

在一个平坦最小值的邻域内，所有点对应的训练损失都比较接近，表明我们在训练神经网络时<u>不需要精确地找到一个局部最小解</u>，只要在一个局部最小解的邻域内就足够了。平坦最小值通常被认为和模型泛化能力有一定的关系，一般而言，当一个模型收敛到一个平坦的局部最小值时，其鲁棒性会更好，即微小的参数变动不会剧烈影响模型能力；而当一个模型收敛到一个尖锐的局部最小值时，其鲁棒性也会比较差。具备良好泛化能力的模型通常应该是鲁棒的，因此<u>理想的局部最小值应该是平坦的</u>。

> 这里的很多描述都是经验性的，并没有很好的理论证明。

**局部最小解的等价性**

在非常大的神经网络中，大部分的局部最小解是等价的，它们在测试集上性能都比较相似。此外，<u>局部最小解对应的训练损失都可能非常接近于全局最小解对应的训练损失</u> [Choromanska et al., 2015] 。虽然神经网络有一定概率收敛于比较差的局部最小值，但随着网络规模增加，网络陷入比较差的局部最小值的概率会大大降低。在训练神经网络时，我们通常没有必要找全局最小值，这反而可能导致过拟合。

## 神经网络优化的改善方法

改善神经网络优化的目标是找到更好的局部最小值和提高优化效率，目前比较有效的经验性改善方法通常分为以下几个方面：

1. 使用更有效的<u>优化算法</u>来提高梯度下降优化方法的效率和稳定性，比如动态学习率调整、 梯度估计修正等。
   
2. 使用更好的<u>参数初始化方法</u>、 <u>数据预处理方法</u>来提高优化效率。
   
3. 修改网络结构来得到更好的**优化地形(optimization landscape)**， 比如使用 ReLU 激活函数、残差连接、<u>逐层归一化</u>等。

4. 使用更好的<u>超参数优化方法</u>。

通过上面的方法，我们通常可以高效地、端到端地训练一个深度神经网络。

# 优化算法

目前，深度神经网络的参数学习主要是通过梯度下降法来寻找一组可以最小化结构风险的参数。在具体实现中，梯度下降法可以分为：批量梯度下降、随机梯度下降以及小批量梯度下降三种形式。根据不同的数据量和参数量，可以选择一种具体的实现形式。这里介绍一些在训练神经网络时常用的优化算法，这些优化算法大体上可以分为两类：(1) 调整学习率, 使得优化更稳定；(2) 梯度估计修正，优化训练速度。

## 小批量梯度下降

在训练深度神经网络时，训练数据的规模通常都比较大。如果在梯度下降时，每次迭代都要计算整个训练数据上的梯度，这就需要比较多的计算资源。另外大规模训练集中的数据通常会非常冗余，也没有必要在整个训练集上计算梯度。因此在训练深度神经网络时，经常使用**小批量梯度下降法(mini-batch gradient descent)**。

令 $f(\pmb x;\pmb \theta)$ 表示一个深度神经网络， $\pmb \theta$ 为网络参数，在使用小批量梯度下降进行优化时，每次选取 $K$ 个训练样本 $\mathcal{S}_t=\{(\pmb x)^{(k)},(\pmb y)^{(k)} \}_{k=1}^K$，第 $t$ 次**迭代(iteration)**时损失函数关于参数 $\theta$ 的偏导数为
$$
g_t(\pmb \theta)=\frac{1}{K}\sum_{(\pmb x,\pmb y)\in \mathcal{S}_t}\frac{\partial \mathcal{L}(\pmb y, f(\pmb x;\pmb \theta))}{\partial \pmb \theta}\\
=\frac{\partial \frac{1}{K}\sum_{(\pmb x,\pmb y)\in \mathcal{S}_t} \mathcal{L}(\pmb y, f(\pmb x;\pmb \theta))}{\partial \pmb \theta}
$$
其中 $\mathcal{L}(\cdot)$ 为可微分的损失函数， $K$ 为**批量大小(batch size)**。

使用梯度下降来更新参数
$$
\pmb \theta_t \leftarrow \pmb \theta_{t-1}-\alpha g_t(\pmb \theta_{t-1})
$$
其中 $\alpha>0$ 为学习率。

从上面公式可以看出，影响小批量梯度下降法的主要因素有：

1. 批量大小 $K$ 

2. 学习率 $α$ 

3. 梯度估计 $g_t(\pmb \theta)$ 

为了更有效地训练深度神经网络，在标准的小批量梯度下降法的基础上，也经常使用一些改进方法以加快优化速度，比如如何选择批量大小、 如何调整学习率以及如何修正梯度估计。我们分别从这三个方面来介绍在神经网络优化中常用的算法。这些改进的优化算法也同样可以应用在批量或随机梯度下降法上。

## 批量大小选择

在小批量梯度下降法中，**批量大小(batch size)**对网络优化的影响也非常大。一般而言，批量大小不影响随机梯度的期望，但是会影响随机梯度的方差。<u>批量大小越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定</u>，因此可以设置较大的学习率；而批量大小较小时，需要设置较小的学习率，否则模型会不收敛。<u>学习率通常要随着批量大小的增大而相应地增大</u>。一个简单有效的方法是**线性缩放规则(Linear Scaling Rule)** [Goyal et al., 2017] ：当批量大小增加 $m$ 倍时，学习率也增加 $m$ 倍。线性缩放规则往往<u>在批量大小比较小时适用</u>，当批量大小非常大时，线性缩放会使得训练不稳定。

下图给出了从**回合(epoch)**和迭代(iteration)的角度，批量大小对损失下降的影响。每一次小批量更新为一次迭代，所有训练集的样本更新一遍为一个回合，两者的关系为
$$
1\ {\rm epoch}=\frac{训练集的样本数 N}{批量大小K}\ {\rm iteration}
$$
![](https://i.loli.net/2020/12/03/Wbasgt3SI476yHm.png)

从左图可以看出，按迭代数来看，批量大小越大，下降效果越明显，并且下降曲线越平滑；但从右图可以看出，按回合数来看，适当小的批量大小会导致更快的收敛。

此外，批量大小和模型的泛化能力也有一定的关系。 [Keskar et al., 2016] 通过实验发现：批量越大，越有可能收敛到尖锐最小值；批量越小，越有可能收敛到平坦最小值。

## 学习率调整

学习率是神经网络优化时的重要超参数。在梯度下降法中，学习率 $α$ 的取值非常关键，如果过大就会不收敛，如果过小则收敛速度太慢。常用的学习率调整方法包括学习率衰减、学习率预热、周期性学习率调整以及一些自适应调整学习率的方法，比如AdaGrad、RMSprop、AdaDelta等。自适应学习率方法可以针对每个参数设置不同的学习率。

### 学习率衰减

从经验上看，学习率在<u>一开始要保持大些来保证收敛速度</u>，<u>在收敛到最优点附近时要小些以避免来回振荡</u>。比较简单的学习率调整可以通过**学习率衰减(learning rate decay)**的方式来实现，也称为**学习率退火(learning rate annealing)**。

不失一般性，这里的衰减方式设置为按迭代次数进行衰减。

假设初始化学习率为 $α_0$，在第 $t$ 次迭代时的学习率 $α_t$。常见的衰减方法有以下几种：

**分段常数衰减(piecewise constant decay)**：即每经过 $T_1, T_2 , ⋯ , T_m$ 次迭代将学习率衰减为原来的 $β_1, β_2, ⋯, β_m$ 倍，其中 $T_m$ 和 $β_m < 1$ 为根据经验设置的超参数。分段常数衰减，也称为**阶梯衰减(step decay)**。

**逆时衰减(inverse time decay)**：
$$
\alpha_t = \alpha_0\frac{1}{1+\beta t}
$$
其中 $\beta$ 为衰减率。

**指数衰减(exponential decay)**：
$$
\alpha_t=\alpha_0\beta^t
$$
其中 $\beta<1$ 为衰减率。

**余弦衰减(cosine decay)**：
$$
\alpha_t=\frac{1}{2}\alpha_0(1+\cos(\frac{t\pi}{T}))
$$
其中 $T$ 为总的迭代次数。

下图给出了不同衰减方法的示例（假设初始学习率为1）。

![](https://i.loli.net/2020/12/03/NeS3MkR25idKxAZ.png)

### 学习率预热

在小批量梯度下降法中，当批量大小的设置比较大时，通常需要比较大的学习率。但在刚开始训练时，由于参数是随机初始化的，梯度往往也比较大，再加上比较大的初始学习率，会使得训练不稳定。

> 参数更新差值 $\Delta\pmb \theta_t=-\alpha g_t(\pmb \theta)$，刚开始训练时梯度可能非常大，乘以较大的初始学习率可能导致参数更新差值远大于参数本身。

为了提高训练稳定性，我们可以在最初几轮迭代时，采用比较小的学习率，等梯度下降到一定程度后再恢复到初始的学习率，这种方法称为**学习率预热(learning rate warmup)**。

一个常用的学习率预热方法是逐渐预热(gradual warmup) [Goyal et al.,2017] 。假设预热的迭代次数为 $T′$，初始学习率为 $α_0$，在预热过程中，每次更新的学习率为
$$
\alpha_t'=\frac{t}{T'}\alpha_0,\quad 1\le t\le T'
$$
当预热过程结束，再选择一种学习率衰减方法来逐渐降低学习率。

### 周期性学习率调整

为了使得梯度下降法能够逃离鞍点或尖锐最小值，一种经验性的方式是在训练过程中周期性地增大学习率。<u>当参数处于尖锐最小值附近时，增大学习率有助于逃离尖锐最小值；当参数处于平坦最小值附近时，增大学习率依然有可能在该平坦最小值的**吸引域(basin of attraction)**内</u>。 因此，周期性地增大学习率虽然可能短期内损害优化过程，使得网络收敛的稳定性变差，但<u>从长期来看有助于找到更好的局部最优解</u>。

这里介绍两种常用的周期性调整学习率的方法：循环学习率和带热重启的随机梯度下降。

**循环学习率**

一种简单的方法是使用**循环学习率(cyclic learning rate)** [Goyal et al., 2017] ，即让学习率在一个区间内周期性地增大和缩小。通常可以使用线性缩放来调整学习率，称为**三角循环学习率(triangular cyclic learning rate)**。假设每个循环周期的长度相等都为 $2ΔT$，其中前 $ΔT$ 步为学习率线性增大阶段，后 $ΔT$ 步为学习率线性缩小阶段。在第 $t$ 次迭代时，其所在的循环周期数 $m$ 为
$$
m=\lfloor 1+\frac{t}{2\Delta T} \rfloor
$$
第 $t$ 次迭代的学习率为
$$
\alpha_t=\alpha_{\min}^{(m)}+(\alpha_{\max}^{(m)}-\alpha_{\min}^{(m)})(\max(0, 1-b))
$$
其中 $α^m_{\max}$ 和 $α_{\min}^m$ 分别为第 $m$ 个周期中学习率的上界和下界，可以随着 $m$ 的增大而逐渐降低； $b = |\frac{t}{\Delta T}-2m+1| ∈ [0, 1]$。

**带热重启的随机梯度下降**

**带热重启的随机梯度下降(Stochastic Gradient Descent with Warm Restarts , SGDR)** [Loshchilov et al., 2017a] 是用热重启方式来替代学习率衰减的方法。学习率每间隔一定周期后重新初始化为某个预先设定值，然后逐渐衰减。每次重启后模型参数不是从头开始优化，而是从重启前的参数基础上继续优化。

假设在梯度下降过程中重启 $M$ 次，第 $m$ 次重启在上次重启开始第 $T_m$ 个回合后进行， $T_m$ 称为重启周期。在第 $m$ 次重启之前，采用余弦衰减来降低学习率。第 $t$ 次迭代的学习率为
$$
\alpha_t=\alpha_{\min}^{(m)}+\frac{1}{2}(\alpha_{\max}^{(m)}-\alpha_{\min}^{(m)})(1+\cos(\frac{T_{cur}}{T_m}\pi))
$$
其中 $α^m_{\max}$ 和 $α_{\min}^m$ 分别为第 $m$ 个周期中学习率的上界和下界, 可以随着 $m$ 的增大而逐渐降低； $T_{cur}$ 为从上次重启之后的回合数；. 重启周期 $T_m$ 可以随着重启次数逐渐增加，比如 $T_m = T_{m−1} × κ$，其中 $κ ≥ 1$ 为放大因子。

下图给出了两种周期性学习率调整的示例（假设初始学习率为 1 ），每个周期中学习率的上界也逐步衰减。

![](https://i.loli.net/2020/12/03/brJsuW73wi1aQxP.png)

### AdaGrad 算法

在标准的梯度下降法中，每个参数在每次迭代时都使用相同的学习率。由于每个参数的维度上收敛速度都不相同，因此应根据不同参数的收敛情况分别设置学习率。

> 例如有的参数已经接近极小值，有的参数仍然梯度较大，分别应设置较小和较大的学习率。

**AdaGrad 算法(Adaptive Gradient Algorithm)** [Duchi et al., 2011] 是借鉴 $\ell_2$ 正则化的思想，每次迭代时自适应地调整每个参数的学习率。在第 $t$ 次迭代时，先计算每个参数梯度平方的累计值
$$
\pmb s_t = \sum_{\tau=1}^{t}\pmb g_\tau\odot\pmb g_\tau
$$

其中 $⊙$ 为逐元素乘法， $\pmb g_\tau ∈ \mathbb{R}^{|\pmb θ|}$ 是第 $τ$ 次迭代时的梯度。

AdaGrad 算法的参数更新差值为
$$
\Delta\pmb \theta_t=-\frac{\alpha}{\sqrt{\pmb s_t+\epsilon}}\odot\pmb g_t
$$
其中 $α$ 是初始的学习率， $ε$ 是为了保持数值稳定性而设置的非常小的常数，一般取值 $e^{−7}$ 到 $e^{−10}$。此外，这里的开方、除、加运算都是按元素进行的操作。

在 AdaGrad 算法中，如果<u>某个参数的偏导数累积比较大，其学习率相对较小</u>；相反，如果其<u>偏导数累积较小，其学习率相对较大</u>。但<u>整体是随着迭代次数的增加，学习率逐渐缩小</u>。

AdaGrad 算法的缺点是在<u>经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小</u>，很难再继续找到最优点。

### RMSprop 算法

RMSprop 算法是 Geoff Hinton 提出的一种自适应学习率的方法 [Tieleman et al., 2012] ，可以在有些情况下避免 AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点。

RMSprop 算法首先计算每次迭代梯度 $g_t(\pmb \theta)$ 平方的指数衰减移动平均，
$$
\pmb s_t = \beta \pmb s_{t-1}+(1-\beta)\pmb g_t\odot\pmb g_t\\
=(1-\beta)\sum_{\tau=1}^t\beta^{(t-\tau)}\pmb g_\tau\odot\pmb g_\tau
$$

其中 $\beta$ 为衰减率，一般取值为 0.9。

RMSprop 算法的参数更新差值为
$$
\Delta\pmb \theta_t=-\frac{\alpha}{\sqrt{\pmb s_t+\epsilon}}\odot\pmb g_t
$$
其中 $α$ 是初始的学习率，比如 0.001。

从上式可以看出，RMSProp 算法和 AdaGrad 算法的区别在于 $\pmb s_t$ 的计算由累积方式变成了指数衰减移动平均。在迭代过程中，每个参数的学习率并不是呈衰减趋势，既可以变小也可以变大。

> 在 RMSprop 算法中，如果某个参数的偏导数在一段时间内累积比较大，其学习率减小；相反，如果其偏导数在一段时间内累积较小，其学习率增大。

### AdaDelta 算法

AdaDelta 算法 [Zeiler, 2012] 也是 AdaGrad 算法的一个改进。和 RMSprop 算法类似，AdaDelta 算法通过梯度平方的指数衰减移动平均来调整学习率。此外，AdaDelta 算法还引入了每次参数更新差值 $Δ\pmb θ$ 的平方的指数衰减权移动平均，以替代学习率这一超参数。

第 $t$ 次迭代时，参数更新差值 $Δ\pmb θ$ 的平方的指数衰减权移动平均为
$$
\Delta \pmb x_{t-1} = \beta_1\Delta \pmb x_{t-2}+(1-\beta_1)\Delta\pmb \theta_{t-1}\odot\Delta\pmb \theta_{t-1}
$$
其中 $\beta_1$ 为衰减率。

AdaDelta 算法的参数更新差值为
$$
\Delta\pmb \theta_t=-\frac{\sqrt{\Delta \pmb x_{t-1}+\epsilon}}{\sqrt{\pmb s_t+\epsilon}}\odot\pmb g_t
$$
其中 $\pmb s_t$ 的计算方式和 RMSprop 算法一样， $\Delta \pmb x_{t-1}$ 为参数更新差值 $ Δ\pmb θ $ 的指数衰减权移动平均。

从上式可以看出，AdaDelta 算法将 RMSprop 算法中的初始学习率 $α$ 改为动态计算的 $\sqrt{\Delta \pmb x_{t-1}+\epsilon}$，在一定程度上<u>平抑了学习率的波动</u>。

> 在 AdaDelta 算法中，如果某个参数的变化在一段时间内累积比较大，其学习率增加；相反，如果其变化在一段时间内累积较小，其学习率减小。
>
> 所以分子和分母的综合效果是什么……

## 梯度估计修正

除了调整学习率之外，还可以进行**梯度估计(gradient estimation)**的修正。在小批量随机梯度下降法中，如果每次选取样本数量比较小，损失会呈现振荡的方式下降，也就是说随机梯度下降方法中每次迭代的梯度估计和整个训练集上的最优梯度并不一致，具有一定的随机性。一种有效地缓解梯度估计随机性的方式是通过<u>使用最近一段时间内的平均梯度来代替当前时刻的随机梯度来作为参数更新的方向，从而提高优化速度</u>。

> 增加批量大小也是一种缓解梯度估计随机性的方式。

### 动量法

**动量(momentum)**是模拟物理中的概念。一个物体的动量指的是该物体在它运动方向上保持运动的趋势，是该物体的质量和速度的乘积。**动量法(momentum method)**是用之前积累动量来替代真正的梯度，每次迭代的梯度可以看作<u>加速度</u>。

在第 $t$ 次迭代时，计算负梯度的“加权移动平均”作为参数的更新方向
$$
\Delta\pmb \theta_t = \rho\Delta\pmb \theta_{t-1}-\alpha g_t(\pmb \theta)\\
=-\alpha\sum_{\tau=1}^t\rho^{t-\tau} g_\tau(\pmb \theta)
$$
其中 $ρ$ 为动量因子，通常设为 0.9 ， $α$ 为学习率。

这样，每个参数的实际更新差值取决于<u>最近一段时间内梯度的加权平均值</u>。当某个参数在<u>最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小</u>；相反，当在<u>最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用</u>。一般而言，<u>在迭代初期，梯度方向都比较一致，动量法会起到加速作用，可以更快地到达最优点</u>；<u>在迭代后期，梯度方向会不一致，在收敛值附近振荡，动量法会起到减速作用，增加稳定性</u>。从某种角度来说，当前梯度叠加上部分的上次梯度，一定程度上可以近似看作二阶梯度。

### Nesterov 加速梯度

**Nesterov 加速梯度(Nesterov Accelerated Gradient, NAG)**是一种对动量法的改进 [Nesterov, 2013; Sutskever et al., 2013] ，也称为 Nesterov 动量法(Nesterov momentum)。

在动量法中，实际的参数更新方向 $Δ\pmb θ_t$ 为上一步的参数更新方向 $Δ\pmb θ_{t-1}$ 和当前梯度的反方向 $g_t(\pmb \theta_{t-1})$ 的叠加，这样将参数更新拆分为两步进行
$$
\hat{\pmb \theta}=\pmb θ_{t-1}+\rhoΔ\pmb θ_{t-1}\\
\pmb θ_t=\hat{\pmb \theta}-\alpha g_t(\pmb \theta_{t-1})
$$
对于第二步更新，更合理的更新方向应该为 $\hat{\pmb \theta}$ 上的梯度。因此修改后的更新方向为
$$
\Delta\pmb \theta_t = \rho\Delta\pmb \theta_{t-1}-\alpha g_t(\pmb \theta_{t-1}+\rho\Delta\pmb \theta_{t-1})
$$
下图给出了动量法和 Nesterov 加速梯度在参数更新时的比较。

![](https://i.loli.net/2020/12/03/rhLaXiAGmqveCuF.png)

### Adam 算法

**Adam 算法(Adaptive Moment Estimation Algorithm)** [Kingma et al., 2015] 可以看作<u>动量法和 RMSprop 算法的结合</u>，不但使用动量作为参数更新方向，而且可以自适应调整学习率。

Adam 算法一方面计算梯度平方 $g_t^2(\pmb \theta)$ 的指数加权平均（和 RMSprop 算法类似），另一方面计算梯度 $g_t(\pmb \theta)$ 的指数加权平均（和动量法类似）。
$$
\pmb m_t=\beta_1\pmb m_{t-1}+(1-\beta_1)g_t(\pmb \theta)\\
\pmb g_t=\beta_2\pmb g_{t-1}+(1-\beta_2)g_t(\pmb \theta)\odot g_t(\pmb \theta)
$$
其中 $β_1$ 和 $β_2$ 分别为两个移动平均的衰减率，通常取值为 $β_1 = 0.9, β_2 = 0.99$。我们可以把 $\pmb m_t$ 和 $\pmb g_t$ 分别看作梯度的均值（一阶矩）和未减去均值的方差（二阶矩）。

假设 $\pmb m_0 =\pmb 0,\pmb g_0 =\pmb 0$，那么在迭代初期 $\pmb m_t$ 和 $\pmb g_t$ 的值会比真实的均值和方差要小，特别是当 $β_1$ 和 $β_2$ 都接近于 1 时。因此需要对偏差进行修正
$$
\hat{\pmb m_t}=\frac{\pmb m_t}{1-\beta_1^t}\\
\hat{\pmb g_t}=\frac{\pmb g_t}{1-\beta_2^t}
$$
Adam 算法的参数更新差值为
$$
\Delta\pmb\theta_t=-\frac{\alpha}{\sqrt{\hat{\pmb g_t}+\epsilon}}\hat{\pmb m_t}
$$
其中学习率 $\alpha$ 通常设为 0.001，并且也可以进行衰减，比如 $\alpha_t=\alpha_0/\sqrt{t}$。

Adam 算法是 RMSProp 算法与动量法的结合，因此一种自然的 Adam 算法的改进方法是引入 Nesterov 加速梯度，称为 Nadam 算法 [Dozat, 2016]。

### 梯度截断

在深度神经网络或循环神经网络中，除了梯度消失之外，梯度爆炸也是影响学习效率的主要因素。在基于梯度下降的优化过程中，如果梯度突然增大，用大的梯度更新参数反而会导致其远离最优点。为了避免这种情况，当梯度的模大于一定阈值时，就对梯度进行截断，称为**梯度截断(gradient clipping)** [Pascanu et al., 2013]。

梯度截断是一种比较简单的启发式方法，把梯度的值限定在一个区间，当梯度的值小于或大于这个区间时就进行截断。一般截断的方式有以下几种：

**按值截断** 在第 $t$ 次迭代时，梯度为 $g_t(\pmb \theta)$，给定一个区间 $[a, b]$，如果一个参数的梯度小于 $a$ 时，就将其设为 $a$ ；如果大于 $b$ 时，就将其设为 $b$ 
$$
g_t(\pmb \theta)=\max(\min(g_t(\pmb \theta), b), a)
$$
**按模截断** 给定一个截断阈值 $b$，如果 $\|g_t(\pmb \theta)\|^2> b$，令
$$
g_t(\pmb \theta)=\frac{b}{\|g_t(\pmb \theta)\|}g_t(\pmb \theta)
$$
截断阈值 $b$ 是一个超参数，也可以根据一段时间内的平均梯度来自动调整。实验中发现，训练过程对阈值 $b$ 并不十分敏感，通常一个小的阈值就可以得到很好的结果 [Pascanu et al., 2013]。

## 优化算法比较

![](https://img-blog.csdn.net/20180426130002689)

![](https://img-blog.csdn.net/20180426113728916)

![](https://img-blog.csdn.net/20180425221525155)

# 参数初始化

神经网络的参数学习是一个非凸优化问题。当使用梯度下降法来进行优化网络参数时，参数初始值的选取十分关键，关系到网络的优化效率和泛化能力。参数初始化的方式通常有以下三种：

1. 预训练初始化：不同的参数初始值会收敛到不同的局部最优解。虽然这些局部最优解在训练集上的损失比较接近，但是它们的泛化能力差异很大。一个好的初始值会使得网络收敛到一个泛化能力高的局部最优解。通常情况下，一个已经在大规模数据上训练过的模型可以提供一个好的参数初始值, 这种初始化方法称为**预训练初始化(pre-trained initialization)**。

   > 预训练初始化通常会提升模型泛化能力的一种解释是预训练任务起到一定的正则化作用。

   预训练任务可以为监督学习或无监督学习任务。由于无监督学习任务更容易获取大规模的训练数据，因此被广泛采用。预训练模型在目标任务上的学习过程也称为**精调(fine-tuning)**。

2. 随机初始化：在线性模型的训练（比如感知器和 Logistic 回归）中， 我们一般将参数全部初始化为 0 。但是这在神经网络的训练中会存在一些问题，因为如果参数都为 0 ，第一遍前向计算时，所有的隐藏层神经元的激活值都相同；在反向传播时，所有权重的更新也都相同，这样会导致隐藏层神经元没有区分性，这种现象也称为<u>对称权重</u>现象。为了打破这个平衡，比较好的方式是对每个参数都**随机初始化(random initialization)**，使得不同神经元之间的区分性更好。

3. 固定值初始化：对于一些特殊的参数，我们可以根据经验用一个特殊的固定值来进行初始化。比如偏置(bias)通常用 0 来初始化，但是有时可以设置某些经验值以提高优化效率。在 LSTM 网络的遗忘门中，偏置通常初始化为 1 或 2 ，使得时序上的梯度变大。对于使用 ReLU 的神经元，有时也可以将偏置设为0.01 ，使得 ReLU 神经元在训练初期更容易激活，从而获得一定的梯度来进行误差反向传播。

虽然预训练初始化通常具有更好的收敛性和泛化性，但是灵活性不够，不能在目标任务上任意地调整网络结构。因此，好的随机初始化方法对训练神经网络模型来说依然十分重要。这里我们介绍三类常用的随机初始化方法：基于固定方差的参数初始化、基于方差缩放的参数初始化和正交初始化方法。

## 基于固定方差的参数初始化

一种最简单的随机初始化方法是从一个固定均值（通常为 0）和方差 $σ^2$ 的分布中采样来生成参数的初始值。基于固定方差的参数初始化方法主要有以下两种：

1. 高斯分布初始化：使用高斯分布 $N(0, σ^2)$ 对每个参数进行随机初始化。
2. 均匀分布初始化：使用区间 $[−r, r]$ 上的均匀分布对每个参数进行随机初始化。方差 $\sigma^2$ 对应的 $r$ 的取值为 $r=\sqrt{3\sigma^2}$。

在基于固定方差的随机初始化方法中，比较关键的是如何设置方差 $σ^2$。如果参数范围取的太小，一是会<u>导致神经元的输出过小</u>，经过多层之后信号就慢慢消失了，二是还会<u>使得 Sigmoid 型激活函数丢失非线性的能力</u>，以 Sigmoid 型函数为例，在 0 附近基本上是近似线性的，这样多层神经网络的优势也就不存在了。如果参数范围取的太大，会<u>导致输入状态过大，对于 Sigmoid 型激活函数来说，激活值变得饱和，梯度接近于 0 ，从而导致梯度消失问题</u>。

为了降低固定方差对网络性能以及优化效率的影响，基于固定方差的随机初始化方法一般需要配合逐层归一化来使用。

## 基于方差缩放的参数初始化

要高效地训练神经网络，给参数选取一个合适的随机初始化区间是非常重要的。一般而言，参数初始化的区间应该根据神经元的性质进行差异化的设置。如果一个神经元的输入连接很多，它的每个输入连接上的权重就应该小一些，以避免神经元的输出过大（当激活函数为 ReLU 时）或过饱和（当激活函数为Sigmoid 函数时）。

初始化一个深度网络时，为了缓解梯度消失或爆炸问题，我们尽可能保持每个神经元的输入和输出的方差一致，根据神经元的连接数量来自适应地调整初始化分布的方差，这类方法称为**方差缩放(variance scaling)**。

### Xavier 初始化

![](https://i.loli.net/2020/09/15/Yi1LzNP5mfGgCaH.png)

假设在一个神经网络中，第 $l$ 层的一个神经元 $a^{(l)}$，其接收前一层的 $M_{l−1}$ 个神经元的输出 $a_i^{(l-1)}$， $1\le i\le M_{l-1}$，
$$
a^{(l)}=f(\sum_{i=1}^{M_{l-1}}w_i^{(l)}a_i^{(l-1)})
$$
其中 $f(\cdot)$ 为激活函数， $w_i^{(l)}$ 为参数， $M_{l−1}$ 为 $l-1$ 层神经元个数。为简单起见，这里令激活函数 $f(\cdot)$ 为恒等函数。

假设 $w_i^{(l)}$ 和 $a_i^{(l-1)}$ 各服从均值为0的独立同分布，则 $a^{(l)}$ 的均值为
$$
E(a^{(l)})=E(\sum_{i=1}^{M_{l-1}}w_i^{(l)}a_i^{(l-1)})=\sum_{i=1}^{M_{l-1}}E(w_i^{(l)})E(a_i^{(l-1)})=0
$$
$a^{(l)}$ 的方差为
$$
Var(a^{(l)})=Var(\sum_{i=1}^{M_{l-1}}w_i^{(l)}a_i^{(l-1)})=\sum_{i=1}^{M_{l-1}}Var(w_i^{(l)})Var(a_i^{(l-1)})\\
=M_{l-1}Var(w_i^{(l)})Var(a_i^{(l-1)})
$$

> 对于相互独立的随机变量 $X,Y$ 
> $$
> Var(X+Y)=Var(X)+Var(Y)\\
> Var(XY)=E^2(X)Var(Y)+E^2(Y)Var(X)+Var(X)Var(Y)
> $$

也就是说，输入信号的方差在经过该神经元后放大或缩小为 $M_{l-1}Var(w_i^{(l)})$ 倍。为了使得在经过多层网络后，信号不被过分放大或过分减弱，我们尽可能保持每个神经元的输入和输出的方差一致，这样 $M_{l-1}Var(w_i^{(l)})$ 设为1比较合理，即
$$
Var(w_i^{(l)}) = \frac{1}{M_{l-1}}
$$
同理，为了使得在反向传播中，误差信号也不被放大或缩小，需要将 $w_i$ 的方差保持为
$$
Var(w_i^{(l)}) = \frac{1}{M_{l}}
$$
作为折中，同时考虑信号在前向和反向传播中都不被放大或缩小，可以设置
$$
Var(w_i^{(l)}) = \frac{2}{M_{l-1}+M_{l}}
$$
在计算出参数的理想方差后，可以通过高斯分布或均匀分布来随机初始化参数。若采用高斯分布来随机初始化参数，连接权重 $w_i$ 可以按 $N(0, \frac{2}{M_{l-1}+M_{l}})$ 的高斯分布进行初始化；若采用区间为 $[−r, r]$ 的均分分布来初始化 $w_i$，则 $r$ 的取值为 $\sqrt{\frac{6}{M_{l-1}+M_{l}}}$。这种根据每层的神经元数量来自动计算初始化参数方差的方法称为 **Xavier 初始化** [Glorot et al., 2010]。

虽然在 Xavier 初始化中我们假设激活函数为恒等函数，但是 Xavier 初始化也适用于 Logistic 函数和 Tanh 函数。这是因为神经元的参数和输入的绝对值通常比较小，处于激活函数的线性区间，这时 Logistic 函数和 Tanh 函数可以近似为线性函数。由于 Logistic 函数在线性区间的斜率约为 0.25 ，因此其参数初始化的方差约为 $16×\frac{2}{M_{l-1}+M_{l}}$。在实际应用中，使用 Logistic 函数或 Tanh 函数的神经层通常将方差 $\frac{2}{M_{l-1}+M_{l}}$ 乘以一个缩放因子 $\rho$， $\rho$ 根据经验进行设定。

### He初始化

当第 $l$ 层神经元使用 ReLU 激活函数时，通常有一半的神经元输出为 0 ，因此其分布的方差也近似为使用恒等函数时的一半。这样，只考虑前向传播时，参数 $w_i^{(l)}$ 的理想方差为
$$
Var(w_i^{(l)}) = \frac{2}{M_{l-1}}
$$
因此当使用 ReLU 激活函数时，若采用高斯分布来初始化参数 $w_i^{(l)}$，其方差为 $\frac{2}{M_{l-1}}$ ；若采用区间为 $[−r, r]$ 的均匀分布来初始化参数 $w_i^{(l)}$，则 $r=\sqrt{\frac{6}{M_{l-1}}}$。这种初始化方法称为 **He 初始化** [He et al., 2015] 。

下表给出了 Xavier 初始化和 He 初始化的具体设置情况。

![](https://i.loli.net/2020/12/03/I6DnxtC23blU7BP.png)

## 正交初始化

上面介绍的两种基于方差的初始化方法都是对权重矩阵中的每个参数进行独立采样。由于采样的随机性，采样出来的权重矩阵依然可能存在梯度消失或梯度爆炸问题。

假设一个 $L$ 层的等宽线性网络（激活函数为恒等函数）为
$$
\pmb y=W^{(L)}\cdots W^{(1)}\pmb x
$$
其中 $W^{(l)} ∈\mathbb{R}^{M×M}\ (1 ≤ l ≤ L)$ 为神经网络的第 $l$ 层权重矩阵。在反向传播中，误差项 $\pmb\delta$ 的反向传播公式为 $\pmb \delta^{(l-1)}=W^{(l){\rm T}}\pmb \delta^{(l)}$。为了避免梯度消失或梯度爆炸问题，我们希望误差项在反向传播中具有**范数保持性(norm-preserving)**，即 $\|\pmb \delta^{(l-1)}\|^2=\|W^{(l){\rm T}}\pmb \delta^{(l)}\|^2=\|\pmb \delta^{(l)}\|^2$。

一种保证范数保持性的方式是将 $W^{(l)}$ 初始化为正交矩阵，这种方法称为**正交初始化(orthogonal initialization)** [Saxe et al., 2014] 。正交初始化的具体实现过程可以分为两步： 1）用均值为 0 、方差为 1 的高斯分布初始化一个矩阵； 2）将这个矩阵用奇异值分解得到两个正交矩阵，并使用其中之一作为权重矩阵。

根据正交矩阵的性质，这个线性网络在信息的前向传播过程和误差的反向传播过程中都具有范数保持性，从而可以避免在训练开始时就出现梯度消失或梯度爆炸现象。

当在非线性神经网络中应用正交初始化时，通常需要将正交矩阵乘以一个缩放系数 $ρ$。比如当激活函数为 ReLU 时，为了保持范数不变，缩放系数 $ρ$ 可以设置为 $\sqrt{2}$。

# 数据预处理

一般而言，样本特征由于来源以及度量单位不同，它们的**尺度(scale)**（即取值范围）往往差异很大。以描述长度的特征为例，当用 “米” 作单位时令其值为 $x$，那么当用 “厘米” 作单位时其值为 $100x$。不同机器学习模型对数据特征尺度的敏感程度不一样，如果一个机器学习算法在缩放全部或部分特征后不影响它的学习和预测，我们就称该算法具有**尺度不变性(scale invariance)**，比如线性分类器是尺度不变的，而最近邻分类器就是尺度敏感的。当我们计算不同样本之间的欧氏距离时，尺度大的特征会起到主导作用。因此对于尺度敏感的模型，<u>必须先对样本进行预处理，将各个维度的特征转换到相同的取值区间</u>，并且消除不同特征之间的相关性，才能获得比较理想的结果。

从理论上，神经网络应该具有尺度不变性，可以通过参数的调整来适应不同特征的尺度，但尺度不同的输入特征会增加训练难度。假设一个只有一层的网络 $y = {\rm tanh}(w_1 x_1 + w_2 x_2 + b)$，其中 $x_1∈ [0, 10] , x_2 ∈ [0, 1]$。之前我们提到 tanh 函数的导数在区间 $[−2, 2]$ 上是敏感的，其余的导数接近于 0 。因此，如果 $w_1 x_1 + w_2 x_2 + b$ 过大或过小，都会导致梯度过小，难以训练。为了提高训练效率，我们需要使 $w_1 x_1 + w_2 x_2 + b$ 在 $[−2, 2]$ 区间，因此需要将 $w_1$ 设得小一点，比如在 $[−0.1, 0.1]$ 之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数。因此，如果每一个特征的尺度相似，比如 $[0, 1]$ 或者 $[−1, 1]$，我们就不太需要区别对待每一个参数，从而减少人工干预。

除了参数初始化比较困难之外，不同输入特征的尺度差异比较大时，梯度下降法的效率也会受到影响。下图给出了数据归一化对梯度的影响，其中，左图为未归一化数据的等高线图。尺度不同会造成在大多数位置上的梯度方向并不是最优的搜索方向，当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛。如果我们把数据归一化为相同尺度，如右图所示，大部分位置的梯度方向近似于最优搜索方向。这样在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高。

![](https://i.loli.net/2020/12/03/et3lCVqFQJR7NvO.png)

**归一化(normalization)**方法泛指把数据特征转换为相同尺度的方法，比如把数据特征映射到 $[0, 1]$ 或 $[−1, 1]$ 区间内，或者映射为服从均值为 0 、方差为 1的标准正态分布。归一化的方法有很多种，比如之前我们介绍的 Sigmoid 型函数等都可以将不同尺度的特征挤压到一个比较受限的区间。这里，我们介绍几种在神经网络中经常使用的归一化方法。

**最小最大值归一化**

**最小最大值归一化(min-max normalization)**是一种非常简单的归一化方法，通过缩放将每一个特征的取值范围归一到 $[0, 1]$ 或 $[−1, 1]$ 之间。假设有 $N$ 个样本 $\{\pmb x^{(n)}\}_{n=1}^N$，对于每一维特征 $x$，归一化后的特征为
$$
\hat{x}=\frac{x-\min(x^{(n)})}{\max(x^{(n)})-\min(x^{(n)})}
$$
其中 $\min(x^{(n)})$ 和 $\max(x^{(n)})$ 分别是特征 $x$ 在所有样本上的最小值和最大值。

**标准化**

**标准化(standardization)**也叫 **Z 值归一化(Z-score normalization)**，来源于统计上的标准分数，将每一个维特征都调整为均值为 0 ，方差为 1 。假设有 $N$ 个样本 $\{\pmb x^{(n)}\}_{n=1}^N$，对于每一维特征 $x$，我们先计算它的均值和方差：
$$
\mu = \frac{1}{N}\sum_{n=1}^N x^{(n)}\\
\sigma^2= \frac{1}{N}\sum_{n=1}^N (x^{(n)}-\mu)^2
$$
然后将特征 $x$ 减去均值，并除以标准差，得到新的特征值 $\hat{x}$ ：
$$
\hat{x}=\frac{x-\mu}{\sigma}
$$
**白化**

**白化(whitening)**是一种重要的预处理方法，用来降低输入数据特征之间的冗余性。输入数据经过白化处理后，特征之间相关性较低，并且所有特征具有相同的方差。白化的一个主要实现方式是使用**主成分分析(Principal Component Analysis, PCA)**方法去除掉各个成分之间的相关性。

下图给出了标准归一化和 PCA 白化的比较。

![](https://i.loli.net/2020/12/04/SXzYqMnO14I7dFv.png)

# 逐层归一化

**逐层归一化(layer-wise normalization)**是将传统机器学习中的数据归一化方法应用到深度神经网络中，对神经网络中隐藏层的输入进行归一化，从而使得网络更容易训练。

> 这里的逐层归一化方法是指可以应用在深度神经网络中的任何一个中间层，实际上并不需要对所有层进行归一化。

逐层归一化可以有效提高训练效率的原因有以下几个方面：

1. 更好的尺度不变性：在深度神经网络中，一个神经层的输入是之前神经层的输出。给定一个神经层 $l$，它之前的神经层 $(1, ⋯ , l − 1)$ 的参数变化会导致其输入的分布发生较大的改变。当使用随机梯度下降来训练网络时，<u>每次参数更新都会导致该神经层的输入分布发生改变</u>。越高的层，其输入分布会改变得越明显。从机器学习角度来看，<u>如果一个神经层的输入分布发生了改变，那么其参数需要重新学习</u>，这种现象叫作**内部协变量偏移(internal covariate shift)**。为了缓解这个问题，我们可以对每一个神经层的输入进行归一化操作，使其分布保持稳定。

   <u>把每个神经层的输入分布都归一化为标准正态分布，可以使得每个神经层对其输入具有更好的尺度不变性</u>。不论低层的参数如何变化，高层的输入保持相对稳定。另外，尺度不变性可以使得我们更加高效地进行参数初始化以及超参数选择。

2. 更平滑的优化地形：逐层归一化一方面可以使得大部分神经层的输入处于不饱和区域，从而让梯度变大，避免梯度消失问题；另一方面还可以使得神经网络的**优化地形(optimization landscape)**更加平滑，以及使梯度变得更加稳定，从而允许我们使用更大的学习率，并提高收敛速度 [Bjorck et al., 2018; Santurkar et al., 2018]。

> 优化地形指在高维空间中损失函数的曲面形状，好的优化地形通常比较平滑。

## 批量归一化

![](https://i.loli.net/2020/09/15/Yi1LzNP5mfGgCaH.png)

**批量归一化(Batch Normalization , BN)**方法 [Ioffe et al., 2015] 是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。

对于一个深度神经网络，令第 $l$ 层的净输入为 $\pmb z^{(l)}$，神经元的输出为 $\pmb a^{(l)}$，即
$$
\pmb a^{(l)}=f(\pmb z^{(l)})=f(W\pmb a^{(l-1)}+\pmb b)
$$
为了提高优化效率，就要使得净输入 $\pmb z^{(l)}$ 的分布一致，比如都归一化到标准正态分布。虽然归一化操作也可以应用在输入 $\pmb a^{(l-1)}$ 上，但归一化 $\pmb z^{(l)}$ 更加有利于优化。因此，在实践中归一化操作一般应用在仿射变换 $W\pmb a^{(l-1)}+\pmb b$ 之后，激活函数之前。

利用前一节中介绍的数据预处理方法对进行归一化，相当于每一层都进行一次数据预处理，从而加速收敛速度。但是逐层归一化需要在中间层进行操作，要求效率比较高，因此复杂度比较高的白化方法就不太合适。为了提高归一
化效率，<u>一般使用标准化将净输入 $\pmb z^{(l)}$ 的每一维都归一到标准正态分布</u>。
$$
\hat{\pmb z}^{(l)}=\frac{\pmb z^{(l)}-E(\pmb z^{(l)})}{\sqrt{Var(\pmb z^{(l)})+\epsilon}}
$$
其中 $E(\pmb z^{(l)})$ 和 $Var(\pmb z^{(l)})$ 是指当前参数下， $\pmb z^{(l)}$ 的每一维在整个训练集上的期望和方差。因为目前主要的优化算法是基于小批量的随机梯度下降法，所以准确地计算 $\pmb z^{(l)}$ 的期望和方差是不可行的，因此 $\pmb z^{(l)}$ 的期望和方差通常用当前小批量样本集的均值和方差近似估计。

给定一个包含 $K$ 个样本的小批量样本集合，第 $l$ 层神经元的净输入 $\pmb z^{(1,l)},\cdots,\pmb z^{(K,l)}$ 的均值和方差为
$$
\pmb \mu_b = \frac{1}{K}\sum_{k=1}^K \pmb z^{(k,l)}\\
\pmb \sigma_b^2=\frac{1}{K}\sum_{k=1}^K(\pmb z^{(k,l)}-\pmb \mu_b)\odot(\pmb z^{(k,l)}-\pmb \mu_b)
$$
对净输入 $\pmb z^{(l)}$ 的标准归一化会使得其取值集中到 0 附近，如果使用 Sigmoid 型激活函数时，这个取值区间刚好是接近线性变换的区间，减弱了神经网络的非线性性质。因此为了使得归一化不对网络的表示能力造成负面影响，可以通过一个附加的缩放和平移变换改变取值区间。
$$
\hat{\pmb z}^{(l)}=\frac{\pmb z^{(l)}-\pmb \mu_b}{\sqrt{\pmb \sigma_b^2+\epsilon}}\odot\pmb \gamma + \pmb\beta\\
\triangleq {\rm BN}_{\pmb\gamma,\pmb\beta}(\pmb z^{(l)})
$$
其中 $\pmb γ$ 和 $\pmb β$ 分别代表缩放和平移的参数向量。从最保守的角度考虑，可以通过标准归一化的逆变换来使得归一化后的变量可以被还原为原来的值，即当 $\pmb γ =\sqrt{\pmb \sigma_b^2}, \pmb \beta=\pmb \mu_b$ 时， $\hat{\pmb z}^{(l)}=\pmb z^{(l)}$。

批量归一化操作可以看作一个特殊的神经层，加在每一层非线性激活函数之前，即
$$
\pmb a^{(l)}=f({\rm BN}_{\pmb\gamma,\pmb\beta}(\pmb z^{(l)}))=f({\rm BN}_{\pmb\gamma,\pmb\beta}(W\pmb a^{(l-1)}))
$$
其中因为批量归一化本身具有平移变换，所以仿射变换 $W\pmb a^{(l-1)}$ 不再需要偏置参数。

这里要注意的是，每次小批量样本的 $\pmb \mu_b$ 和方差 $\pmb \sigma_b^2$ 是净输入 $\pmb z^{(l)}$ 的函数，而不是常量。因此在计算参数梯度时需要考虑 $\pmb \mu_b$ 和 $\pmb \sigma_b^2$ 的影响。当训练完成时，用整个数据集上的均值 $μ$ 和方差 $σ$ 来分别代替每次小批量样本的 $\pmb \mu_b$ 和方差 $\pmb \sigma_b^2$。在实践中， $\pmb \mu_b$ 和 $\pmb \sigma_b^2$ 也可以用移动平均来计算。

值得一提的是，逐层归一化不但可以提高优化效率，还可以作为一种隐形的正则化方法。在训练时，神经网络对一个样本的预测不仅和该样本自身相关，也和同一批次中的其他样本相关。由于在选取批次时具有随机性，因此使得神经网络不会 “过拟合” 到某个特定样本，从而提高网络的泛化能力 [Luo et al., 2018] 。

> 批量归一化的提出动机是为了解决内部协方差偏移问题，但后来的研究者发现其主要优点是归一化会导致更平滑的优化地形 [Santurkar et al.,2018] 。

## 层归一化

批量归一化是对一个中间层的单个神经元进行归一化操作，因此要求小批量样本的数量不能太小，否则难以计算单个神经元的统计信息。此外，如果一个神经元的净输入的分布在神经网络中是动态变化的，比如循环神经网络，那么就无法应用批量归一化操作。

**层归一化(Layer Normalization, LN)** [Ba et al., 2016] 是和批量归一化非常类似的方法。和批量归一化不同的是，层归一化是对一个中间层的所有神经元进行归一化。

对于一个深度神经网络，令第 $l$ 层神经元的净输入为 $\pmb z^{(l)}$，其均值和方差为
$$
\mu^{(l)} = \frac{1}{M_l}\sum_{i=1}^{M_l} z_i^{(l)}\\
(\sigma^{(l)})^2 = \frac{1}{M_l}\sum_{i=1}^{M_l} (z_i^{(l)}-\mu^{(l)})^2
$$
其中 $M_l$ 为第 $l$ 层神经元的数量。

层归一化定义为
$$
\hat{\pmb z}^{(l)}=\frac{\pmb z^{(l)}-\mu^{(l)}}{\sqrt{(\sigma^{(l)})^2+\epsilon}}\odot\pmb \gamma + \pmb\beta\\
\triangleq {\rm LN}_{\pmb\gamma,\pmb\beta}(\pmb z^{(l)})
$$
其中 $\pmb γ$ 和 $\pmb β$ 分别代表缩放和平移的参数向量。

**循环神经网络中的层归一化**

层归一化可以应用在循环神经网络中，对循环神经层进行归一化操作。假设在时刻 $t$，循环神经网络的隐藏层为 $\pmb h_t$，其层归一化的更新为
$$
\pmb z_t = U \pmb h_{t-1}+W\pmb x_t\\
\pmb h_t= f({\rm LN}_{\pmb\gamma,\pmb\beta}(\pmb z_t))
$$
其中输入为 $\pmb x_t$ 为第 $t$ 时刻的输入， $U$ 和 $W$ 为网络参数。

在标准循环神经网络中，循环神经层的净输入一般会随着时间慢慢变大或变小，从而导致梯度爆炸或消失。而层归一化的循环神经网络可以有效地缓解这种状况。

层归一化和批量归一化整体上是十分类似的，差别在于归一化的方法不同。对于 $K$ 个样本的一个小批量集合 $Z^{(l)}=[\pmb z^{(1,l)},\cdots,\pmb z^{(K,l)}]$，层归一化是对矩阵 $Z^{(l)}$ 的每一列进行归一化，而批量归一化是对每一行进行归一化。一般而言，批量归一化是一种更好的选择。当小批量样本数量比较小时，可以选择层归一化。

## 权重归一化

> ？参数解耦是归一化吗？

**权重归一化(weight normalization)** [Salimans et al., 2016] 是对神经网络的连接权重进行归一化，通过再参数化(reparameterization)方法，将连接权重分解为长度和方向两种参数。假设第 $l$ 层神经元 $\pmb a^{(l)}=f(W\pmb a^{(l-1)}+\pmb b)$，我们将 $W$ 再参数化为
$$
\pmb w_i=\frac{g_i}{\|\pmb v_i\|}\pmb v_i,\quad 1\le i\le M_l
$$
其中 $\pmb w_i$ 表示权重 $W$ 的第 $i$ 行， $M_l$ 为神经元数量，参数 $g_i$ 代表 $\pmb w_i$ 的模， $\pmb v_i$ 代表 $\pmb w_i$。由此一个权重参数被拆分为两个。

由于在神经网络中权重经常是共享的，权重数量往往比神经元数量要少，因此权重归一化的开销会比较小。

## 局部响应归一化

**局部响应归一化(Local Response Normalization, LRN)** [Krizhevsky et al., 2012] 是一种受生物学启发的归一化方法，通常用在基于卷积的图像处理上。

……

> 参见[深度学习饱受争议的局部响应归一化(LRN)详解](https://blog.csdn.net/qq_27825451/article/details/88745034)

# 超参数优化

在神经网络中，除了可学习的参数之外，还存在很多超参数，这些超参数对网络性能的影响也很大。不同的机器学习任务往往需要不同的超参数，常见的超参数有以下三类：

1. 网络结构，包括神经元之间的连接关系、层数、每层的神经元数量、激活函数的类型等

2. 优化参数，包括优化方法、 学习率、 小批量的样本数量等

3. 正则化系数

**超参数优化(hyperparameter optimization, HPO)**主要存在两方面的困难：

1. 超参数优化是一个组合优化问题，无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法；
2. 评估一组超参数配置(configuration)的时间代价非常高，从而导致一些优化方法（比如演化算法(evolution algorithm)）需要相当大的计算资源。

假设一个神经网络中总共有 $K$ 个超参数，每个超参数配置表示为一个向量 $\pmb x ∈\mathcal{X}, \mathcal{X} ⊂\mathbb{R}^K$ 是超参数配置的取值空间。超参数优化的目标函数定义为 $f(\pmb x)∶\mathcal{X}→\mathbb{R}$， $f(\pmb x)$ 是衡量一组超参数配置 $\pmb x$ 效果的函数，一般设置为开发集
上的错误率。目标函数 $f(\pmb x)$ 可以看作一个黑盒(black-box)函数，不需要知道其具体形式。虽然在神经网络的超参数优化中， $f(\pmb x)$ 的函数形式已知，但 $f(\pmb x)$ 不是关于 $\pmb x$ 的连续函数，并且 $\pmb x$ 不同， $f(\pmb x)$ 的函数形式也不同，因此无法使用梯度下降等优化方法。

> 进一步了解HPO和NAS，请参考：
>
> [使用 NNI 内置 Tuner 进行超参数调优](https://github.com/microsoft/nni/blob/master/docs/zh_CN/Tuner/BuiltinTuner.md)
>
> [NNI 上的神经网络架构搜索](https://github.com/microsoft/nni/blob/master/docs/zh_CN/NAS/Overview.md)