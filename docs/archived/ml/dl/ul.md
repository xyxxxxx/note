**无监督学习(Unsupervised Learning , UL)**是指从无标签的数据中学习出一些有用的模式。无监督学习算法一般直接从原始数据中学习，不借助于任何人工给出标签或者反馈等指导信息。如果监督学习是建立输入-输出之间的映射关系，那么无监督学习就是发现隐藏的数据中的有价值信息，包括有效的特征、类别、结构以及概率分布等。

典型的无监督学习问题可以分为以下几类：

1. **无监督特征学习(unsupervised feature learning)**是从无标签的训练数据中挖掘有效的特征或表示。无监督特征学习一般用来进行降维、数据可视化或监督学习前期的数据预处理。
2. **概率密度估计(probabilistic density estimation)**简称密度估计，是根据一组训练样本来估计样本空间的概率密度。密度估计可以分为参数密度估计和非参数密度估计：参数密度估计是假设数据服从某个已知概率密度函数形式的分布（比如高斯分布），然后根据训练样本去估计概率密度函数的参数；非参数密度估计是不假设数据服从某个已知分布，只利用训练样本对密度进行估计，可以进行任意形状密度的估计。非参数密度估计的方法有直方图、核密度估计等。
3. **聚类(clustering)**是将一组样本根据一定的准则划分到不同的组（也称为**簇(cluster)**），一个比较通用的准则是组内样本的相似性要高于组间样本的相似性。常见的聚类算法包括 K-Means 算法、谱聚类等。

和监督学习一样，无监督学习方法也包含三个基本要素：模型、 学习准则和优化算法。无监督学习的准则非常多，比如最大似然估计、最小重构错误等。在无监督特征学习中，经常使用的准则为最小化重构错误，同时也经常对特征进行一些约束，比如独立性、非负性或稀释性等。而在密度估计中，经常采用最大似然估计来进行学习。

这里介绍两种无监督学习问题：无监督特征学习和概率密度估计。

# 无监督特征学习

无监督特征学习是指从无标注的数据中自动学习有效的数据表示，从而能够帮助后续的机器学习模型更快速地达到更好的性能。无监督特征学习主要方法有主成分分析、稀疏编码、自编码器等。

## 主成分分析

**主成分分析(Principal Component Analysis, PCA)**是一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。如图所示的两维数据，如果将这些数据投影到一维空间中，选择数据方差最大的方向进行投影，才能最大化数据的差异性，保留更多的原始数据信息。

![](https://i.loli.net/2020/12/03/923lZIUgGLVyaDK.png)

假设有一组 $D$ 维的样本 $\pmb x^{(n)} ∈\mathbb{R}^D, 1 ≤ n ≤ N$，我们希望将其投影到一维空间中，投影向量为 $\pmb w\in\mathbb{R}^D$。不失一般性，我们限制 $\pmb w$ 的模为 1 ，即 $\pmb w^{T}\pmb w = 1$。每个样本点 $\pmb x^{(n)}$ 投影之后的表示为
$$
z^{(n)}=\pmb w^{\rm T}\pmb x^{(n)}
$$
用矩阵 $X=[\pmb x^{(1)},\pmb x^{(2)},\cdots\pmb x^{(N)}]$ 表示输入样本， $\bar{\pmb x}=\frac{1}{N}\sum_{n=1}^N\pmb x^{(n)}$ 为原始样本的中心点，所有样本投影后的方差为
$$
\sigma(X;\pmb w)=\frac{1}{N}\sum_{n=1}^N(\pmb w^{\rm T}\pmb x^{(n)}-)
$$

