# 介绍

这里以一个生活中的例子来介绍机器学习中的一些基本概念和流程：

假设我们需要到市场上购买芒果，但是之前毫无挑选芒果的经验，那么我们应该如何获取这些经验？

首先，我们从市场上随机选取一些芒果，列出每个芒果的**特征(feature)**，包括颜色、大小、形状、气味、产地、品牌，以及我们想到得到的评价结果，称为**标签(label)**。

为了表示一个芒果的所有特征，我们将其量化为一个 $D$ 维向量 $\pmb x =[x_1,x_2,\cdots,x_D]^{\rm T}$，其中每个分量都表示一个特征，可以是连续值（比如尺寸大小）或者离散值（比如品牌）。

标签可以是连续值（比如关于芒果的甜度、 水分以及成熟度的综合打分，从0.0~10.0)，也可以是离散值(比如 “好”“ 坏” 两类标签)。每个芒果的标签可以通过直接品尝来获得，也可以通过请一些经验丰富的老手来进行评判。标签通常用标量 $y$ 表示。

我们可以将一个标记好特征以及标签的芒果看作一个**样本(sample)**，一组样本构成的集合称为**数据集(data set)**。一般将数据集分为两部分：训练集和测试集。我们使用**训练集(training set)**中的样本来练习评价芒果的能力，而使用**测试集(test set)**中的样本是用来检验我们练习而得到的评价标准是否可靠。

假设市场上所有可能出现的芒果共同组成一个样本空间 $\{(\pmb x,y)\}$，从市场每购买一个芒果都返回一个随机变量 $(\pmb x^{(i)},y^{(i)})$，该随机变量服从未知的固定分布，因此我们的数据集中的每个样本都是**独立同分布的(identically and independently distributed, IID)**。给定包含 $N$ 个样本的训练集 $\mathcal{D}=\{(\pmb x^{(1)},y^{(1)}),(\pmb x^{(2)},y^{(2)}),\cdots,(\pmb x^{(N)},y^{(N)}) \}$ 后，我们希望让计算机从一个函数集合 $\mathcal{F}=\{f_1(\pmb x),f_2(\pmb x),\cdots \}$ 中寻找一个最优的函数 $f^*(\pmb x)$，能够最逼近特征向量 $\pmb x$ 和标签 $y$ 之间的真实映射关系，不同的 $\mathcal{F}$ 选取对应了不同种类的**模型(model)**。

如何寻找这个 “最优” 的函数 $f^∗ (\pmb x)$ 是机器学习的关键, 一般需要通过**学习算法(learning algorithm)**来完成。这个寻找过程通常称为**学习(learning)**或**训练(training)**过程。

当得到函数 $f^*(\pmb x)$，也就是模型(model)之后，我们就可以在下次挑选芒果时，根据芒果的特征 $\pmb x^{(0)}$ 来预测其标签的值：
$$
\hat y^{(0)} = f^*(\pmb x^{(0)})
$$
但是我们得到的这个模型是否可靠？这时需要对测试集 $\mathcal{D'}$ 的所有芒果进行测试，然后计算一些评价指标，比如**准确率(accuracy)**：
$$
Acc(f^*(\pmb x))=\frac{1}{|\mathcal{D'}|}\sum_{(\pmb x,y)\in \mathcal{D'}}I(f^*(\pmb x)=y)
$$

下图给出了机器学习的基本流程。对一个预测任务，输入特征向量为 $\pmb x$， 输出标签为 $y$，我们选择一个函数集合 $\mathcal{F}$，通过学习算法 $\mathcal{A}$ 和一组训练样本 $\mathcal{D}$，从 $\mathcal{F}$ 中学习到函数 $f^∗(\pmb x)$。 这样对新的输入 $\pmb x$，就可以用函数 $f^∗(\pmb x)$ 进行预测。

![](https://i.loli.net/2020/09/03/QoUBMEjRXuJzZ8A.png)

# 模型

机器学习的三个基本要素分别是：模型、学习准则和学习算法（优化算法）。

假定输入 $\pmb x\in \mathcal{X}$ 和输出 $y\in \mathcal{Y}$ 之间的关系可以通过一个未知的真实映射函数 $y=g(\pmb x)$ 或真实条件概率分布 $p(y|\pmb x)$ 来描述，但我们无法知道其具体形式，因此只能根据经验来假设一个函数集合 $\mathcal{F}$，称为**假设空间(hypothesis space)**，然后通过观测各个假设在训练集 $\mathcal{D}$ 上的特性，从中选择一个最接近真实映射函数或真实条件概率分布的模型。

> 映射函数给出一个确定的结果（如邮件系统判断某个邮件是否是垃圾邮件），而条件概率分布则给出各种可能结果的概率大小（如手写数字识别系统判断某个数字有40%的概率是3，40%的概率是2）

## 线性模型，非线性模型

若假设空间为一个参数化的线性函数族，
$$
f(\pmb x;\pmb \theta)=\pmb w^{\rm T}\pmb x+b
$$
则这些模型称为**线性模型(linear model)**（如图所示），其中参数 $\pmb \theta$ 包含了权重向量 $\pmb w$ 和偏置 $b$。

![](https://i.loli.net/2020/09/03/sUabBP13eAh6oyV.png)

广义的**非线性模型(nonlinear model)**（如图所示）可以写为多个非线性基函数 $\pmb \phi(\pmb x)$ 的线性组合：
$$
f(\pmb x;\pmb \theta)=\pmb w^{\rm T}\pmb\phi(\pmb x)+b
$$
![](https://i.loli.net/2020/09/03/DQYsLq7M5TbRema.png)

如果 $\pmb \phi(\pmb x)$ 本身为可学习的基函数，比如
$$
\phi_k(\pmb x)=h(\pmb w_k^{\rm T}\pmb \phi'(\pmb x)+b_k)
$$
其中 $h()$ 为非线性函数， $\pmb \phi'(\pmb x)$ 为另一组基函数，则 $f(\pmb x;\pmb \theta)$ 等价于**神经网络模型(neural network model)**（如图所示）。

![](https://i.loli.net/2020/09/03/YJc2teTQhI8UbvH.png)

# 学习准则

## 经验风险最小化准则

模型 $f(\pmb x;\pmb \theta)$ 的好坏可以通过**期望风险(expected risk)** $\mathcal{R}(\pmb \theta)$ 来衡量，其定义为
$$
\mathcal{R}(\pmb \theta)=E_{(\pmb x,y)\sim p(\pmb x,y)}(\mathcal{L}(y,f(\pmb x;\pmb \theta)))
$$
其中 $p(\pmb x,y)$ 表示样本空间中的样本分布， $\mathcal{L}(y,f(\pmb x;\pmb \theta))$ 为损失函数，用来量化模型预测与真实标签之间的差异。

一个好的模型应当有一个比较小的期望风险，但由于不知道真实的样本分布，期望风险并不能实际计算。替代的方法是计算**经验风险(empirical risk)**，即在训练集上的平均损失，或**训练损失(training loss)**：
$$
\mathcal{R}_{\mathcal{D}}^{emp}(\pmb \theta)=\frac{1}{N}\sum_{i=1}^N\mathcal{L}(y^{(i)},f(\pmb x^{(i)};\pmb \theta))
$$
一个切实可行的学习准则就是找到一组参数 $\pmb \theta^*$ 使得经验风险最小，即
$$
\pmb \theta^*=\arg \min_\pmb \theta \mathcal{R}_\mathcal{D}^{emp}(\pmb \theta)
$$
这就是**经验风险最小化(empirical risk minimization, ERM)**准则。

## 结构风险最小化准则

根据大数定理可知，当训练集大小 $|\mathcal{D}|$ 趋于无穷大时，经验风险将趋于期望风险。然而通常情况下我们无法获取无穷多个训练样本，训练集往往是样本空间的一个很小的子集，并且数据中包含一定的**噪声(noise)**，不能很好地反映全部样本的真实分布。经验风险最小化准则很容易导致模型在训练集上错误率很低，但是在测试集上错误率很高，即所谓的**过拟合(overfitting)**。

> **过拟合**：给定一个假设空间 $\mathcal{F}$，一个模型 $f$ 属于 $\mathcal{F}$，如果存在其他的模型 $f'$ 也属于 $\mathcal{F}$，使得在训练集上 $f$ 的损失比 $f ′$ 的损失小，但在整个样本空间上 $f ′$ 的损失比 $f$ 的损失小，那么就说模型 $f$ 过度拟合训练数据

过拟合问题往往是由于训练数据少，噪声大以及模型能力强等原因造成的。为了解决过拟合问题，一般采用限制模型能力的方法——在经验风险最小化的基础上再引入参数的**正则化(regularization)**，使经验风险不要过度地最小化。这种准则就是**结构风险最小化(structure risk minimization, SRM)**准则。
$$
\pmb \theta^*=\arg \min_{\pmb \theta} \mathcal{R}_\mathcal{D}^{struct}(\pmb \theta)\\
=\arg \min_{\pmb \theta} \mathcal{R}_\mathcal{D}^{emp}(\pmb \theta)+\frac{1}{2}\lambda||\pmb \theta||^2\\
=\arg \min_{\pmb \theta} \frac{1}{N}\sum_{i=1}^N\mathcal{L}(y^{(i)},f(\pmb x^{(i)};\pmb \theta))+\frac{1}{2}\lambda||\pmb \theta||^2
$$
其中 $||\pmb \theta||$ 是 $l_2$ 范数的正则化项，用来限制参数大小，避免过拟合； $\lambda$ 用于控制正则化的强度。正则化项也可以其它函数，如 $l_1$ 范数。

与过拟合相反的一个概念是**欠拟合(underfitting)**，即模型不能很好地拟合训练数据，在训练集上的错误率比较高。欠拟合一般是由于模型能力不足造成的。

![](https://i.loli.net/2020/09/03/WZLiyxq1zEue6K2.png)

总之，机器学习中的学习准则并不仅仅是拟合训练集上的数据，同时也要使得**泛化(generalization)**错误最低。

## 损失函数

**0-1损失函数(0-1 Loss Function)**  是最直观的损失函数：
$$
\mathcal{L}(y,f(\pmb x;\pmb \theta))=I(y\neq f(\pmb x;\pmb \theta))=\begin{cases}0, &y= f(\pmb x;\pmb \theta)\\
1, &y\neq f(\pmb x;\pmb \theta)
\end{cases}
$$
0-1损失函数的缺点是数学性质不是很好：不连续且导数为0，难以优化。因此经常用连续可微的损失函数替代。

**平方损失函数(quadratic loss function)** 一般用于回归问题，定义为
$$
\mathcal{L}(y,f(\pmb x;\pmb \theta))=\frac{1}{2}(y-f(\pmb x;\pmb \theta))^2
$$

**交叉熵损失函数(cross-entropy loss function)** 一般用于分类问题。假设样本的标签 $y\in \{1,\cdots,C\}$ 为离散的类别，模型 $f(\pmb x;\pmb \theta)\in[0,1]^C$ 的输出为标签的条件概率分布，即
$$
p(y=c|\pmb x;\pmb \theta)=f_c(\pmb x;\pmb \theta)\\
满足f_c(\pmb x;\pmb \theta)\in [0,1],\ \sum_{c=1}^C f_c(\pmb x;\pmb \theta)=1
$$
我们可以用一个 $C$ 维的one-hot向量 $\pmb y$ 来表示样本标签，即 $\pmb y=[0,\cdots,0,1,0,\cdots,0]$。 $\pmb y$ 可以看作真实条件概率分布 $p(\pmb y|\pmb x)$。那么如何衡量两个概率分布， $\pmb y$ 和 $f(\pmb x;\pmb \theta)$ 之间的差异？一般使用交叉熵：
$$
\mathcal{L}(y,f(\pmb x;\pmb \theta))=-\sum_{c=1}^Cy_c\log f_c(\pmb x;\pmb \theta)\\
=-\log f_y(\pmb x;\pmb \theta)
$$

为了充分利用凸优化中一些高效、成熟的优化算法，比如共轭梯度、拟牛顿法等，很多机器学习方法都倾向于选择合适的模型和损失函数，以<u>构造一个凸函数作为优化目标</u>。但也有很多模型(比如神经网络)的优化目标是非凸的，只能退而求其次找到局部最优解。

> 凸优化问题是一类特殊的非线性优化问题，需要满足可行域为凸集，目标函数为凸函数，等式约束函数为线性函数，不等式约束函数为凸函数。
>
> 凸优化问题中的局部最小解就是全局最小解。

## 偏差—方差分解

以回归问题为例，假设样本的真实分布为 $p(\pmb x,y)$，并采用平方损失函数，那么模型 $f(\pmb x)$ 的期望风险为
$$
\mathcal{R}(f)=E_{(\pmb x,y)\sim p(\pmb x,y)}((y-f(\pmb x))^2)
$$
最优模型为
$$
f^*(\pmb x)=E_{y\sim p(y|\pmb x)}(y)
$$
其期望风险为
$$
\mathcal{R}(f^*)=E_{(\pmb x,y)\sim p(\pmb x,y)}((y-f^*(\pmb x))^2)
$$
最优模型的期望风险是由于样本分布以及噪声引起的，无法再通过优化模型来减少。

将 $\mathcal{R}(f)$ 分解为
$$
\mathcal{R}(f)=E_{(\pmb x,y)\sim p(\pmb x,y)}((y-f^*(\pmb x)+f^*(\pmb x)-f(\pmb x))^2)\\
=E_{(\pmb x,y)\sim p(\pmb x,y)}((y-f^*(\pmb x))^2)+E_{\pmb x\sim p(\pmb x)}((f(\pmb x)-f^*(\pmb x))^2)+2E_{(\pmb x,y)\sim p(\pmb x,y)}((y-f^*(\pmb x))(f^*(\pmb x)-f(\pmb x)))\\
=\varepsilon+E_{\pmb x\sim p(\pmb x)}((f(\pmb x)-f^*(\pmb x))^2)\quad(证明？)
$$
其中第二项是当前模型和最优模型之间的差距，是机器学习算法可以优化的真实目标。

在实际训练一个模型 $f(\pmb x)$ 时，训练集 $\mathcal{D}$ 是从真实分布 $p(\pmb x, y)$ 上独立同分布地采样出来的有限样本集合。不同的训练集会得到不同的模型。令 $f_{\mathcal{D}} (\pmb x)$ 表示在训练集 $\mathcal{D}$ 上学习到的模型，一个机器学习算法(包括模型以及优化算法)的能力可以用<u>不同训练集上的模型的平均性能</u>来评价。

对于单个样本 $\pmb x$，不同训练集 $\mathcal{D}$ 得到得到模型 $f_{\mathcal{D}} (\pmb x)$ 和最优模型 $f^*(\pmb x)$ 的期望差距为
$$
E_{\mathcal{D}}[(f_{\mathcal{D}}(\pmb x)-f^*(\pmb x))^2]\\
=E_{\mathcal{D}}[( f_{\mathcal{D}}(\pmb x) - E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)] + E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)]-f^*(\pmb x))^2]\\
=E_{\mathcal{D}}[(f_{\mathcal{D}}(\pmb x)-E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)])^2]+(E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)]-f^*(\pmb x))^2
$$

> 证明：
> $$
> E[(f-E[f]+E[f]-f^*)^2]\\
> =E[(f-E[f])^2]+E[(E[f]-f^*)^2]+2E[(f-E[f])(E[f]-f^*)]\\
> =E[(f-E[f])^2]+(E[f]-f^*)^2+2(E[f]-f^*)E[(f-E[f])]\\
> =E[(f-E[f])^2]+(E[f]-f^*)^2
> $$

其中第一项是**方差(variance)**，是指一个模型在不同训练集上的差异，可以用来衡量一个模型是否容易过拟合；第二项为**偏差(bias)**，是指一个模型在不同训练集上的平均性能和最优模型的差异，可以用来衡量一个模型的拟合能力。

将上式带入 $\mathcal{R}(f)$ 的分解式（替换 $(f(\pmb x)-f^*(\pmb x))^2$ ）得到
$$
\mathcal{R}(f)=\varepsilon+({\rm bias})^2+{\rm variance}
$$
其中
$$
({\rm bias})^2=E_{\pmb x}(E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)]-f^*(\pmb x))^2\\
{\rm variance}=E_{\pmb x}[E_{\mathcal{D}}[(f_{\mathcal{D}}(\pmb x)-E_{\mathcal{D}}[f_{\mathcal{D}}(\pmb x)])^2]]
$$
下图给出了机器学习模型的四种偏差和方差组合情况。每个图的中心为最优模型 $f^∗(\pmb x)$，点为不同训练集 $\mathcal{D}$ 上得到的模型 $f_{\mathcal{D}}(\pmb x)$。 图a给出了一种理想情况，方差和偏差都比较低；图b为高偏差低方差的情况，表示模型的泛化能力很好，但拟合能力不足；图c为低偏差高方差的情况，表示模型的拟合能力很好，但泛化能力比较差，当训练数据比较少时会导致过拟合；图d为高偏差高方差的情况，是一种最差的情况。

![](https://i.loli.net/2020/09/04/fdGCwQEms15XTcu.png)

随着模型复杂度的增加，模型的拟合能力变强，偏差减少而方差增大，从而导致过拟合。以结构风险最小化为例，我们通过调整正则化系数 $λ$ 来控制模型的复杂度，因此一个好的正则化系数 $λ$ 需要在偏差和方差之间取得比较好的平衡。下图给出了机器学习模型的期望风险、偏差和方差随复杂度的变化情况，其中红色虚线表示最优模型。最优模型并不一定是偏差曲线和方差曲线的交点。

![](https://i.loli.net/2020/09/04/YLd74xBmu5A1RTt.png)

偏差和方差分解给机器学习模型提供了一种分析途径，但在实际操作中难以直接衡量。一般来说，当一个模型在训练集上的错误率比较高时，说明模型的<u>拟合能力不够</u>，即<u>偏差比较高</u>，这种情况可以通过增加数据特征、提高模型复杂度、减小正则化系数等操作来改进。当模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型<u>过拟合</u>，<u>方差比较高</u>，这种情况可以通过降低模型复杂度、加大正则化系数、引入先验等方法来缓解。

# 优化算法

在确定了训练集 $\mathcal{D}$，假设空间 $\mathcal{F}$ 以及学习准则后，如何找到最优的模型 $f(\pmb x, θ^∗ ) $ 就成了一个**数学优化(mathematical optimization)**问题。机器学习的训练过程其实就是最优化问题的求解过程。

在机器学习中，优化又可以分为**参数优化**和**超参数优化**。模型 $f(\pmb x; θ)$ 中的 $θ$ 称为模型的参数，可以通过优化算法进行学习。除了可学习的参数 $θ$ 之外，还有一类参数是用来定义模型结构或优化策略的， 这类参数叫作**超参数(hyper-parameter)**。常见的超参数包括：聚类算法中的类别个数、梯度下降法中的步长、正则化项的系数、神经网络的层数、支持向量机中的核函数等。超参数的选取一般都是组合优化问题，很难通过优化算法来自动学习， 因此超参数优化是机器学习的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整。

## 梯度下降法

### 批量梯度下降法

机器学习中，最简单、最常用的优化算法就是**梯度下降法(gradient descent method)**，即首先初始化参数 $θ_0$，然后按下面的迭代公式来计算训练集 $\mathcal{D}$ 上风险函数的最小值：
$$
\pmb \theta_{t+1}=\pmb \theta_t-\alpha\frac{\partial \mathcal{R}_\mathcal{D}(\pmb \theta)}{\partial \pmb \theta}\bigg|_{\pmb\theta = \pmb \theta_t} \\
=\pmb \theta_t-\alpha(\frac{1}{N}\sum_{i=1}^{N}\frac{\partial \mathcal{L}(y^{(i)},f(\pmb x^{(i)};\pmb \theta))}{\partial \pmb \theta}\bigg|_{\pmb\theta = \pmb \theta_t}+\lambda\pmb \theta_t)
$$
其中 $\pmb \theta_t$ 为第 $t$ 迭代时的参数值， $\alpha$ 为搜索步长。在机器学习中， $\alpha$ 一般称为**学习率(learning rate)**。

> 对于函数 $f(\boldsymbol x)$ , 如果 $f(\boldsymbol x)$ 在点 $\boldsymbol x_t$ 附近是连续可微的，那么 $f(\boldsymbol x)$ 下降最快的方向是 $f(\boldsymbol x)$ 在 $\boldsymbol x_t$ 点的梯度方向的反方向。根据泰勒一阶展开公式，有
> $$
> f(\pmb x_{t+1})=f(\pmb x_t +\Delta \pmb x)\approx f(\pmb x_t)+\Delta \pmb x^{\rm T}\nabla f(\pmb x_t)
> $$
> 取 $\Delta \pmb x = -\alpha\nabla f(\pmb x_t)$，当 $\alpha$ 足够小时， $f(\pmb x_{t+1}) < f(\pmb x_t)$ 成立。
>
> 这样我们就可以从一个初始值 $\pmb x_0$ 出发，通过迭代公式
> $$
> \pmb x_{t+1}=\pmb x_t-\alpha_t\nabla f(\pmb x_t),\ t\ge 0
> $$
> 生成序列 $\pmb x_0, \pmb x_1,\pmb x_2,\cdots$，使得
> $$
> f(\pmb x_0)\ge f(\pmb x_1)\ge f(\pmb x_2)\ge \cdots
> $$
> 如果顺利的话，序列 $(\pmb x_n)$ 收敛到局部最小解 $\pmb x^*$。

由于这里的目标函数是整个训练集的风险函数，因此称为**批量梯度下降法(batch gradient descent)**。

### 随机梯度下降法

批量梯度下降法在每次迭代时都需要计算每个样本的损失函数的梯度，当训练集中的样本数量 $N$ 很大时，空间复杂度比较高，每次迭代的计算开销也很大。

实际上，批量梯度下降法相当于是从真实样本分布中独立同分布地抽取 $N$ 个样本，由它们计算出来的经验风险的梯度来近似期望风险的梯度。因此为了降低每次迭代的计算复杂度，我们也可以在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即**随机梯度下降法(stochastic Gradient Descent, SGD)**。当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解[Nemirovski et al., 2009]。

和批量梯度下降相比，随机梯度下降实现简单，收敛速度也非常快，因此使用十分广泛。<u>随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声，在非凸优化问题中更容易逃离局部最优点</u>。

### 小批量梯度下降法

随机梯度下降法的一个缺点是无法充分利用计算机的并行计算能力，小批量梯度下降法(mini-batch gradient descent)是批量梯度下降和随机梯度下降的折中。每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率。

## 提前停止

在梯度下降训练的过程中，由于过拟合的原因，在训练集上收敛的参数并不一定在测试集上最优。因此除了训练集和测试集之外，有时也会使用一个**验证集(validation set)**来进行模型选择，测试模型在验证集上是否最优。

在每次迭代时，把新得到的模型 $f(\pmb x;\pmb θ)$ 在验证集上进行测试，并计算错误率。如果在验证集上的错误率不再下降，就停止迭代，这种策略叫提前停止(early stop)。如果没有验证集，可以在训练集上划分出一个小比例的子集作为验证集。如图所示提前停止的示例：

![](https://i.loli.net/2020/09/04/QTfOXJ9toj6lNFR.png)

# 机器学习的类型

除了考虑模型，学习准则和优化算法，我们还会按照<u>训练样本提供的信息以及反馈方式的不同</u>, 将机器学习分为以下几类：

## 监督学习

如果机器学习的目标是建模样本的特征 $\boldsymbol x$ 和标签 $y$ 之间的关系： $y=f(\boldsymbol x; θ)$ 或 $p(y|\boldsymbol x; θ)$，并且训练集中每个样本都有标签，那么这类机器学习称为**监督学习(supervised learning)**。根据标签类型的不同，监督学习又可以分为回归问题、分类问题和结构化学习问题：

1. **回归问题(regression)**中的标签 $y$ 是连续值(实数或连续整数)， $f(\boldsymbol x; θ)$ 的输出也是连续值
2. **分类问题(classification)**中的标签 $y$ 是离散的类别(符号)。在分类问题中，学习到的模型也称为**分类器(classifier)**；分类问题根据其类别数量又可分为**二分类(binary classification)**和**多分类(multi-class classification)**问题。
3. ***结构化学习()**……

## 无监督学习

**无监督学习(unsupervised learning, UL)**是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有聚类、密度估计、特征学习、降维等。

## *强化学习

**强化学习(reinforcement learning, RL)**是一类通过交互来学习的机器学习算法。在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励。智能体在和环境的交互中不断学习并调整策略，以取得最大化
的期望总回报。

# 特征工程与深度学习

## 特征工程

在实际应用中，数据类型多种多样，比如文本、音频、图像、视频等。不同类型的数据，其**原始特征(raw feature)**的空间也不相同，比如一张灰度图像(像素数量为 $D$ )的特征空间为 $[0, 255]^D$，一个自然语言句子(长度为 $L$ )的特征空间为 $|\mathcal{V}|^L$，其中 $\mathcal{V}$ 为词表集合。而很多机器学习算法要求输入的样本特征是数学上可计算的,，因此在机器学习之前我们需要将这些不同类型的数据转换为向量表示。

> **图像特征**
> 在手写体数字识别任务中，样本 $x$ 为待识别的图像。为了识别 $x$ 是什么数字，我们可以从图像中抽取一些特征。如果图像是一张大小为 $M × N$ 的图像，其特征向量可以简单地表示为 $M × N$ 维的向量，每一维的值为图像中对应像素的灰度值。为了提高模型准确率，也会经常加入一个额外的特征，比如直方图、宽高比、笔画数、纹理特征、边缘特征等。假设我们总共抽取了 $D$ 个特征，这些特征可以表示为一个向量 $\pmb x ∈ \mathbb{R}^D$。
>
> **文本特征**
> 在文本情感分类任务中，样本 $x$ 为自然语言文本，类别 $y ∈ \{+1, −1\}$ 分别表示正面或负面的评价。为了将样本 $x$ 从文本形式转为向量形式，一种简单的方式是使用**词袋(Bag-of-Words ,BoW)**模型：假设训练集合中的词都来自一个词表 $\mathcal{V}$，大小为 $|\mathcal{V}|$，则每个样本可以表示为一个 $|\mathcal{V}|$ 维的向量 $\pmb x∈\{0,1\}^{|V|}$。向量 $x$ 中第 $i$ 维的值表示词表中的第 $i$ 个词是否在 $x$ 中出现。

但直接用数据的原始特征来进行预测可能存在以下几种不足：

1. 特征比较单一，需要进行(非线性的)组合才能发挥其作用；
2. 特征之间冗余度比较高；
3. 并不是所有的特征都对预测有用；
4. 很多特征通常是易变的；
5. 特征中往往存在一些噪声

传统的机器学习中，特征需要靠人工经验或特征转换方法来抽取，一般包含以下步骤：

![](https://i.loli.net/2020/09/04/CVQRfXBsWMGt8Em.png)

1. **数据预处理**：对数据进行预处理，如去除噪声等。

2. **特征提取**：从原始数据中提取一些有效的特征，比如在图像分类中，提取边缘、尺度不变特征变换(scale invariant feature transform, SIFT)特征等。

3. **特征转换**: 对特征进行一定的加工，比如降维和升维。降维包括**特征抽取(feature extraction)**和**特征选择(feature selection)**两种途径。常用的特征转换方法有主成分分析(principal components analysis, PCA)、线性判别分析(linear discriminant analysis, LDA)等。

   > 很多特征转换方法就是机器学习方法。

4. **预测**：机器学习的核心部分，学习一个函数并进行预测。

上述流程中，每步特征处理以及预测一般都是分开进行的，这类机器学习称为**浅层学习(shallow learning)**。实际操作过程中，不同预测模型的性能相差不多，而<u>前三步中的特征处理对最终系统的准确性有着十分关键的作用</u>。特征处理一般都需要人工干预完成，利用人类的经验来选取好的特征并最终提高机器学习系统的性能。因此很多的机器学习问题变成了**特征工程(feature engineering)**问题——开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。

### *特征选择和特征抽取

**特征选择(feature selection)**是选取原始特征集合的一个有效子集，使得基于这个特征子集训练出来的模型准确率最高。简单地说，特征选择就是保留有用特征，移除冗余或无关的特征。

**子集搜索**

一种直接的特征选择方法为**子集搜索(subset search)**。假设原始特征数为 $D$，则共有 $2^D$ 个候选子集，特征选择的目标是选择一个最优的候选子集。最暴力的做法是测试每个特征子集，看机器学习模型哪个子集上的准确率最高，
但是这种方式效率太低。常用的方法是采用贪心的策略：由空集合开始，每一轮添加该轮最优的特征，称为**前向搜索(forward search)**；或者从原始特征集合开始，每次删除最无用的特征，称为**反向搜索(backward search)**。

** $l_1$ 正则化**

$l_1$ 正则化通过导致稀疏特征从而简介实现了特征选择。

**特征抽取(feature extraction)**是构造一个新的特征空间，并将原始特征投影在新的空间中得到新的表示。以线性投影为例，令 $\pmb x∈\mathbb{R}^D$ 为原始特征向量， $\pmb x′∈\mathbb{R}^K$ 为经过线性投影后得到的在新空间中的特征向量，有
$$
\pmb x′ =\pmb W\pmb x
$$
其中 $\pmb W∈ \mathbb{R}^{K×D}$ 为映射矩阵。

特征抽取又可以分为监督和无监督的方法。监督的特征学习的目标是抽取对一个特定的预测任务最有用的特征，比如线性判别分析(linear discriminant analysis , LDA)。而无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析(principal component analysis , PCA)和自编码器(auto-encoder , AE)。

特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难(curse of dimensionality)。对于很多没有正则化的模型，特征选择和特征抽取非常必要。经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取也经常称为维数约减或降维(dimension reduction)。

## 表示

特征工程中往往需要大量的人工和专家知识，并且需要尝试大量的特征。如何让机器自动地学习出有效的特征（也称为**表示(representation)**）也成为机器学习中的一项重要研究内容，称为**特征学习(feature learning)**，也叫**表示学习(representation learning)**。

> 表示学习可以看作一个特殊的机器学习任务，即有自己的模型、学习准则和优化方法。

### 表示方法

一个好的表示具有以下几个特点：

1. 具有很强的表示能力，即同样大小的向量可以表示更多信息
2. 使后续的学习任务变得简单，即需要包含更高层的语义信息
3. 具有一般性，是任务或领域独立的

> **语义鸿沟(semantic gap)**指数据的<u>底层特征</u>和<u>高层语义信息</u>的差异性。例如给定一些汽车的图片，由于每辆车的颜色和形状都各不相同，因此这些图片在像素级别上的表示（即底层特征）的差异性非常大，但是我们对于这些图片的理解（即高层语义信息）都是一致的。

常用的两种表示为**局部表示(local representation)**和**分布式表示(distributed representation)**。以颜色表示为例，局部表示方法使用不同的名字来命名不同的颜色，例如“红”，“绿”，“蓝”，“黄”，“紫”，“紫罗兰”等，通常表示为**one-hot向量**的形式。假设所有颜色的名字构成一个词表 $\mathcal{V}$，词表大小为 $|\mathcal{V}|$，那么可以用一个 $|\mathcal{V}|$ 维的one-hot向量来表示每一种颜色：第 $i$ 种颜色对应的one-hot向量的第 $i$ 维的值为1，其它都为0。

局部表示有两个优点：(1) 这种离散的表示方式具有很好的解释性, 有利于人工归纳和总结特征, 并通过特征组合进行高效的特征工程；(2) 通过多种特征组合得到的表示向量通常是稀疏的二值向量，当用于线性模型时计算效率非常高。但局部表示有两个不足之处：(1) one-hot 向量的维数很高且不能扩展，如果有一种新的颜色那么就需要增加一维来表示； (2) 不同颜色之间的相似度都为0，即我们无法知道“紫”和“紫罗兰”的相似度要高于“紫”和“绿”的相似度。

分布式表示方法使用RGB值来表示颜色，不同颜色对应到R, G, B三维空间的一个点，这样分布式表示可以表示为低维的稠密向量。

我们可以使用神经网络来将高维的局部表示空间 $\mathbb{R}^{|V|}$ 映射到一个非常低维的分布式表示空间 $\mathbb{R}^D, D ≪ |\mathcal{V}|$。在这个低维空间中，每个特征不再是坐标轴上的点，而是分散在整个低维空间中，在机器学习中这个过程也称为**嵌入(embedding)**。嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系，比如自然语言中词的分布式表示经常称为词嵌入。

下图展示了一个3维one-hot向量空间和一个2维嵌入空间的对比。图中有三个样本 $w_1$， $w_2$ 和 $w_3$。在one-hot向量空间中，每个样本都位于坐标轴上，每个坐标轴上一个样本。而在低维的嵌入空间中，每个样本都不在坐标轴上，样本之间可以计算相似度。

![](https://i.loli.net/2020/09/04/cvyG9dzPSxOpMtb.png)

### 表示学习

要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特征开始，经过多步非线性转换才能得到。深层结构的优点是可以增加特征的重用性，从而指数级地增加表示能力，因此表示学习的关键是构建<u>具有一定深度的多层次特征表示</u>。

在传统的机器学习中，也有很多有关特征学习的方法，比如主成分分析、线性判别分析、独立成分分析等，但是传统的特征学习一般是通过<u>人为地设计一些准则</u>，然后根据这些准则来选取有效的特征。特征的学习是和最终预测模型的学习<u>分开进行</u>的，因此学习到的特征不一定可以提升最终模型的性能。

## *深度学习

上面已经提到，表示学习需要构建一个深层结构的模型，每一层的非线性转换都将特征转换为更高层的特征。使用这种表示学习方法的机器学习称为**深度学习(deep learning, DL)**。

> 深度学习早期主要用来进行表示学习，但后来越来越多地用来处理更加复杂的推理、决策等问题。

下图给出了深度学习的数据处理流程。通过多层的特征转换将原始数据变成更高层次、更抽象的表示，这些学习到的表示可以替代人工设计的特征，从而避免了“特征工程”。

![](https://i.loli.net/2020/09/04/elzfAJ2FWYsiqod.png)

和 “浅层学习” 不同，深度学习需要解决的关键问题是**贡献度分配问题(credit assignment problem, CAP)** [Minsky,1961] ，即一个系统中不同的**组件(component)**或其参数对最终系统输出结果的贡献或影响。以下围棋为例，每当下完一盘棋，最后的结果要么赢要么输。我们会思考哪几步棋导致了最后的胜利，或者又是哪几步棋导致了最后的败局。如何判断每一步棋的贡献就是贡献度分配问题，这是一个非常困难的问题。

目前深度学习采用的模型主要是<u>神经网络模型</u>，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。只要是超过一层的神经网络都会存在贡献度分配问题，因此可以将超过一层的神经网络都看作深度学习模型。随着深度学习的快速发展，模型深度也从早期的5 ∼ 10层增加到目前的数百层，随着模型深度的不断增加，其特征表示的能力也越来越强，从而使后续的预测更加容易。

### 端到端学习

在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间人为地切割成很多子模块（或多个阶段），每个子模块分开学习，比如一个自然语言理解任务，一般分为分词、词性标注、句法分析、语义分析、语义推理等步骤。这种学习方式有两个问题：一是每一个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致；二是错误传播，前一步的错误会对后续的模型造成很大的影响。这样就增加了机器学习方法在实际应用中的难度。

**端到端学习(end-to-end learning)**，也称端到端训练，是指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标。在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预。端到端学习的训练数据为“输入-输出”对的形式，无须提供其他额外信息。因此，端到端学习和深度学习一样，都是要解决贡献度分配问题。目前大部分采用神经网络模型的深度学习也可以看作一种端到端的学习。

# 评价指标

在介绍部分的购买芒果的例子中，我们为了衡量得到的模型的好坏，用模型对测试集的所有芒果进行测试，然后计算了准确率作为评价指标。这里将介绍更多的评价指标。

给定测试集 $\mathcal{T}=\{(\pmb x^{(1)},y^{(1)}),\cdots,(\pmb x^{(N)},y^{(N)}) \}$，假设标签 $y^{(n)}\in \{1,\cdots,C\}$，用学习好的模型 $f(\pmb x;\pmb \theta^*)$ 对测试集中的每一个样本进行预测，结果为 $\{\hat y^{(1)},\cdots,\hat y^{(N)}\}$ 

**准确率(accuracy)**
$$
\mathcal{A}=\frac{1}{N}\sum_{i=1}^N I(y^{(i)}=\hat y^{(n)})
$$
**错误率(error rate)**
$$
\mathcal{E}=1-\mathcal{A}=\frac{1}{N}\sum_{i=1}^N I(y^{(i)}\neq\hat y^{(n)})
$$
**精确率(precision)和召回率(recall)**

模型对于任意一个测试样本的结果有4种情况，用如下的**混淆矩阵(confusion matrix)**来表示：

![](https://i.loli.net/2020/09/04/aj4dY5ZuKnpDk9R.png)

精确率定义为
$$
\mathcal{P}=\frac{TP}{TP+FP}
$$
召回率定义为
$$
\mathcal{R}=\frac{TP}{TP+FN}
$$
F值定义为
$$
\mathcal{F}=\frac{(1+\beta^2)\times \mathcal{P} \times \mathcal R}{\beta^2\times \mathcal{P}+ \mathcal{R}}
$$
当 $\beta=1$ 时，F值称为F1值，是精确率和召回率的调和平均数。

**宏平均(macro average)**

宏平均是在所有类别上的总体精确率、召回率和F1值的算术平均值：
$$
\mathcal{P}_{macro}=\frac{1}{C}\sum_{c=1}^C\mathcal{P}_c\\
\mathcal{R}_{macro}=\frac{1}{C}\sum_{c=1}^C\mathcal{R}_c\\
\mathcal{F1}_{macro}=\frac{2\times \mathcal{P}_{macro}\times \mathcal{R}_{macro}}{\mathcal{P}_{macro}+\mathcal{R}_{macro}}
$$

# 各类理论

## PAC学习理论

我们使用经验风险来替代期望风险，但经验风险和期望风险之间存在一定的差异，称为**泛化错误(generalization error)**。泛化错误可以衡量一个模型 $f$ 是否可以很好地泛化到未知数据：
$$
\mathcal{G}_D(f)=\mathcal{R}(f)-\mathcal{R}_{\mathcal{D}}^{emp}(f)
$$
根据大数定律，当训练集大小 $|\mathcal{D}|$ 趋向于无穷大时，泛化错误趋向于0，即经验风险趋近于期望风险。
$$
\forall \varepsilon>0,\ \lim_{|\mathcal{D}|\to \infty}P(\left | \mathcal{R}(f)-\mathcal{R}_{\mathcal{D}}^{emp}(f) \right |<\varepsilon)=1
$$
然而实际的训练集大小是有限的，因此只能降低期望，要求学习算法可以以一定的概率学习到一个近似正确的假设，即**PAC(probably approximately correct)学习(PAC learning)**。一个**PAC可学习(PAC-learnable)**的算法是指该学习算法能够在<u>多项式时间内</u>从合理数量的训练数据中学习到一个近似正确的 $f$。

PAC学习可以下面公式描述：
$$
P(\left | \mathcal{R}(f)-\mathcal{R}_{\mathcal{D}}^{emp}(f) \right |<\varepsilon)>1-\delta
$$
其中 $ε,δ$ 是和样本数量 $N$ 以及假设空间 $\mathcal{F}$ 相关的变量；如果固定 $\varepsilon,\delta$，则可以反过来计算 $N$ （证明？）：
$$
N(\varepsilon,\delta)\ge \frac{1}{2\varepsilon^2}(\log |\mathcal{F}|+\log \frac{2}{\delta})
$$
从上面的公式可以看出，模型越复杂，即假设空间 $\mathcal{F}$ 越大，那么模型的泛化能力越差；要达到相同的泛化能力，越复杂的模型需要的样本数量越多。为了提高模型的泛化能力，通常需要正则化来限制模型复杂度。

PAC 学习理论也可以帮助分析一个机器学习方法在什么条件下可以学习到一个近似正确的分类器：如果希望模型的假设空间越大，而泛化错误越小，那么其需要的样本数量越多。

## 奥卡姆剃刀

**奥卡姆剃刀(Occam’s Razor)**原理是由14世纪逻辑学家 William of Occam提出的一个解决问题的法则：“如无必要, 勿增实体”。奥卡姆剃刀的思想和机器学习中的正则化思想十分类似：<u>简单的模型泛化能力更好</u>。如果有两个性能相近的模型，我们应该<u>选择更简单的模型</u>。因此，在机器学习的学习准则上，我们经常会引入参数正则化来限制模型能力，避免过拟合。

# 参考

邱锡鹏,2020. 神经网络与深度学习[M/OL].  机械工业出版社. https://nndl.github.io/nndl-book.pdf

机器学习速成课程 https://developers.google.com/machine-learning/crash-course

