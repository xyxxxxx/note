
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="xyx">
      
      
        <link rel="canonical" href="https://xyxxxxx.github.io/note/ml/platform-and-tool/pytorch/api-distributed.html">
      
      
        <link rel="prev" href="api-backends.html">
      
      
        <link rel="next" href="api-multiprocessing.html">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.1">
    
    
      
        <title>API: torch.distributed - 笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.45e1311d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="light-green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torchdistributed" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="笔记" class="md-header__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API: torch.distributed
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../index.html" class="md-tabs__link">
        
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/index.html" class="md-tabs__link">
          
  
    
  
  数学

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../cs/dsa/data-structure/index.html" class="md-tabs__link">
          
  
    
  
  CS

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../python/index.html" class="md-tabs__link">
          
  
    
  
  Python

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../index.html" class="md-tabs__link">
          
  
    
  
  机器学习

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../reference-and-tool/linux/linux-command.html" class="md-tabs__link">
          
  
    
  
  参考和工具

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../web/simple-html.html" class="md-tabs__link">
          
  
    
  
  前端

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="笔记" class="md-nav__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/algebra/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    代数
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            代数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/elementary-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra-understanding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数理解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/abstract-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    抽象代数
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/analysis/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分析
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/multivariate-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多元微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/matrix-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    矩阵微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/differential-equation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微分方程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/complex-analysis.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/mathematical-physics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学物理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    应用数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            应用数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/optimization/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学优化
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_2" id="__nav_2_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_2">
            <span class="md-nav__icon md-icon"></span>
            数学优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-set.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/duality.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对偶性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/nlp.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非线性优化
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    概率论与数理统计
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_3" id="__nav_2_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_3">
            <span class="md-nav__icon md-icon"></span>
            概率论与数理统计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/probability-of-event.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    事件的概率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/random-variable.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/limit-theorems.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    极限定理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/stochastic-process/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    随机过程
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_4" id="__nav_2_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_4">
            <span class="md-nav__icon md-icon"></span>
            随机过程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/stochastic-process-introduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机过程基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/markov-chain.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    马尔可夫链
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/poisson-process.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泊松过程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/discrete-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    离散数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            离散数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/mathematical-logic.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学逻辑
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/set-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    集合论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/enumerative-combinatorics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    组合数学
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/polynomial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多项式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/graph-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/number-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数论
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CS
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            CS
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    数据结构与算法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构与算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/data-structure/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数据结构
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/array-and-linked-list.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数组和链表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/stack-and-queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    栈和队列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/binary-search-tree.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    二叉搜索树
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/hash-table.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    哈希表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/graph.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/heap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    堆
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/algorithm/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    算法
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/common-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常见算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/divide-and-conquer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分而治之
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/dynamic-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动态规划
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/greedy-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贪心算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/backtracking.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回溯法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/network-flow-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络流算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/linear-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性规划
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/leetcode-examples.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leetcode 例题
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/net-model/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络模型
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2_2" id="__nav_3_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_2">
            <span class="md-nav__icon md-icon"></span>
            网络模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/transport-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    传输层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/network-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/application-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    应用层
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/information-theory/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    信息论
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            信息论
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/information-theory/entropy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    熵、相对熵与互信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Python
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/runtime-environment-devtool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运行环境与开发工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/data-type-and-operation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型与操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/control-flow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    控制流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/container-type.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    容器类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/iterator-and-generator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迭代器与生成器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/oop.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向对象编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/process-and-thread.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    进程与线程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/error-handling-and-unit-test.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    错误处理与单元测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/module-and-package.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模块与包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/standard-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    标准库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_13">
            <span class="md-nav__icon md-icon"></span>
            标准库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/argparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    argparse——命令行选项、参数和子命令解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base64——Base16, Base32, Base64, Base85 数据编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/builtins.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    builtins——内建对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.abc.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections.abc——容器的抽象基类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections——容器数据类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/configparser.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configparser——配置文件解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/concurrent.futures.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    concurrent.futures——启动并行任务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/copy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    copy——浅层和深层复制操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/csv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    csv——CSV 文件读写
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/datetime.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    datetime——基本日期和时间类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/enum.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    enum——对枚举的支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functions.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    内置函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    functools——高阶函数和可调用对象上的操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/glob.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    glob——Unix 风格路径名模式扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/graphlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphlib——操作类似图的结构的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hashlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hashlib——安全哈希与消息摘要
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hmac.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hmac——基于密钥的消息验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/importlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    importlib——import 的实现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/inspect.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    inspect——检查对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    io——处理流的核心工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/itertools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    itertools——为高效循环而创建迭代器的函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json——JSON 编码和解码器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/keyword.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    keyword——检验 Python 关键字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/marshal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marshal——内部 Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    math——数学函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    multiprocessing——基于进程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/operator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    operator——标准运算符替代函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os——多种操作系统接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.path.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os.path——常用路径操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pathlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pathlib——面向对象的文件系统路径
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pickle.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pickle——Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/platform.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    platform——获取底层平台的标识数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pprint.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pprint——数据美化输出
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    queue——一个同步的队列类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    random——生成伪随机数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/re.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    re——正则表达式操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/secrets.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    secrets——生成安全随机数字用于管理密码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/select.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    select——等待 I/O 完成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shlex.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shlex——简单的词法分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shutil.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shutil——高阶文件操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    signal——设置异步事件处理程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/socket.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    socket——底层网络接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/subprocess.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    subprocess——子进程管理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/sys.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sys——系统相关的参数和函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tarfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tarfile——读写 tar 归档文件
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tempfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tempfile——生成临时文件和目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/threading.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    threading——基于线程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/time.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    time——时间的访问和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/timeit.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timeit——测量小段代码的执行时间
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/types.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    types——动态类型创建和内置类型名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/typing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    typing——类型提示支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.parse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.parse——用于解析 URL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.request.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.request——用于打开 URL 的可扩展库
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/uuid.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    uuid——RFC 4122 定义的 UUID 对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/weakref.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    weakref——弱引用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/zipfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zipfile——使用 ZIP 存档
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/common-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    常用库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_14">
            <span class="md-nav__icon md-icon"></span>
            常用库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/beautifulsoup.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BeautifulSoup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/click.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    click
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/filelock.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    filelock
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pillow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pillow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pyyaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyYAML (yaml)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/requests.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    requests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/rich.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rich
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/websocket-client.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    websocket-client (websocket)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/style-guide.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    风格指南
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    机器学习
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    统计学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            统计学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/nb.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/perceptron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    感知器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/svm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    支持向量机
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/fnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前馈神经网络（FNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/cnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积神经网络（CNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    循环神经网络（RNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/seq2seq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列到序列模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/transformer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/self-supervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自监督学习模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/gan.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成对抗网络（GAN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rl.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/auto-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    常用技术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            常用技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/normalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    归一化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/generalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泛化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/anomaly-detection.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    异常检测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/adversarial-attack.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗攻击
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/explainable-ml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型可解释性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/transfer-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/model-compression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型压缩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/life-long-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    终身学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../nlp/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    自然语言处理专题
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            自然语言处理专题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/text-processing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    文本处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/language-model.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/sentiment-classification.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯和情感分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/logistic-regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    逻辑回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/neural-network.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/part-of-speech-tagging.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词性标注和命名实体检测
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../distributed/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分布式训练
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    平台和工具
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            平台和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../numpy/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    NumPy
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            NumPy
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../pandas/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pandas
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            pandas
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../matplotlib/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    matplotlib
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_4" id="__nav_5_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_4">
            <span class="md-nav__icon md-icon"></span>
            matplotlib
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matplotlib/example.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    示例
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../tensorflow/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_5" id="__nav_5_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_5">
            <span class="md-nav__icon md-icon"></span>
            TensorFlow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/tensorflow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-config.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-distribute.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.distribute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-image.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-keras.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.keras
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-linalg.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.linalg
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.math
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.random
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.signal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-strings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.strings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-train.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.train
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tfds.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tfds
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_6" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_6" id="__nav_5_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="pytorch.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchvision.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchserve.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchserve
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-torch.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-nn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-nn-functional.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-optim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-autograd.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-cuda.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-backends.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    API: torch.distributed
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="api-distributed.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    API: torch.distributed
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#后端" class="md-nav__link">
    <span class="md-ellipsis">
      后端
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#初始化" class="md-nav__link">
    <span class="md-ellipsis">
      初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_process_group" class="md-nav__link">
    <span class="md-ellipsis">
      init_process_group()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_available()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_initialized" class="md-nav__link">
    <span class="md-ellipsis">
      is_initialized()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_mpi_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_mpi_available()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_nccl_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_nccl_available()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#初始化后" class="md-nav__link">
    <span class="md-ellipsis">
      初始化后
    </span>
  </a>
  
    <nav class="md-nav" aria-label="初始化后">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backend" class="md-nav__link">
    <span class="md-ellipsis">
      Backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_backend-get_rank-get_world_size" class="md-nav__link">
    <span class="md-ellipsis">
      get_backend(), get_rank(), get_world_size()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式键值存储" class="md-nav__link">
    <span class="md-ellipsis">
      分布式键值存储
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式键值存储">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#store" class="md-nav__link">
    <span class="md-ellipsis">
      Store
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Store">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add" class="md-nav__link">
    <span class="md-ellipsis">
      add()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delete_key" class="md-nav__link">
    <span class="md-ellipsis">
      delete_key()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get" class="md-nav__link">
    <span class="md-ellipsis">
      get()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_keys" class="md-nav__link">
    <span class="md-ellipsis">
      num_keys()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wait" class="md-nav__link">
    <span class="md-ellipsis">
      wait()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filestore" class="md-nav__link">
    <span class="md-ellipsis">
      FileStore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hashstore" class="md-nav__link">
    <span class="md-ellipsis">
      HashStore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tcpstore" class="md-nav__link">
    <span class="md-ellipsis">
      TCPStore
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#进程组" class="md-nav__link">
    <span class="md-ellipsis">
      进程组
    </span>
  </a>
  
    <nav class="md-nav" aria-label="进程组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#new_group" class="md-nav__link">
    <span class="md-ellipsis">
      new_group()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#点对点通信" class="md-nav__link">
    <span class="md-ellipsis">
      点对点通信
    </span>
  </a>
  
    <nav class="md-nav" aria-label="点对点通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#send" class="md-nav__link">
    <span class="md-ellipsis">
      send()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recv" class="md-nav__link">
    <span class="md-ellipsis">
      recv()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isend" class="md-nav__link">
    <span class="md-ellipsis">
      isend()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#irecv" class="md-nav__link">
    <span class="md-ellipsis">
      irecv()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#集体通信" class="md-nav__link">
    <span class="md-ellipsis">
      集体通信
    </span>
  </a>
  
    <nav class="md-nav" aria-label="集体通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#broadcast" class="md-nav__link">
    <span class="md-ellipsis">
      broadcast()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduce" class="md-nav__link">
    <span class="md-ellipsis">
      reduce()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_reduce" class="md-nav__link">
    <span class="md-ellipsis">
      all_reduce()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gather" class="md-nav__link">
    <span class="md-ellipsis">
      gather()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      all_gather()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_to_all" class="md-nav__link">
    <span class="md-ellipsis">
      all_to_all()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#barrier" class="md-nav__link">
    <span class="md-ellipsis">
      barrier()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduceop" class="md-nav__link">
    <span class="md-ellipsis">
      ReduceOp
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rpc" class="md-nav__link">
    <span class="md-ellipsis">
      RPC
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RPC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_rpc" class="md-nav__link">
    <span class="md-ellipsis">
      init_rpc()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_sync" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_sync()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_async" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_async()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote" class="md-nav__link">
    <span class="md-ellipsis">
      remote()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shutdown" class="md-nav__link">
    <span class="md-ellipsis">
      shutdown()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workerinfo" class="md-nav__link">
    <span class="md-ellipsis">
      WorkerInfo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_worker_info" class="md-nav__link">
    <span class="md-ellipsis">
      get_worker_info()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backendtype" class="md-nav__link">
    <span class="md-ellipsis">
      BackendType
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BackendType">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backendtypetensorpipe" class="md-nav__link">
    <span class="md-ellipsis">
      BackendType.TENSORPIPE
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpcbackendoptions" class="md-nav__link">
    <span class="md-ellipsis">
      RpcBackendOptions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RpcBackendOptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_method" class="md-nav__link">
    <span class="md-ellipsis">
      init_method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_timeout" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_timeout
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorpiperpcbackendoptions" class="md-nav__link">
    <span class="md-ellipsis">
      TensorPipeRpcBackendOptions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorPipeRpcBackendOptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#device_maps-devices-init_method-num_worker_threads-rpc_timeout" class="md-nav__link">
    <span class="md-ellipsis">
      device_maps, devices, init_method, num_worker_threads, rpc_timeout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_device_map" class="md-nav__link">
    <span class="md-ellipsis">
      set_device_map()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_devices" class="md-nav__link">
    <span class="md-ellipsis">
      set_devices()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rref" class="md-nav__link">
    <span class="md-ellipsis">
      RRef
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RRef">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confirmed_by_owner" class="md-nav__link">
    <span class="md-ellipsis">
      confirmed_by_owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_owner" class="md-nav__link">
    <span class="md-ellipsis">
      is_owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local_value" class="md-nav__link">
    <span class="md-ellipsis">
      local_value()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#owner" class="md-nav__link">
    <span class="md-ellipsis">
      owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#owner_name" class="md-nav__link">
    <span class="md-ellipsis">
      owner_name()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote_1" class="md-nav__link">
    <span class="md-ellipsis">
      remote()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_async_1" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_async()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_sync_1" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_sync()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_here" class="md-nav__link">
    <span class="md-ellipsis">
      to_here()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#remotemodule" class="md-nav__link">
    <span class="md-ellipsis">
      RemoteModule
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RemoteModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_module_rref" class="md-nav__link">
    <span class="md-ellipsis">
      get_module_rref()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      remote_parameters()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式-autograd-框架" class="md-nav__link">
    <span class="md-ellipsis">
      分布式 Autograd 框架
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式 Autograd 框架">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward_1" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_gradients" class="md-nav__link">
    <span class="md-ellipsis">
      get_gradients()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式优化器" class="md-nav__link">
    <span class="md-ellipsis">
      分布式优化器
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式优化器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#distributedoptimizer" class="md-nav__link">
    <span class="md-ellipsis">
      DistributedOptimizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.fft, torch.linalg, torch.special
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-tensorboard.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lightning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: lightning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../horovod.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    horovod
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../nni/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    nni
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_8" id="__nav_5_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_8">
            <span class="md-nav__icon md-icon"></span>
            nni
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nni/tuner.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    调参器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    参考和工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            参考和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
        
          
          <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Linux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command-line-tool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令行工具
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文件格式
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            文件格式
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/yaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/xml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/markdown.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    编码
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            编码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/charset-and-encoding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    字符集和字符编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base64
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            文本工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/regular-expression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    正则表达式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/vim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vim
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    构建工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            构建工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/build-tool/make.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    make
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/git.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/vocabulary.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词汇表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    前端
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            前端
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-html.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple HTML
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-css.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple CSS
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#后端" class="md-nav__link">
    <span class="md-ellipsis">
      后端
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#初始化" class="md-nav__link">
    <span class="md-ellipsis">
      初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_process_group" class="md-nav__link">
    <span class="md-ellipsis">
      init_process_group()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_available()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_initialized" class="md-nav__link">
    <span class="md-ellipsis">
      is_initialized()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_mpi_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_mpi_available()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_nccl_available" class="md-nav__link">
    <span class="md-ellipsis">
      is_nccl_available()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#初始化后" class="md-nav__link">
    <span class="md-ellipsis">
      初始化后
    </span>
  </a>
  
    <nav class="md-nav" aria-label="初始化后">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backend" class="md-nav__link">
    <span class="md-ellipsis">
      Backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_backend-get_rank-get_world_size" class="md-nav__link">
    <span class="md-ellipsis">
      get_backend(), get_rank(), get_world_size()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式键值存储" class="md-nav__link">
    <span class="md-ellipsis">
      分布式键值存储
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式键值存储">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#store" class="md-nav__link">
    <span class="md-ellipsis">
      Store
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Store">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add" class="md-nav__link">
    <span class="md-ellipsis">
      add()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delete_key" class="md-nav__link">
    <span class="md-ellipsis">
      delete_key()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get" class="md-nav__link">
    <span class="md-ellipsis">
      get()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#num_keys" class="md-nav__link">
    <span class="md-ellipsis">
      num_keys()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wait" class="md-nav__link">
    <span class="md-ellipsis">
      wait()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#filestore" class="md-nav__link">
    <span class="md-ellipsis">
      FileStore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hashstore" class="md-nav__link">
    <span class="md-ellipsis">
      HashStore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tcpstore" class="md-nav__link">
    <span class="md-ellipsis">
      TCPStore
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#进程组" class="md-nav__link">
    <span class="md-ellipsis">
      进程组
    </span>
  </a>
  
    <nav class="md-nav" aria-label="进程组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#new_group" class="md-nav__link">
    <span class="md-ellipsis">
      new_group()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#点对点通信" class="md-nav__link">
    <span class="md-ellipsis">
      点对点通信
    </span>
  </a>
  
    <nav class="md-nav" aria-label="点对点通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#send" class="md-nav__link">
    <span class="md-ellipsis">
      send()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recv" class="md-nav__link">
    <span class="md-ellipsis">
      recv()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isend" class="md-nav__link">
    <span class="md-ellipsis">
      isend()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#irecv" class="md-nav__link">
    <span class="md-ellipsis">
      irecv()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#集体通信" class="md-nav__link">
    <span class="md-ellipsis">
      集体通信
    </span>
  </a>
  
    <nav class="md-nav" aria-label="集体通信">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#broadcast" class="md-nav__link">
    <span class="md-ellipsis">
      broadcast()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduce" class="md-nav__link">
    <span class="md-ellipsis">
      reduce()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_reduce" class="md-nav__link">
    <span class="md-ellipsis">
      all_reduce()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gather" class="md-nav__link">
    <span class="md-ellipsis">
      gather()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      all_gather()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all_to_all" class="md-nav__link">
    <span class="md-ellipsis">
      all_to_all()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#barrier" class="md-nav__link">
    <span class="md-ellipsis">
      barrier()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reduceop" class="md-nav__link">
    <span class="md-ellipsis">
      ReduceOp
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rpc" class="md-nav__link">
    <span class="md-ellipsis">
      RPC
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RPC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_rpc" class="md-nav__link">
    <span class="md-ellipsis">
      init_rpc()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_sync" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_sync()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_async" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_async()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote" class="md-nav__link">
    <span class="md-ellipsis">
      remote()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shutdown" class="md-nav__link">
    <span class="md-ellipsis">
      shutdown()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workerinfo" class="md-nav__link">
    <span class="md-ellipsis">
      WorkerInfo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_worker_info" class="md-nav__link">
    <span class="md-ellipsis">
      get_worker_info()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backendtype" class="md-nav__link">
    <span class="md-ellipsis">
      BackendType
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BackendType">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backendtypetensorpipe" class="md-nav__link">
    <span class="md-ellipsis">
      BackendType.TENSORPIPE
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpcbackendoptions" class="md-nav__link">
    <span class="md-ellipsis">
      RpcBackendOptions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RpcBackendOptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#init_method" class="md-nav__link">
    <span class="md-ellipsis">
      init_method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_timeout" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_timeout
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorpiperpcbackendoptions" class="md-nav__link">
    <span class="md-ellipsis">
      TensorPipeRpcBackendOptions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorPipeRpcBackendOptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#device_maps-devices-init_method-num_worker_threads-rpc_timeout" class="md-nav__link">
    <span class="md-ellipsis">
      device_maps, devices, init_method, num_worker_threads, rpc_timeout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_device_map" class="md-nav__link">
    <span class="md-ellipsis">
      set_device_map()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_devices" class="md-nav__link">
    <span class="md-ellipsis">
      set_devices()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rref" class="md-nav__link">
    <span class="md-ellipsis">
      RRef
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RRef">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confirmed_by_owner" class="md-nav__link">
    <span class="md-ellipsis">
      confirmed_by_owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_owner" class="md-nav__link">
    <span class="md-ellipsis">
      is_owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local_value" class="md-nav__link">
    <span class="md-ellipsis">
      local_value()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#owner" class="md-nav__link">
    <span class="md-ellipsis">
      owner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#owner_name" class="md-nav__link">
    <span class="md-ellipsis">
      owner_name()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote_1" class="md-nav__link">
    <span class="md-ellipsis">
      remote()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_async_1" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_async()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rpc_sync_1" class="md-nav__link">
    <span class="md-ellipsis">
      rpc_sync()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to_here" class="md-nav__link">
    <span class="md-ellipsis">
      to_here()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#remotemodule" class="md-nav__link">
    <span class="md-ellipsis">
      RemoteModule
    </span>
  </a>
  
    <nav class="md-nav" aria-label="RemoteModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_module_rref" class="md-nav__link">
    <span class="md-ellipsis">
      get_module_rref()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remote_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      remote_parameters()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式-autograd-框架" class="md-nav__link">
    <span class="md-ellipsis">
      分布式 Autograd 框架
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式 Autograd 框架">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward_1" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_gradients" class="md-nav__link">
    <span class="md-ellipsis">
      get_gradients()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#分布式优化器" class="md-nav__link">
    <span class="md-ellipsis">
      分布式优化器
    </span>
  </a>
  
    <nav class="md-nav" aria-label="分布式优化器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#distributedoptimizer" class="md-nav__link">
    <span class="md-ellipsis">
      DistributedOptimizer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="torchdistributed">torch.distributed<a class="headerlink" href="#torchdistributed" title="Permanent link">&para;</a></h1>
<p><code>torch.distributed</code> 包为跨多个计算节点的多进程并行提供了 PyTorch 支持和通信原语。建立在此功能上的 <code>torch.nn.parallel.DistributedDataParallel</code> 类提供了 PyTorch 模型的同步训练的包装器，它与 <code>torch.multiprocessing</code> 提供的并行方法以及 <code>torch.nn.DataParallel</code> 的不同之处在于它支持在由网络连接的多台机器上运行，以及用户必须显式地为每个进程启动一个训练脚本的一个单独的副本。</p>
<p>即使是单台机器上的同步训练，<code>torch.nn.parallel.DistributedDataParallel</code> 包装器也相对于其他数据并行的方法具有优势，因为其每个进程都拥有单独的 Python 解释器，消除了 GIL 锁对于性能的限制。</p>
<h2 id="后端">后端<a class="headerlink" href="#后端" title="Permanent link">&para;</a></h2>
<p><code>torch.distributed</code> 支持三种后端：GLOO、MPI 和 NCCL，它们各自的适用条件请参考<a href="https://pytorch.org/docs/stable/distributed.html#backends">官方文档</a>。</p>
<h2 id="初始化">初始化<a class="headerlink" href="#初始化" title="Permanent link">&para;</a></h2>
<h3 id="init_process_group">init_process_group()<a class="headerlink" href="#init_process_group" title="Permanent link">&para;</a></h3>
<p>初始化默认的分布式进程组，同时初始化 <code>torch.distributed</code> 包。阻塞进程直到所有进程已经加入。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1800</span><span class="p">),</span> <span class="n">world_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rank</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">store</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">group_name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">pg_options</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># backend      使用的后端,可以是`&#39;mpi&#39;`,`&#39;gloo&#39;`或`&#39;nccl&#39;`,取决于构建时的设置.如果使用NCCL后端并且一台机器上</span>
<span class="c1">#              有多个进程,那么每个进程必须对其使用的每个GPU有排他的访问权,否则进程间共享GPU可能会造成死锁</span>
<span class="c1"># init_method  指明如何初始化进程组的URL.如果`init_method`和`store`都没有指定,则默认为&#39;env://&#39;.与`store`互斥</span>
<span class="c1"># world_size   参与任务的进程数</span>
<span class="c1"># rank         当前进程的rank</span>
<span class="c1"># store        对于所有worker可见的键值存储,用于交换连接/地址信息.与`init_method`互斥</span>
<span class="c1"># timeout      进程组执行操作的超时时间,默认为30min,对于gloo后端适用</span>
<span class="c1"># group_name   进程组名称</span>
<span class="c1"># pg_options</span>
</code></pre></div>
<p>目前支持以下三种初始化方法：</p>
<ul>
<li><strong>TCP 初始化</strong></li>
</ul>
<p>此方法需要指定一个属于 rank 0 进程的所有进程都可以访问的网络地址，各进程的 rank，以及 <code>world_size</code>。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="c1"># Use address of one of the machines</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;tcp://10.1.1.20:23456&#39;</span><span class="p">,</span>
                        <span class="n">rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><strong>共享文件系统初始化</strong></li>
</ul>
<p>此方法需要指定一个对所有进程可见的共享文件系统，以及 <code>world_size</code>。URL 应以 <code>file://</code> 开头，并且包含一个到已经存在的目录下的不存在的文件的路径。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="c1"># rank should always be specified</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;file:///mnt/nfs/sharedfile&#39;</span><span class="p">,</span>
                        <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><strong>环境变量初始化</strong></li>
</ul>
<p>此方法从环境变量中读取配置，允许用户完全自定义配置信息。需要设置的变量有：</p>
<ul>
<li><code>MASTER_ADDR</code>：rank 0 进程所在节点的网络地址。</li>
<li><code>MASTER_PORT</code>：rank 0 进程所在节点的一个空闲端口号，rank 0 进程将监听此端口并负责建立所有链接。</li>
<li><code>WORLD_SIZE</code>：进程数，rank 0 进程据此确定要等待来自多少个进程的连接。可以设为环境变量或直接传入初始化函数。</li>
<li><code>RANK</code>：当前进程的 rank，进程据此确定自己是否是 rank 0 进程。可以设为环境变量或直接传入初始化函数。</li>
</ul>
<p>此方法为默认方法。</p>
<div class="highlight"><pre><span></span><code><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>
<h3 id="is_available">is_available()<a class="headerlink" href="#is_available" title="Permanent link">&para;</a></h3>
<p>返回 <code>torch.distributed</code> 包是否可用。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="is_initialized">is_initialized()<a class="headerlink" href="#is_initialized" title="Permanent link">&para;</a></h3>
<p>返回默认进程组是否已经初始化。</p>
<h3 id="is_mpi_available">is_mpi_available()<a class="headerlink" href="#is_mpi_available" title="Permanent link">&para;</a></h3>
<p>返回 MPI 后端是否可用。</p>
<h3 id="is_nccl_available">is_nccl_available()<a class="headerlink" href="#is_nccl_available" title="Permanent link">&para;</a></h3>
<p>返回 NCCL 后端是否可用。</p>
<h2 id="初始化后">初始化后<a class="headerlink" href="#初始化后" title="Permanent link">&para;</a></h2>
<h3 id="backend">Backend<a class="headerlink" href="#backend" title="Permanent link">&para;</a></h3>
<p>可用后端的枚举类，包括成员 <code>GlOO</code>, <code>MPI</code>, <code>NCCL</code>，对应的值分别为字符串 <code>'gloo'</code>, <code>'mpi'</code>, <code>'nccl'</code>（即 <code>Backend.GLOO == 'gloo'</code>）。</p>
<p>可以直接调用此类以解析字符串，例如 <code>Backend('GLOO')</code> 将返回 <code>'gloo'</code>。</p>
<h3 id="get_backend-get_rank-get_world_size">get_backend(), get_rank(), get_world_size()<a class="headerlink" href="#get_backend-get_rank-get_world_size" title="Permanent link">&para;</a></h3>
<p>返回指定进程组的后端、rank 和进程数，默认为当前进程组。</p>
<h2 id="分布式键值存储">分布式键值存储<a class="headerlink" href="#分布式键值存储" title="Permanent link">&para;</a></h2>
<p>分布式键值存储用于在一个进程组的各进程之间共享数据或者初始化进程组，共有 3 种类型：<code>TCPStore</code>、<code>FileStore</code> 和 <code>HashStore</code>。</p>
<h3 id="store">Store<a class="headerlink" href="#store" title="Permanent link">&para;</a></h3>
<p>存储的基类。</p>
<h4 id="add">add()<a class="headerlink" href="#add" title="Permanent link">&para;</a></h4>
<h4 id="delete_key">delete_key()<a class="headerlink" href="#delete_key" title="Permanent link">&para;</a></h4>
<h4 id="get">get()<a class="headerlink" href="#get" title="Permanent link">&para;</a></h4>
<h4 id="num_keys">num_keys()<a class="headerlink" href="#num_keys" title="Permanent link">&para;</a></h4>
<h4 id="wait">wait()<a class="headerlink" href="#wait" title="Permanent link">&para;</a></h4>
<h3 id="filestore">FileStore<a class="headerlink" href="#filestore" title="Permanent link">&para;</a></h3>
<h3 id="hashstore">HashStore<a class="headerlink" href="#hashstore" title="Permanent link">&para;</a></h3>
<h3 id="tcpstore">TCPStore<a class="headerlink" href="#tcpstore" title="Permanent link">&para;</a></h3>
<p>基于 TCP 的分布式键值存储实现。存储服务器保存数据，而存储客户端则可以通过 TCP 连接到存储服务器。只能有一个存储服务器。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">TCPStore</span><span class="p">(</span><span class="n">host_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">port</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_master</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="n">timedelta</span> <span class="o">=</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">300</span><span class="p">),</span> <span class="n">wait_for_worker</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="c1"># host_name</span>
<span class="c1"># port</span>
<span class="c1"># world_size</span>
<span class="c1"># is_master</span>
<span class="c1"># timeout</span>
<span class="c1"># wait_for_worker</span>
</code></pre></div>
<h2 id="进程组">进程组<a class="headerlink" href="#进程组" title="Permanent link">&para;</a></h2>
<p>默认情况下集体通信操作在 world 上执行，并要求所有进程都进入该分布式函数调用。然而，更加细粒度的通信有利于一些工作负载，这时就可以使用进程组。<code>new_group()</code> 函数可以对所有进程的任意子集创建新的进程组，返回的不透明组句柄可以用作所有集体通信方法的 <code>group</code> 参数。</p>
<h3 id="new_group">new_group()<a class="headerlink" href="#new_group" title="Permanent link">&para;</a></h3>
<p>创建一个新的分布式进程组。</p>
<p>此函数要求所有进程都进入（调用）此函数，即使进程不会成为该进程组的成员。此外，所有进程中的 <code>ranks</code> 参数应该是相同的，包括 rank 的顺序。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">ranks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1800</span><span class="p">),</span> <span class="n">backend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pg_options</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># ranks       进程组成员的rank列表.若为None,则设定为所有进程的rank</span>
<span class="c1"># timeout     进程组执行操作的超时时间,默认为30min,对于gloo后端适用</span>
<span class="c1"># backend     使用的后端,可以是`gloo`和`nccl`,取决于构建时的设置.默认与world使用相同的后端</span>
<span class="c1"># pg_options  </span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">new_group</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  1  has data  tensor([2.])
Rank  0  has data  tensor([2.])
Rank  3  has data  tensor([1.])
Rank  2  has data  tensor([1.])
</code></pre></div>
<h2 id="点对点通信">点对点通信<a class="headerlink" href="#点对点通信" title="Permanent link">&para;</a></h2>
<h3 id="send">send()<a class="headerlink" href="#send" title="Permanent link">&para;</a></h3>
<p>同步地发送一个张量。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># tensor    发送的张量</span>
<span class="c1"># dst       目标rank</span>
<span class="c1"># group     工作的进程组.若为`None`,则设为world</span>
<span class="c1"># tag       用于与远程`recv`匹配的标签</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># rank 0 sends the tensor to rank 1</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># rank 1 receives tensor from rank 0</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  2  has data  tensor([0.])
Rank  3  has data  tensor([0.])
Rank  1  has data  tensor([1.])
Rank  0  has data  tensor([1.])
</code></pre></div>
<h3 id="recv">recv()<a class="headerlink" href="#recv" title="Permanent link">&para;</a></h3>
<p>同步地接收一个张量。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># tensor    放置接收数据的张量</span>
<span class="c1"># src       源rank.若为`None`,则接收来自任意进程的数据</span>
<span class="c1"># group     工作的进程组.若为`None`,则设为world</span>
<span class="c1"># tag       用于与远程`send`匹配的标签</span>
</code></pre></div>
<h3 id="isend">isend()<a class="headerlink" href="#isend" title="Permanent link">&para;</a></h3>
<p>异步地发送一个张量。</p>
<p><code>isend()</code> 和 <code>irecv()</code> 返回一个分布式请求对象，支持下面两个方法：</p>
<ul>
<li><code>is_completed()</code>：当操作结束时返回 <code>True</code></li>
<li><code>wait()</code>：阻塞进程直到操作结束。当 <code>wait()</code> 返回后，<code>is_completed()</code> 一定返回 <code>True</code></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># tensor    发送的张量</span>
<span class="c1"># dst       目标rank</span>
<span class="c1"># group     工作的进程组.若为`None`,则设为world</span>
<span class="c1"># tag       用于与远程`recv`匹配的标签</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># rank 0 sends the tensor to rank 1</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank 0 started sending&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># rank 1 receives tensor from rank 0</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">irecv</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank 1 started receiving&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">req</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank 1 started receiving
Rank 0 started sending
Rank  3  has data  tensor([0.])
Rank  2  has data  tensor([0.])
Rank  0  has data  tensor([1.])
Rank  1  has data  tensor([1.])
</code></pre></div>
<h3 id="irecv">irecv()<a class="headerlink" href="#irecv" title="Permanent link">&para;</a></h3>
<p>异步地接收一个张量。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">irecv</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># tensor    放置接收数据的张量</span>
<span class="c1"># src       源rank.若为`None`,则接收来自任意进程的数据</span>
<span class="c1"># group     工作的进程组.若为`None`,则设为world</span>
<span class="c1"># tag       用于与远程`send`匹配的标签</span>
</code></pre></div>
<h2 id="集体通信">集体通信<a class="headerlink" href="#集体通信" title="Permanent link">&para;</a></h2>
<p>每个集体通信操作函数都支持下面两种操作类型：</p>
<ul>
<li><strong>同步操作</strong>：当函数返回时，相应的集体通信操作会确保已经完成。但对于 CUDA 操作则不能确保其已经完成，因为 CUDA 操作是异步的。因此对于 CPU 集体通信操作，对其返回值的操作结果会符合预期；对于 CUDA 集体通信操作，在同一个 CUDA 流上对其返回值的操作结果会符合预期；在运行在不同 CUDA 流上的情形下，用户必须自己负责同步。</li>
<li><strong>异步操作</strong>：函数返回一个分布式请求对象，支持下面两个方法：</li>
<li><code>is_completed()</code>：对于 CPU 操作，当操作结束时返回 <code>True</code>；对于 GPU 操作，当操作成功进入排进一个 CUDA 流并且输出可以在默认流上使用（而无需进一步同步）时返回 <code>True</code>。</li>
<li><code>wait()</code>：对于 CPU 操作，阻塞进程直到操作结束；对于 GPU 操作，阻塞进程直到操作成功进入排进一个 CUDA 流并且输出可以在默认流上使用（而无需进一步同步）。</li>
</ul>
<div class="highlight"><pre><span></span><code>
</code></pre></div>
<h3 id="broadcast">broadcast()<a class="headerlink" href="#broadcast" title="Permanent link">&para;</a></h3>
<p>Broadcast 操作。参与到此集体通信操作的所有进程的 <code>tensor</code> 必须具有相同的形状。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor    若当前进程的rank是`src`,则为发送的张量,否则为放置接收数据的张量</span>
<span class="c1"># src       源rank</span>
<span class="c1"># group     工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op  是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  0  has data  tensor([1.])
Rank  1  has data  tensor([1.])
Rank  2  has data  tensor([1.])
Rank  3  has data  tensor([1.])
</code></pre></div>
<h3 id="reduce">reduce()<a class="headerlink" href="#reduce" title="Permanent link">&para;</a></h3>
<p>Reduce 操作。原位操作，rank 为 <code>dst</code> 的进程的 <code>tensor</code> 将放置最终归约结果，其他进程的 <code>tensor</code> 将放置中间结果。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">op</span><span class="o">=&lt;</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor      归约的张量兼放置归约结果的张量(原位操作,rank为`dst`的进程将放置最终结果,其他进程将放置中间结果)</span>
<span class="c1"># dst         目标rank</span>
<span class="c1"># op          归约操作,是`torch.distributed.ReduceOp`枚举类的实例之一</span>
<span class="c1"># group       工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op    是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">rank</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  3  has data  tensor([3.])        # 3.
Rank  2  has data  tensor([5.])        # 3. + 2.
Rank  1  has data  tensor([6.])        # 3. + 2. + 1.
Rank  0  has data  tensor([6.])        # 3. + 2. + 1. + 0.
</code></pre></div>
<h3 id="all_reduce">all_reduce()<a class="headerlink" href="#all_reduce" title="Permanent link">&para;</a></h3>
<p>All-Reduce 操作。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=&lt;</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor      归约的张量兼放置归约结果的张量(原位操作)</span>
<span class="c1"># op          归约操作,是`torch.distributed.ReduceOp`枚举类的实例之一</span>
<span class="c1"># group       工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op    是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">rank</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  0  has data  tensor([6.])
Rank  3  has data  tensor([6.])
Rank  2  has data  tensor([6.])
Rank  1  has data  tensor([6.])
</code></pre></div>
<h3 id="gather">gather()<a class="headerlink" href="#gather" title="Permanent link">&para;</a></h3>
<p>Gather 操作。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">gather_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor       收集的张量</span>
<span class="c1"># gather_list  放置收集数据的张量列表,必须包含正确数量和形状的张量元素(仅限rank为`dst`的进程)</span>
<span class="c1"># dst          目标rank</span>
<span class="c1"># group        工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op     是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">rank</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">gather_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span> <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">gather_list</span><span class="o">=</span><span class="n">gather_list</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has list &#39;</span><span class="p">,</span> <span class="n">gather_list</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  0  has data  tensor([0.])
Rank  1  has data  tensor([1.])
Rank  2  has data  tensor([2.])
Rank  1  has list  []
Rank  2  has list  []
Rank  3  has data  tensor([3.])
Rank  3  has list  []
Rank  0  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
</code></pre></div>
<h3 id="all_gather">all_gather()<a class="headerlink" href="#all_gather" title="Permanent link">&para;</a></h3>
<p>All-Gather 操作。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor_list  放置收集数据的张量列表,必须包含正确数量和形状的张量元素</span>
<span class="c1"># tensor       收集的张量</span>
<span class="c1"># group        工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op     是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">rank</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tensor_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has list &#39;</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  0  has data  tensor([0.])
Rank  1  has data  tensor([1.])
Rank  2  has data  tensor([2.])
Rank  3  has data  tensor([3.])
Rank  0  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
Rank  2  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
Rank  1  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
Rank  3  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
</code></pre></div>
<h3 id="all_to_all">all_to_all()<a class="headerlink" href="#all_to_all" title="Permanent link">&para;</a></h3>
<p>All-to-All 操作。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">output_tensor_list</span><span class="p">,</span> <span class="n">input_tensor_list</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># output_tensor_list   放置分发数据的张量列表</span>
<span class="c1"># input_tensor_list    分发的张量列表</span>
<span class="c1"># group         工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op      是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">input_tensor_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">rank</span> <span class="o">*</span> <span class="n">size</span> <span class="o">+</span> <span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
    <span class="n">output_tensor_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">output_tensor_list</span><span class="o">=</span><span class="n">output_tensor_list</span><span class="p">,</span> <span class="n">input_tensor_list</span><span class="o">=</span><span class="n">input_tensor_list</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has input list &#39;</span><span class="p">,</span> <span class="n">input_tensor_list</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has output list &#39;</span><span class="p">,</span> <span class="n">output_tensor_list</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>RuntimeError: ProcessGroup does not support alltoall
</code></pre></div>
<h3 id="scatter">scatter()<a class="headerlink" href="#scatter" title="Permanent link">&para;</a></h3>
<p>Scatter 操作。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">scatter_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># tensor        放置分发数据的张量</span>
<span class="c1"># scatter_list  分发的张量列表</span>
<span class="c1"># src           源rank</span>
<span class="c1"># group         工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op      是否为异步操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">scatter_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span> <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">scatter_list</span><span class="o">=</span><span class="n">scatter_list</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has list &#39;</span><span class="p">,</span> <span class="n">scatter_list</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Rank  2  has list  []
Rank  1  has list  []
Rank  3  has list  []
Rank  3  has data  tensor([3.])
Rank  1  has data  tensor([1.])
Rank  2  has data  tensor([2.])
Rank  0  has list  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]
Rank  0  has data  tensor([0.])
</code></pre></div>
<h3 id="barrier">barrier()<a class="headerlink" href="#barrier" title="Permanent link">&para;</a></h3>
<p>同步所有进程，即阻塞进入此函数的进程，直到进程组的所有进程全部进入此函数。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># group         工作的进程组.若为`None`,则设为world</span>
<span class="c1"># async_op      是否为异步操作</span>
<span class="c1"># device_ids    GPU设备的id列表,仅对NCCL后端有效</span>
</code></pre></div>
<h3 id="reduceop">ReduceOp<a class="headerlink" href="#reduceop" title="Permanent link">&para;</a></h3>
<p>可用归约操作的枚举类，包括成员：<code>SUM</code>, <code>PRODUCT</code>, <code>MIN</code>, <code>MAX</code>, <code>BAND</code>, <code>BOR</code>, <code>BXOR</code>。</p>
<p>注意 <code>BAND</code>, <code>BOR</code>, <code>BXOR</code> 不适用于 <code>NCCL</code> 后端；<code>MAX</code>, <code>MIN</code>, <code>PRODUCT</code> 不适用于复张量。</p>
<h2 id="rpc">RPC<a class="headerlink" href="#rpc" title="Permanent link">&para;</a></h2>
<h3 id="init_rpc">init_rpc()<a class="headerlink" href="#init_rpc" title="Permanent link">&para;</a></h3>
<p>初始化诸如本地 RPC 代理和分布式 autograd 的 RPC 原语，这会立刻使当前进程准备好发送和接收 RPC。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rpc_backend_options</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># name        此进程的全局唯一名称(例如`Master`,`ps`,`Worker1`等)</span>
<span class="c1"># backend     RPC后端实现的类型,默认为`Backend.TENSORPIPE`</span>
<span class="c1"># rank        此进程的全局唯一rank</span>
<span class="c1"># world_size  组内的工作器数量</span>
<span class="c1"># rpc_backend_options</span>
</code></pre></div>
<h3 id="rpc_sync">rpc_sync()<a class="headerlink" href="#rpc_sync" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="n">to</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># to          目标工作器的名称/rank/`WorkerInfo`实例</span>
<span class="c1"># func        函数,例如Python可调用对象、Python内置函数和被注解的TorchScript函数</span>
<span class="c1"># args        传递给`func`的参数元组</span>
<span class="c1"># kwargs      传递给`func`的关键字参数字典</span>
<span class="c1"># timeout     此远程调用的超时时间(秒).0表示永不超时.若此参数没有提供,则使用初始化期间设定的默认值</span>
</code></pre></div>
<p>进行一次阻塞的 RPC 调用以在工作器 <code>to</code> 上运行函数 <code>func</code>。RPC 消息的发送和接收相对于 Python 代码的执行是并行的。此方法是线程安全的。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s1">&#39;worker0&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="s1">&#39;worker1&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ret</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s1">&#39;worker1&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>使用 <code>rpc_sync()</code>、<code>rpc_async()</code> 等 API 时，函数的参数张量和返回值张量都必须是 CPU 张量（否则当两个进程的设备列表不一致时可能会引起崩溃）。如有必要，应用可以显式地在调用进程中将张量移动到 CPU，再在被调用进程中将其移动到想要的设备中。</p>
</div>
<h3 id="rpc_async">rpc_async()<a class="headerlink" href="#rpc_async" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">to</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># to          目标工作器的名称/rank/`WorkerInfo`实例</span>
<span class="c1"># func        函数,例如Python可调用对象、Python内置函数和被注解的TorchScript函数</span>
<span class="c1"># args        传递给`func`的参数元组</span>
<span class="c1"># kwargs      传递给`func`的关键字参数字典</span>
<span class="c1"># timeout     此远程调用的超时时间(秒).0表示永不超时.若此参数没有提供,则使用初始化期间设定的默认值</span>
</code></pre></div>
<p>进行一次非阻塞的 RPC 调用以在工作器 <code>to</code> 上运行函数 <code>func</code>，并立即返回一个 <code>Future</code> 实例。RPC 消息的发送和接收相对于 Python 代码的执行是并行的。此方法是线程安全的。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s1">&#39;worker0&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fut1</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="s1">&#39;worker1&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fut2</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="s1">&#39;worker1&#39;</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">fut1</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span> <span class="o">+</span> <span class="n">fut2</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s1">&#39;worker1&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p><code>rpc_async()</code> API 会等到要通过网络发送参数时才复制这些参数（包括其中的张量），这会由另一个线程完成，取决于 RPC 后端的类型。调用进程应确保参数张量的内容保持不变直到返回的 <code>Future</code> 实例得到返回值。</p>
</div>
<h3 id="remote">remote()<a class="headerlink" href="#remote" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">to</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># to          目标工作器的名称/rank/`WorkerInfo`实例</span>
<span class="c1"># func        函数,例如Python可调用对象、Python内置函数和被注解的TorchScript函数</span>
<span class="c1"># args        传递给`func`的参数元组</span>
<span class="c1"># kwargs      传递给`func`的关键字参数字典</span>
<span class="c1"># timeout     此远程调用的超时时间(秒).0表示永不超时.若此参数没有提供,则使用初始化期间设定的默认值</span>
</code></pre></div>
<p>进行一次远程调用以在工作器 <code>to</code> 上运行函数 <code>func</code>，并立即返回一个指向返回值的 <code>RRef</code> 实例。工作器 <code>to</code> 是返回的 <code>RRef</code> 实例的所有者，而调用进程则是使用者。所有者管理 <code>RRef</code> 实例的全局引用计数，并在计数归零（即全局不再有任何对它的引用）时销毁该实例。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker0&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>    <span class="c1"># 阻塞</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref1</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref2</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">rref1</span><span class="o">.</span><span class="n">to_here</span><span class="p">()</span> <span class="o">+</span> <span class="n">rref2</span><span class="o">.</span><span class="n">to_here</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>    <span class="c1"># 阻塞</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>    <span class="c1"># 阻塞</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>    <span class="c1"># 阻塞</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p><code>remote()</code> API 会等到要通过网络发送参数时才复制这些参数（包括其中的张量），这会由另一个线程完成，取决于 RPC 后端的类型。调用进程应确保参数张量的内容保持不变直到返回的 <code>RRef</code> 实例被其所有者确认，可以通过 <code>torch.distributed.rpc.RRef.confirmed_by_owner()</code> API 进行检查。</p>
</div>
<h3 id="shutdown">shutdown()<a class="headerlink" href="#shutdown" title="Permanent link">&para;</a></h3>
<p>关闭 RPC 代理并随后销毁。这将阻止本地代理接收外部请求，并通过停止所有 RPC 线程关闭 RPC 框架。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">graceful</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># graceful       若为`True`,则会阻塞直到(1)不再有挂起的`UserRRefs`系统消息,同时删除这些消息</span>
<span class="c1">#                (2)所有本地和远程RPC进程到达此方法并且等待所有外部工作结束</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker0&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>    <span class="c1"># 阻塞</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># on worker 1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>    <span class="c1"># 阻塞</span>
</code></pre></div>
<h3 id="workerinfo">WorkerInfo<a class="headerlink" href="#workerinfo" title="Permanent link">&para;</a></h3>
<p>包装了工作器信息的结构，其中包含工作器的名称和 ID。此类的实例不应直接构造，而应通过 <code>get_worker_info()</code> 函数获取；实例可用于传入诸如 <code>rpc_sync()</code>、<code>rpc_async()</code>、<code>remote()</code> 等函数以避免每次远程调用都要复制字符串。</p>
<h3 id="get_worker_info">get_worker_info()<a class="headerlink" href="#get_worker_info" title="Permanent link">&para;</a></h3>
<p>获取指定工作器的 <code>WorkerInfo</code>。使用此 <code>WorkerInfo</code> 实例以避免每次远程调用都传递昂贵的字符串。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">get_worker_info</span><span class="p">(</span><span class="n">worker_name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># worker_name    工作器的字符串名称</span>
</code></pre></div>
<h3 id="backendtype">BackendType<a class="headerlink" href="#backendtype" title="Permanent link">&para;</a></h3>
<p>可用后端的枚举类。</p>
<p>PyTorch 内置一个 <code>BackendType.TENSORPIPE</code> 后端；可以使用 <code>register_backend()</code> 函数来注册更多的后端。</p>
<h4 id="backendtypetensorpipe">BackendType.TENSORPIPE<a class="headerlink" href="#backendtypetensorpipe" title="Permanent link">&para;</a></h4>
<p>默认使用的 TensorPipe 代理利用了 TensorPipe 库，其提供了一个原生的点对点的通信原语，从根本上解决了 Gloo 的一些局限性，因而特别适用于机器学习。相比 Gloo，其优势在于它是异步的，允许大量转移操作同时进行，而不会互相阻塞或影响运行速度。进程对之间的管道只有在需要时才会打开；当一个进程故障时只有它相关的管道会被关闭，而其他管道都会照常工作。此外，TensorPipe 还支持多种传输方式（TCP、共享内存、NVLink、InfiniBand 等），能够自动检测这些方式的可用性并为每个管道选择最佳的传输方式。</p>
<p>TensorPipe 后端自 PyTorch v1.6 版本被引入。目前它仅支持 CPU 张量，GPU 支持将在不久之后到来。它和 Gloo 一样使用基于 TCP 的连接。它还可以自动切分大型张量，在多个套接字和线程上多路复用以达成高带宽。</p>
<h3 id="rpcbackendoptions">RpcBackendOptions<a class="headerlink" href="#rpcbackendoptions" title="Permanent link">&para;</a></h3>
<p>包装了传入到 RPC 后端的选项的抽象结构。此类的实例可被传入到 <code>init_rpc()</code> 以使用特定配置初始化 RPC，例如 RPC 超时时间和使用的 <code>init_method</code>。</p>
<h4 id="init_method">init_method<a class="headerlink" href="#init_method" title="Permanent link">&para;</a></h4>
<p>指定如何初始化进程组的 URL，默认为 <code>env://</code>。</p>
<h4 id="rpc_timeout">rpc_timeout<a class="headerlink" href="#rpc_timeout" title="Permanent link">&para;</a></h4>
<p>指定所有 RPC 操作的超时时间的浮点数。</p>
<h3 id="tensorpiperpcbackendoptions">TensorPipeRpcBackendOptions<a class="headerlink" href="#tensorpiperpcbackendoptions" title="Permanent link">&para;</a></h3>
<p>TensorPipe 代理的后端选项，继承自 <code>RpcBackendOptions</code>。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">rpc</span><span class="o">.</span><span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">num_worker_threads</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">rpc_timeout</span><span class="o">=</span><span class="mf">60.0</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;env://&#39;</span><span class="p">,</span> <span class="n">device_maps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_transports</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># num_worker_threads   TensorPipe代理执行请求时使用的线程池中线程的数量</span>
<span class="c1"># rpc_timeout          默认的RPC请求的超时时间(秒).如果RPC没有在这一时间范围内完成,则引发一个</span>
<span class="c1">#                      相应的异常.调用进程可以为`rpc_sync()`和`rpc_async()`的RPC单独重载</span>
<span class="c1">#                      这一超时时间</span>
<span class="c1"># init_method          同`init_process_group()`的`init_method`参数</span>
<span class="c1"># device_maps          从调用进程到被调用进程的设备放置映射.其中键是被调用工作器的名称,值是映射</span>
<span class="c1">#                      调用进程的设备到被调用进程的设备的字典(设备用`int`,`str`或`torch.device`</span>
<span class="c1">#                      表示)</span>
<span class="c1"># devices              RPC代理使用的所有本地CUDA设备.默认从`device_maps`初始化得到.</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
    <span class="s2">&quot;worker1&quot;</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">rpc_backend_options</span><span class="o">=</span><span class="n">rpc</span><span class="o">.</span><span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span>
        <span class="n">num_worker_threads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">rpc_timeout</span><span class="o">=</span><span class="mi">20</span>    <span class="c1"># 20 second timeout</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="device_maps-devices-init_method-num_worker_threads-rpc_timeout">device_maps, devices, init_method, num_worker_threads, rpc_timeout<a class="headerlink" href="#device_maps-devices-init_method-num_worker_threads-rpc_timeout" title="Permanent link">&para;</a></h4>
<p>见 <code>TensorPipeRpcBackendOptions</code> 初始化函数。</p>
<h4 id="set_device_map">set_device_map()<a class="headerlink" href="#set_device_map" title="Permanent link">&para;</a></h4>
<p>设定调用进程和被调用进程之间的设备映射。此函数可以被多次调用以逐渐增加设备放置的设置。</p>
<div class="highlight"><pre><span></span><code><span class="n">set_device_map</span><span class="p">(</span><span class="n">to</span><span class="p">,</span> <span class="n">device_map</span><span class="p">)</span>
<span class="c1"># to           被调用进程的名称</span>
<span class="c1"># device_map   从当前进程到被调用进程的设备放置映射</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># on both workers</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># `tensor([1., 1.], device=&#39;cuda:1&#39;)` on worker 1</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">options</span> <span class="o">=</span> <span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">num_worker_threads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">device_maps</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;worker1&quot;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">}}</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="c1"># maps worker0&#39;s cuda:0 to worker1&#39;s cuda:1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">options</span><span class="o">.</span><span class="n">set_device_map</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># maps worker0&#39;s cuda:1 to worker1&#39;s cuda:2</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="s2">&quot;worker0&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">backend</span><span class="o">=</span><span class="n">rpc</span><span class="o">.</span><span class="n">BackendType</span><span class="o">.</span><span class="n">TENSORPIPE</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">rpc_backend_options</span><span class="o">=</span><span class="n">options</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rets</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># The first argument will be moved to cuda:1 on worker1. When</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># sending the return value back, it will follow the invert of</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># the device map, and hence will be moved back to cuda:0 and</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># cuda:1 on worker0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">rets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># `tensor([2., 2.], device=&#39;cuda:0&#39;)` on worker 0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">rets</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># `tensor([2., 2.], device=&#39;cuda:1&#39;)` on worker 0</span>
</code></pre></div>
<h4 id="set_devices">set_devices()<a class="headerlink" href="#set_devices" title="Permanent link">&para;</a></h4>
<p>设定 TensorPipe 代理使用的本地设备。</p>
<div class="highlight"><pre><span></span><code><span class="n">set_devices</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span>
<span class="c1"># devices      TensorPipe 代理使用的本地设备,是`int`,`str`或`torch.device`列表</span>
</code></pre></div>
<h3 id="rref">RRef<a class="headerlink" href="#rref" title="Permanent link">&para;</a></h3>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>RRef 目前尚不支持 CUDA 张量。</p>
</div>
<p>一个 <code>RRef</code> 实例是对远程工作器上的一个某种类型的值的引用。这种处理方式使被引用的远程值仍位于其所有者上。RRef 可用于多机训练，通过保有对存在于其他工作器上的 <code>nn.Modules</code> 实例的引用，并在训练过程中调用适当的函数以获取或修改其参数。</p>
<h4 id="backward">backward()<a class="headerlink" href="#backward" title="Permanent link">&para;</a></h4>
<p>以此 <code>RRef</code> 实例为根进行反向计算。……</p>
<div class="highlight"><pre><span></span><code><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist_autograd_ctx_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># dist_autograd_ctx_id   要获取的梯度所位于的分布式autograd上下文的id</span>
<span class="c1"># retain_graph           </span>
</code></pre></div>
<h4 id="confirmed_by_owner">confirmed_by_owner()<a class="headerlink" href="#confirmed_by_owner" title="Permanent link">&para;</a></h4>
<p>返回此 <code>RRef</code> 实例是否被其所有者确认。所有者的 <code>RRef</code> 实例总是返回 <code>True</code>，而使用者的 <code>RRef</code> 实例只有当所有者知道此实例时才返回 <code>True</code>。</p>
<h4 id="is_owner">is_owner()<a class="headerlink" href="#is_owner" title="Permanent link">&para;</a></h4>
<p>返回当前进程是否是此 <code>RRef</code> 实例的所有者。</p>
<h4 id="local_value">local_value()<a class="headerlink" href="#local_value" title="Permanent link">&para;</a></h4>
<p>若当前进程是所有者，则返回对本地值的一个引用，否则引发一个异常。</p>
<h4 id="owner">owner()<a class="headerlink" href="#owner" title="Permanent link">&para;</a></h4>
<p>返回此 <code>RRef</code> 实例的所有者的 <code>WorkerInfo</code> 实例。</p>
<h4 id="owner_name">owner_name()<a class="headerlink" href="#owner_name" title="Permanent link">&para;</a></h4>
<p>返回此 <code>RRef</code> 实例的所有者的名称。</p>
<h4 id="remote_1">remote()<a class="headerlink" href="#remote_1" title="Permanent link">&para;</a></h4>
<p>创建一个辅助代理以简单地启动一个 <code>remote</code>，其以此 <code>RRef</code> 实例的所有者为目标工作器运行此 <code>RRef</code> 实例所引用对象的指定方法。更具体地，<code>rref.remote().func_name(*args, **kwargs)</code> 相当于：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">local_value</span><span class="p">(),</span> <span class="n">func_name</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">owner</span><span class="p">(),</span> <span class="n">run</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">remote</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">to_here</span><span class="p">()</span>      <span class="c1"># returns torch.Size([2, 2])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">remote</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">to_here</span><span class="p">()</span>  <span class="c1"># returns tensor([[1., 1., 1., 1.]])</span>
</code></pre></div>
<h4 id="rpc_async_1">rpc_async()<a class="headerlink" href="#rpc_async_1" title="Permanent link">&para;</a></h4>
<p>创建一个辅助代理以简单地启动一个 <code>rpc_async</code>，其以此 <code>RRef</code> 实例的所有者为目标工作器运行此 <code>RRef</code> 实例所引用对象的指定方法。更具体地，<code>rref.rpc_async().func_name(*args, **kwargs)</code> 相当于：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">local_value</span><span class="p">(),</span> <span class="n">func_name</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">owner</span><span class="p">(),</span> <span class="n">run</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>      <span class="c1"># returns torch.Size([2, 2])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>  <span class="c1"># returns tensor([[1., 1., 1., 1.]])</span>
</code></pre></div>
<h4 id="rpc_sync_1">rpc_sync()<a class="headerlink" href="#rpc_sync_1" title="Permanent link">&para;</a></h4>
<p>创建一个辅助代理以简单地启动一个 <code>rpc_sync</code>，其以此 <code>RRef</code> 实例的所有者为目标工作器运行此 <code>RRef</code> 实例所引用对象的指定方法。更具体地，<code>rref.rpc_sync().func_name(*args, **kwargs)</code> 相当于：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">local_value</span><span class="p">(),</span> <span class="n">func_name</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="n">rref</span><span class="o">.</span><span class="n">owner</span><span class="p">(),</span> <span class="n">run</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">rref</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>      <span class="c1"># returns torch.Size([2, 2])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rref</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># returns tensor([[1., 1., 1., 1.]])</span>
</code></pre></div>
<h4 id="to_here">to_here()<a class="headerlink" href="#to_here" title="Permanent link">&para;</a></h4>
<p>阻塞调用，从所有者复制此 <code>RRef</code> 实例的值到本地进程并返回该值。如果当前进程就是所有者，则返回对本地值的一个引用。</p>
<h2 id="remotemodule">RemoteModule<a class="headerlink" href="#remotemodule" title="Permanent link">&para;</a></h2>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p><code>RemoteModule</code> 目前尚不支持 CUDA 张量。</p>
</div>
<p><code>RemoteModule</code> 实例只能在 RPC 初始化之后创建，其将用户指定的一个模块创建在指定的远程 RPC 进程上。<code>RemoteModule</code> 实例的行为就像是常规的 <code>nn.Module</code> 实例，除了其 <code>forward</code> 方法在远程进程中执行。它负责 autograd 记录以确保反向计算过程中将梯度传播回相应的远程模块。</p>
<p>它基于原模块类的 <code>forward</code> 方法的签名产生了 <code>forward_async</code> 和 <code>forward</code> 方法。<code>forward_async</code> 异步运行并返回一个 <code>Future</code>。<code>forward_async</code> 和 <code>forward</code> 方法的参数与原 <code>forward</code> 方法相同。</p>
<p>例如，如果原模块类返回一个 <code>nn.Linear</code> 的实例，其有 <code>forward</code> 方法签名：</p>
<p><code>def forward(input: Tensor) -&gt; Tensor</code></p>
<p>那么产生的 <code>RemoteModule</code> 实例将有如下的方法签名：</p>
<p><code>def forward(input: Tensor) -&gt; Tensor</code></p>
<p><code>def forward_async(input: Tensor) -&gt; Future[Tensor]</code></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">remote_module</span><span class="o">.</span><span class="n">RemoteModule</span><span class="p">(</span>
    <span class="n">remote_device</span><span class="p">,</span> <span class="n">module_cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span>
<span class="p">)</span>
<span class="c1"># remote_device   模块放置在目标工作器上的设备,格式应为`&quot;&lt;worker_name&gt;/&lt;device&gt;&quot;`,例如</span>
<span class="c1">#                 `&quot;trainer0/cpu&quot;``&quot;trainer0&quot;``&quot;ps0/cuda:0&quot;`.设备字段默认为&quot;cpu&quot;</span>
<span class="c1"># module_cls      要远程创建的模块的类</span>
<span class="c1"># args            要传给`module_cls`的参数</span>
<span class="c1"># kwargs          要传给`module_cls`的关键字参数</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># On worker 0:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">torch.distributed.nn.api.remote_module</span> <span class="kn">import</span> <span class="n">RemoteModule</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker0&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">remote_linear_module</span> <span class="o">=</span> <span class="n">RemoteModule</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="s2">&quot;worker1/cpu&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ret_future</span> <span class="o">=</span> <span class="n">remote_linear_module</span><span class="o">.</span><span class="n">forward_async</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">ret_future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># On worker 1:</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</code></pre></div>
<h3 id="get_module_rref">get_module_rref()<a class="headerlink" href="#get_module_rref" title="Permanent link">&para;</a></h3>
<p>返回引用远程模块的 <code>RRef</code> 实例。</p>
<h3 id="remote_parameters">remote_parameters()<a class="headerlink" href="#remote_parameters" title="Permanent link">&para;</a></h3>
<p>返回引用远程模块的参数的 <code>RRef</code> 实例列表。通常与 <code>DistributedOptimizer</code> 一起使用。</p>
<h2 id="分布式-autograd-框架">分布式 Autograd 框架<a class="headerlink" href="#分布式-autograd-框架" title="Permanent link">&para;</a></h2>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>分布式 autograd 目前尚不支持 CUDA 张量。</p>
</div>
<h3 id="backward_1">backward()<a class="headerlink" href="#backward_1" title="Permanent link">&para;</a></h3>
<p>使用给定的根开始分布式反向计算。当前实现的 <a href="https://pytorch.org/docs/master/rpc/distributed_autograd.html#fast-mode-algorithm">FAST 模式算法</a>假定在同一个分布式 autograd 上下文各工作器之间发送的所有 RPC 消息都是反向计算过程中 autograd 图的一部分。</p>
<p>我们使用给定的根来发现 autograd 图并计算其中的依赖关系。此方法会阻塞直到整个 autograd 计算完成。</p>
<p>我们在每一个进程中的适当的 <code>torch.distributed.autograd.context</code> 上下文中累积梯度。调用 <code>torch.distributed.autograd.backward()</code> 时传入的 <code>context_id</code> 用于查找使用的 autograd 上下文，如果没有有效的 autograd 上下文对应于给定的 ID，则抛出一个错误。你可以使用 <code>get_gradients()</code> API 获取累积的梯度。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">roots</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
<span class="c1"># context_id     用于获取梯度的autograd上下文ID</span>
<span class="c1"># roots          代表autograd计算的根的张量.所有的张量都应该为标量</span>
<span class="c1"># retain_graph   若为False,计算图在梯度计算完成后(backward()返回后)即被释放.注意在几</span>
<span class="c1">#                乎所有情形下将其设为True都是不必要的,因为总有更好的解决方法</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.autograd</span> <span class="k">as</span> <span class="nn">dist_autograd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">dist_autograd</span><span class="o">.</span><span class="n">context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context_id</span><span class="p">:</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>             <span class="c1"># 在远程进程中</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">dist_autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</code></pre></div>
<h3 id="context">context<a class="headerlink" href="#context" title="Permanent link">&para;</a></h3>
<p>使用分布式 autograd 时用于包装前向和反向计算的上下文对象。<code>with</code> 语句中生成的 <code>context_id</code> 必须在所有工作器上唯一地识别一次分布式反向计算。每个工作器保存与该 <code>context_id</code> 相关的元数据，这些对于正确执行分布式 autograd 计算是必须的。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.autograd</span> <span class="k">as</span> <span class="nn">dist_autograd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">dist_autograd</span><span class="o">.</span><span class="n">context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context_id</span><span class="p">:</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">loss</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>   <span class="n">dist_autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">,</span> <span class="p">[</span><span class="n">loss</span><span class="p">])</span>
</code></pre></div>
<h3 id="get_gradients">get_gradients()<a class="headerlink" href="#get_gradients" title="Permanent link">&para;</a></h3>
<p>获取张量到其相应梯度的一个映射，其中梯度累积在给定的 <code>context_id</code> 对应的上下文中。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.distributed.autograd</span> <span class="k">as</span> <span class="nn">dist_autograd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">dist_autograd</span><span class="o">.</span><span class="n">context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context_id</span><span class="p">:</span>
<span class="o">...</span>   <span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">...</span>   <span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">...</span>   <span class="n">loss</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_sync</span><span class="p">(</span><span class="s2">&quot;worker1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="o">...</span>   <span class="n">dist_autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">,</span> <span class="p">[</span><span class="n">loss</span><span class="p">])</span>
<span class="o">...</span>   <span class="n">grads</span> <span class="o">=</span> <span class="n">dist_autograd</span><span class="o">.</span><span class="n">get_gradients</span><span class="p">(</span><span class="n">context_id</span><span class="p">)</span>
<span class="o">...</span>   <span class="nb">print</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="n">t1</span><span class="p">])</span>
<span class="o">...</span>   <span class="nb">print</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="n">t2</span><span class="p">])</span>
<span class="o">...</span> 
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">grads</span>
<span class="p">{</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.9787</span><span class="p">,</span> <span class="mf">0.3666</span><span class="p">,</span> <span class="mf">0.9716</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.6967</span><span class="p">,</span> <span class="mf">0.4684</span><span class="p">,</span> <span class="mf">0.0524</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.8899</span><span class="p">,</span> <span class="mf">0.0569</span><span class="p">,</span> <span class="mf">0.2332</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span> <span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                                                                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                                                                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]),</span> 
 <span class="n">tensor</span><span class="p">([[</span><span class="mf">0.6230</span><span class="p">,</span> <span class="mf">0.7423</span><span class="p">,</span> <span class="mf">0.5838</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.0084</span><span class="p">,</span> <span class="mf">0.6071</span><span class="p">,</span> <span class="mf">0.9528</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.3312</span><span class="p">,</span> <span class="mf">0.6938</span><span class="p">,</span> <span class="mf">0.6464</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span> <span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                                                                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                                                                 <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])}</span>
</code></pre></div>
<h2 id="分布式优化器">分布式优化器<a class="headerlink" href="#分布式优化器" title="Permanent link">&para;</a></h2>
<h3 id="distributedoptimizer">DistributedOptimizer<a class="headerlink" href="#distributedoptimizer" title="Permanent link">&para;</a></h3>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    2023-12-11
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="../../../javascripts/tex-mml-chtml.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.cs/net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>