
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="xyx">
      
      
        <link rel="canonical" href="https://xyxxxxx.github.io/note/ml/platform-and-tool/pytorch/api-nn.html">
      
      
        <link rel="prev" href="api-torch.html">
      
      
        <link rel="next" href="api-nn-functional.html">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.1">
    
    
      
        <title>API: torch.nn - 笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.45e1311d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="light-green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torchnn" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="笔记" class="md-header__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API: torch.nn
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../index.html" class="md-tabs__link">
        
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/index.html" class="md-tabs__link">
          
  
    
  
  数学

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../cs/dsa/data-structure/index.html" class="md-tabs__link">
          
  
    
  
  CS

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../python/index.html" class="md-tabs__link">
          
  
    
  
  Python

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../index.html" class="md-tabs__link">
          
  
    
  
  机器学习

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../reference-and-tool/linux/linux-command.html" class="md-tabs__link">
          
  
    
  
  参考和工具

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../web/simple-html.html" class="md-tabs__link">
          
  
    
  
  前端

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="笔记" class="md-nav__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/algebra/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    代数
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            代数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/elementary-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra-understanding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数理解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/abstract-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    抽象代数
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/analysis/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分析
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/multivariate-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多元微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/matrix-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    矩阵微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/differential-equation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微分方程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/complex-analysis.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/mathematical-physics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学物理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    应用数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            应用数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/optimization/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学优化
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_2" id="__nav_2_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_2">
            <span class="md-nav__icon md-icon"></span>
            数学优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-set.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/duality.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对偶性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/nlp.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非线性优化
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    概率论与数理统计
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_3" id="__nav_2_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_3">
            <span class="md-nav__icon md-icon"></span>
            概率论与数理统计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/probability-of-event.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    事件的概率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/random-variable.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/limit-theorems.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    极限定理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/stochastic-process/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    随机过程
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_4" id="__nav_2_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_4">
            <span class="md-nav__icon md-icon"></span>
            随机过程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/stochastic-process-introduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机过程基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/markov-chain.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    马尔可夫链
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/poisson-process.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泊松过程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/discrete-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    离散数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            离散数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/mathematical-logic.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学逻辑
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/set-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    集合论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/enumerative-combinatorics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    组合数学
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/polynomial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多项式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/graph-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/number-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数论
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CS
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            CS
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    数据结构与算法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构与算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/data-structure/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数据结构
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/array-and-linked-list.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数组和链表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/stack-and-queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    栈和队列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/binary-search-tree.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    二叉搜索树
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/hash-table.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    哈希表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/graph.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/heap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    堆
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/algorithm/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    算法
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/common-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常见算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/divide-and-conquer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分而治之
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/dynamic-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动态规划
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/greedy-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贪心算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/backtracking.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回溯法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/network-flow-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络流算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/linear-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性规划
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/leetcode-examples.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leetcode 例题
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/net-model/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络模型
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2_2" id="__nav_3_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_2">
            <span class="md-nav__icon md-icon"></span>
            网络模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/transport-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    传输层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/network-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/application-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    应用层
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/information-theory/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    信息论
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            信息论
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/information-theory/entropy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    熵、相对熵与互信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Python
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/runtime-environment-devtool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运行环境与开发工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/data-type-and-operation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型与操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/control-flow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    控制流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/container-type.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    容器类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/iterator-and-generator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迭代器与生成器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/oop.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向对象编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/process-and-thread.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    进程与线程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/error-handling-and-unit-test.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    错误处理与单元测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/module-and-package.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模块与包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/standard-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    标准库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_13">
            <span class="md-nav__icon md-icon"></span>
            标准库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/argparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    argparse——命令行选项、参数和子命令解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base64——Base16, Base32, Base64, Base85 数据编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/builtins.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    builtins——内建对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.abc.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections.abc——容器的抽象基类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections——容器数据类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/configparser.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configparser——配置文件解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/concurrent.futures.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    concurrent.futures——启动并行任务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/copy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    copy——浅层和深层复制操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/csv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    csv——CSV 文件读写
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/datetime.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    datetime——基本日期和时间类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/enum.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    enum——对枚举的支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functions.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    内置函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    functools——高阶函数和可调用对象上的操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/glob.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    glob——Unix 风格路径名模式扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/graphlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphlib——操作类似图的结构的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hashlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hashlib——安全哈希与消息摘要
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hmac.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hmac——基于密钥的消息验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/importlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    importlib——import 的实现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/inspect.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    inspect——检查对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    io——处理流的核心工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/itertools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    itertools——为高效循环而创建迭代器的函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json——JSON 编码和解码器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/keyword.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    keyword——检验 Python 关键字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/marshal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marshal——内部 Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    math——数学函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    multiprocessing——基于进程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/operator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    operator——标准运算符替代函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os——多种操作系统接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.path.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os.path——常用路径操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pathlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pathlib——面向对象的文件系统路径
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pickle.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pickle——Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/platform.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    platform——获取底层平台的标识数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pprint.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pprint——数据美化输出
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    queue——一个同步的队列类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    random——生成伪随机数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/re.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    re——正则表达式操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/secrets.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    secrets——生成安全随机数字用于管理密码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/select.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    select——等待 I/O 完成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shlex.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shlex——简单的词法分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shutil.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shutil——高阶文件操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    signal——设置异步事件处理程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/socket.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    socket——底层网络接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/subprocess.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    subprocess——子进程管理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/sys.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sys——系统相关的参数和函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tarfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tarfile——读写 tar 归档文件
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tempfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tempfile——生成临时文件和目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/threading.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    threading——基于线程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/time.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    time——时间的访问和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/timeit.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timeit——测量小段代码的执行时间
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/types.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    types——动态类型创建和内置类型名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/typing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    typing——类型提示支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.parse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.parse——用于解析 URL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.request.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.request——用于打开 URL 的可扩展库
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/uuid.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    uuid——RFC 4122 定义的 UUID 对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/weakref.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    weakref——弱引用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/zipfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zipfile——使用 ZIP 存档
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/common-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    常用库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_14">
            <span class="md-nav__icon md-icon"></span>
            常用库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/beautifulsoup.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BeautifulSoup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/click.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    click
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/filelock.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    filelock
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pillow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pillow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pyyaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyYAML (yaml)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/requests.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    requests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/rich.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rich
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/websocket-client.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    websocket-client (websocket)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/style-guide.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    风格指南
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    机器学习
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    统计学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            统计学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/nb.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/perceptron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    感知器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/svm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    支持向量机
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/fnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前馈神经网络（FNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/cnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积神经网络（CNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    循环神经网络（RNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/seq2seq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列到序列模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/transformer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/self-supervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自监督学习模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/gan.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成对抗网络（GAN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rl.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/auto-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    常用技术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            常用技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/normalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    归一化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/generalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泛化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/anomaly-detection.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    异常检测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/adversarial-attack.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗攻击
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/explainable-ml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型可解释性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/transfer-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/model-compression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型压缩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/life-long-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    终身学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../nlp/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    自然语言处理专题
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            自然语言处理专题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/text-processing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    文本处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/language-model.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/sentiment-classification.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯和情感分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/logistic-regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    逻辑回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/neural-network.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/part-of-speech-tagging.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词性标注和命名实体检测
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../distributed/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分布式训练
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    平台和工具
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            平台和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../numpy/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    NumPy
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            NumPy
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../pandas/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pandas
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            pandas
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../matplotlib/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    matplotlib
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_4" id="__nav_5_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_4">
            <span class="md-nav__icon md-icon"></span>
            matplotlib
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matplotlib/example.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    示例
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../tensorflow/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_5" id="__nav_5_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_5">
            <span class="md-nav__icon md-icon"></span>
            TensorFlow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/tensorflow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-config.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-distribute.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.distribute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-image.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-keras.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.keras
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-linalg.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.linalg
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.math
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.random
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.signal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-strings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.strings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-train.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.train
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tfds.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tfds
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_6" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_6" id="__nav_5_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="pytorch.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchvision.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchserve.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchserve
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-torch.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    API: torch.nn
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="api-nn.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    API: torch.nn
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#容器" class="md-nav__link">
    <span class="md-ellipsis">
      容器
    </span>
  </a>
  
    <nav class="md-nav" aria-label="容器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module" class="md-nav__link">
    <span class="md-ellipsis">
      Module
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_module" class="md-nav__link">
    <span class="md-ellipsis">
      add_module()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    <span class="md-ellipsis">
      apply()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#buffers" class="md-nav__link">
    <span class="md-ellipsis">
      buffers()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#children" class="md-nav__link">
    <span class="md-ellipsis">
      children()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu" class="md-nav__link">
    <span class="md-ellipsis">
      cpu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eval" class="md-nav__link">
    <span class="md-ellipsis">
      eval()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_parameter" class="md-nav__link">
    <span class="md-ellipsis">
      get_parameter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_submodule" class="md-nav__link">
    <span class="md-ellipsis">
      get_submodule()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      load_state_dict()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modules" class="md-nav__link">
    <span class="md-ellipsis">
      modules()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_buffers" class="md-nav__link">
    <span class="md-ellipsis">
      named_buffers()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_children" class="md-nav__link">
    <span class="md-ellipsis">
      named_children()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      named_parameters()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      parameters()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_buffer" class="md-nav__link">
    <span class="md-ellipsis">
      register_buffer()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_forward_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_forward_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_pre_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_pre_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_full_backward_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_full_backward_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_parameter" class="md-nav__link">
    <span class="md-ellipsis">
      register_parameter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad_" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      state_dict()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to" class="md-nav__link">
    <span class="md-ellipsis">
      to()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    <span class="md-ellipsis">
      train()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#type" class="md-nav__link">
    <span class="md-ellipsis">
      type()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_grad" class="md-nav__link">
    <span class="md-ellipsis">
      zero_grad()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequential" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#线性层" class="md-nav__link">
    <span class="md-ellipsis">
      线性层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="线性层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear" class="md-nav__link">
    <span class="md-ellipsis">
      Linear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lazylinear" class="md-nav__link">
    <span class="md-ellipsis">
      LazyLinear
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#卷积层" class="md-nav__link">
    <span class="md-ellipsis">
      卷积层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="卷积层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv2d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv3d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#汇聚层池化层" class="md-nav__link">
    <span class="md-ellipsis">
      汇聚层（池化层）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="汇聚层（池化层）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maxpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maxpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maxpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#循环层" class="md-nav__link">
    <span class="md-ellipsis">
      循环层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="循环层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gru" class="md-nav__link">
    <span class="md-ellipsis">
      GRU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lstm" class="md-nav__link">
    <span class="md-ellipsis">
      LSTM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#归一化层" class="md-nav__link">
    <span class="md-ellipsis">
      归一化层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="归一化层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batchnorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batchnorm2d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batchnorm3d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-层" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer 层
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#嵌入层" class="md-nav__link">
    <span class="md-ellipsis">
      嵌入层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="嵌入层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#丢弃层" class="md-nav__link">
    <span class="md-ellipsis">
      丢弃层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="丢弃层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout2d" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout2d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#激活函数" class="md-nav__link">
    <span class="md-ellipsis">
      激活函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="激活函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#elu" class="md-nav__link">
    <span class="md-ellipsis">
      ELU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leakyrelu" class="md-nav__link">
    <span class="md-ellipsis">
      LeakyReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-logsoftmax" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax, LogSoftmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#损失函数" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="损失函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bceloss" class="md-nav__link">
    <span class="md-ellipsis">
      BCELoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crossentropyloss" class="md-nav__link">
    <span class="md-ellipsis">
      CrossEntropyLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kldivloss" class="md-nav__link">
    <span class="md-ellipsis">
      KLDivLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mseloss" class="md-nav__link">
    <span class="md-ellipsis">
      MSELoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nllloss" class="md-nav__link">
    <span class="md-ellipsis">
      NLLLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1loss" class="md-nav__link">
    <span class="md-ellipsis">
      L1Loss
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#数据并行模组" class="md-nav__link">
    <span class="md-ellipsis">
      数据并行模组
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数据并行模组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataparallel" class="md-nav__link">
    <span class="md-ellipsis">
      DataParallel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paralleldistributeddataparallel" class="md-nav__link">
    <span class="md-ellipsis">
      parallel.DistributedDataParallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#实用功能" class="md-nav__link">
    <span class="md-ellipsis">
      实用功能
    </span>
  </a>
  
    <nav class="md-nav" aria-label="实用功能">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flatten" class="md-nav__link">
    <span class="md-ellipsis">
      Flatten
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-nn-functional.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-optim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-autograd.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-cuda.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-backends.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-distributed.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.fft, torch.linalg, torch.special
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-tensorboard.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lightning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: lightning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../horovod.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    horovod
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../nni/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    nni
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_8" id="__nav_5_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_8">
            <span class="md-nav__icon md-icon"></span>
            nni
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nni/tuner.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    调参器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    参考和工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            参考和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
        
          
          <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Linux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command-line-tool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令行工具
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文件格式
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            文件格式
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/yaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/xml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/markdown.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    编码
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            编码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/charset-and-encoding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    字符集和字符编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base64
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            文本工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/regular-expression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    正则表达式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/vim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vim
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    构建工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            构建工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/build-tool/make.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    make
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/git.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/vocabulary.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词汇表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    前端
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            前端
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-html.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple HTML
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-css.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple CSS
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#容器" class="md-nav__link">
    <span class="md-ellipsis">
      容器
    </span>
  </a>
  
    <nav class="md-nav" aria-label="容器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module" class="md-nav__link">
    <span class="md-ellipsis">
      Module
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#add_module" class="md-nav__link">
    <span class="md-ellipsis">
      add_module()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply" class="md-nav__link">
    <span class="md-ellipsis">
      apply()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#buffers" class="md-nav__link">
    <span class="md-ellipsis">
      buffers()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#children" class="md-nav__link">
    <span class="md-ellipsis">
      children()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu" class="md-nav__link">
    <span class="md-ellipsis">
      cpu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eval" class="md-nav__link">
    <span class="md-ellipsis">
      eval()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_parameter" class="md-nav__link">
    <span class="md-ellipsis">
      get_parameter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_submodule" class="md-nav__link">
    <span class="md-ellipsis">
      get_submodule()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      load_state_dict()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modules" class="md-nav__link">
    <span class="md-ellipsis">
      modules()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_buffers" class="md-nav__link">
    <span class="md-ellipsis">
      named_buffers()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_children" class="md-nav__link">
    <span class="md-ellipsis">
      named_children()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      named_parameters()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      parameters()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_buffer" class="md-nav__link">
    <span class="md-ellipsis">
      register_buffer()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_forward_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_forward_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_pre_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_pre_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_full_backward_hook" class="md-nav__link">
    <span class="md-ellipsis">
      register_full_backward_hook()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#register_parameter" class="md-nav__link">
    <span class="md-ellipsis">
      register_parameter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad_" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      state_dict()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to" class="md-nav__link">
    <span class="md-ellipsis">
      to()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    <span class="md-ellipsis">
      train()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#type" class="md-nav__link">
    <span class="md-ellipsis">
      type()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_grad" class="md-nav__link">
    <span class="md-ellipsis">
      zero_grad()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequential" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#线性层" class="md-nav__link">
    <span class="md-ellipsis">
      线性层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="线性层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear" class="md-nav__link">
    <span class="md-ellipsis">
      Linear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lazylinear" class="md-nav__link">
    <span class="md-ellipsis">
      LazyLinear
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#卷积层" class="md-nav__link">
    <span class="md-ellipsis">
      卷积层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="卷积层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv2d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv3d" class="md-nav__link">
    <span class="md-ellipsis">
      Conv3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#汇聚层池化层" class="md-nav__link">
    <span class="md-ellipsis">
      汇聚层（池化层）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="汇聚层（池化层）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#maxpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maxpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maxpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      MaxPool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      AvgPool3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#循环层" class="md-nav__link">
    <span class="md-ellipsis">
      循环层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="循环层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gru" class="md-nav__link">
    <span class="md-ellipsis">
      GRU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lstm" class="md-nav__link">
    <span class="md-ellipsis">
      LSTM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#归一化层" class="md-nav__link">
    <span class="md-ellipsis">
      归一化层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="归一化层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batchnorm1d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batchnorm2d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batchnorm3d" class="md-nav__link">
    <span class="md-ellipsis">
      BatchNorm3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-层" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer 层
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#嵌入层" class="md-nav__link">
    <span class="md-ellipsis">
      嵌入层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="嵌入层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#丢弃层" class="md-nav__link">
    <span class="md-ellipsis">
      丢弃层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="丢弃层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout2d" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout2d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#激活函数" class="md-nav__link">
    <span class="md-ellipsis">
      激活函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="激活函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#elu" class="md-nav__link">
    <span class="md-ellipsis">
      ELU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leakyrelu" class="md-nav__link">
    <span class="md-ellipsis">
      LeakyReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax-logsoftmax" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax, LogSoftmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#损失函数" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="损失函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bceloss" class="md-nav__link">
    <span class="md-ellipsis">
      BCELoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crossentropyloss" class="md-nav__link">
    <span class="md-ellipsis">
      CrossEntropyLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kldivloss" class="md-nav__link">
    <span class="md-ellipsis">
      KLDivLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mseloss" class="md-nav__link">
    <span class="md-ellipsis">
      MSELoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nllloss" class="md-nav__link">
    <span class="md-ellipsis">
      NLLLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1loss" class="md-nav__link">
    <span class="md-ellipsis">
      L1Loss
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#数据并行模组" class="md-nav__link">
    <span class="md-ellipsis">
      数据并行模组
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数据并行模组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataparallel" class="md-nav__link">
    <span class="md-ellipsis">
      DataParallel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#paralleldistributeddataparallel" class="md-nav__link">
    <span class="md-ellipsis">
      parallel.DistributedDataParallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#实用功能" class="md-nav__link">
    <span class="md-ellipsis">
      实用功能
    </span>
  </a>
  
    <nav class="md-nav" aria-label="实用功能">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flatten" class="md-nav__link">
    <span class="md-ellipsis">
      Flatten
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="torchnn">torch.nn<a class="headerlink" href="#torchnn" title="Permanent link">&para;</a></h1>
<h2 id="容器">容器<a class="headerlink" href="#容器" title="Permanent link">&para;</a></h2>
<h3 id="module">Module<a class="headerlink" href="#module" title="Permanent link">&para;</a></h3>
<p>所有神经网络模块（module）的基类。你的自定义模型应继承此类。</p>
<p>模块可以包含其它模块，使得它们可以嵌套成为树形结构。你可以将子模块赋为常规属性：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>     <span class="c1"># 子模块赋为常规属性</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div>
<p>以此种方式赋值的子模块将被注册，当你对模块调用 <code>to()</code> 等方法时这些子模块的参数也会被同样地转换。</p>
<h4 id="add_module">add_module()<a class="headerlink" href="#add_module" title="Permanent link">&para;</a></h4>
<p>为当前模块添加一个子模块。添加的子模块可以作为属性访问（使用给定的名称）。</p>
<div class="highlight"><pre><span></span><code><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
<span class="c1"># name     子模块的名称</span>
<span class="c1"># module   被添加的子模块</span>
</code></pre></div>
<h4 id="apply">apply()<a class="headerlink" href="#apply" title="Permanent link">&para;</a></h4>
<p>递归地为模块及其子模块应用指定函数。典型的应用包括初始化模型的参数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="o">...</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
<span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
<span class="n">Sequential</span><span class="p">(</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">Sequential</span><span class="p">(</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="buffers">buffers()<a class="headerlink" href="#buffers" title="Permanent link">&para;</a></h4>
<p>返回所有缓冲区的一个迭代器。</p>
<h4 id="children">children()<a class="headerlink" href="#children" title="Permanent link">&para;</a></h4>
<p>返回所有直接子模块的一个迭代器。</p>
<h4 id="cpu">cpu()<a class="headerlink" href="#cpu" title="Permanent link">&para;</a></h4>
<p>移动所有的模型参数和缓冲区到 CPU。</p>
<h4 id="cuda">cuda()<a class="headerlink" href="#cuda" title="Permanent link">&para;</a></h4>
<p>移动所有的模型参数和缓冲区到 GPU。</p>
<p>如果你需要将模型移动到 GPU（通过调用 <code>.cuda()</code> 或 <code>.to()</code>），请在为此模型构造优化器之前完成这一操作。<code>.cuda()</code> 或 <code>.to()</code> 调用之后的模型的参数将会是一组不同的对象。</p>
<h4 id="eval">eval()<a class="headerlink" href="#eval" title="Permanent link">&para;</a></h4>
<p>设置模块为测试模式。</p>
<p>仅对某些模块有效，请参阅特定模块的文档以了解其在训练/测试模式下的行为细节。</p>
<p>等价于 <code>train(False)</code>。</p>
<h4 id="forward">forward()<a class="headerlink" href="#forward" title="Permanent link">&para;</a></h4>
<p>定义每次调用时执行的前向计算。</p>
<h4 id="get_parameter">get_parameter()<a class="headerlink" href="#get_parameter" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">get_parameter</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</code></pre></div>
<p>返回由 <code>target</code> 给出的参数，若其不存在则引发异常。</p>
<h4 id="get_submodule">get_submodule()<a class="headerlink" href="#get_submodule" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">get_submodule</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</code></pre></div>
<p>返回由 <code>target</code> 给出的子模块，若其不存在则引发异常。</p>
<p>例如，现有模块 <code>a</code>，其有一个嵌套的子模块 <code>net_b</code>，<code>net_b</code> 又有两个子模块 <code>net_c</code> 和 <code>linear</code>，<code>net_c</code> 又有子模块 <code>conv</code>。为了检查模块 <code>a</code> 是否有子模块 <code>linear</code>，应调用 <code>get_submodule("net_b.linear")</code>；为了检查模块 <code>a</code> 是否有子模块 <code>conv</code>，应调用 <code>get_submodule("net_b.net_c.linear")</code>。</p>
<h4 id="load_state_dict">load_state_dict()<a class="headerlink" href="#load_state_dict" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># state_dict    包含模块参数和持久缓冲区的字典</span>
<span class="c1"># strict        若为`True`,则`state_dict`的键必须正好匹配当前模块的`state_dict()`方法返回的模块的键</span>
</code></pre></div>
<p>从 <code>state_dict</code> 复制参数和缓冲区到当前模块及其子模块。</p>
<h4 id="modules">modules()<a class="headerlink" href="#modules" title="Permanent link">&para;</a></h4>
<p>返回所有模块（当前模块及其子模块）的一个迭代器。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="mi">0</span> <span class="o">-&gt;</span> <span class="n">Sequential</span><span class="p">(</span>                                          <span class="c1"># 0 -&gt; 当前模块</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
<span class="mi">1</span> <span class="o">-&gt;</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>     <span class="c1"># 1 -&gt; 子模块1</span>
<span class="mi">2</span> <span class="o">-&gt;</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>     <span class="c1"># 2 -&gt; 子模块2</span>
</code></pre></div>
<h4 id="named_buffers">named_buffers()<a class="headerlink" href="#named_buffers" title="Permanent link">&para;</a></h4>
<p>返回所有缓冲区的一个迭代器，产出缓冲区及其名称。</p>
<h4 id="named_children">named_children()<a class="headerlink" href="#named_children" title="Permanent link">&para;</a></h4>
<p>返回所有直接子模块的一个迭代器，产出模块及其名称。</p>
<h4 id="named_parameters">named_parameters()<a class="headerlink" href="#named_parameters" title="Permanent link">&para;</a></h4>
<p>返回所有参数的一个迭代器，产出模块及其名称。</p>
<h4 id="parameters">parameters()<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h4>
<p>返回所有参数的一个迭代器，通常用于传给优化器。</p>
<h4 id="register_buffer">register_buffer()<a class="headerlink" href="#register_buffer" title="Permanent link">&para;</a></h4>
<p>为模块添加一个缓冲区。</p>
<p>通常用于注册一个不应被看作为模型参数的缓冲区。例如，BatchNorm 的 <code>running_mean</code> 不是一个参数，但却是模块状态的一部分。默认情况下，缓冲区是持久的，并和参数一起保存。</p>
<p>缓冲区可以作为属性访问（使用给定的名称）。</p>
<div class="highlight"><pre><span></span><code><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># name        缓冲区的名称</span>
<span class="c1"># tensor      要注册的缓冲区</span>
<span class="c1"># persistent  若为`True`,则缓冲区是持久的,并会成为模块的`state_dict`的一部分</span>
</code></pre></div>
<h4 id="register_forward_hook">register_forward_hook()<a class="headerlink" href="#register_forward_hook" title="Permanent link">&para;</a></h4>
<p>为模块注册一个前向钩子。</p>
<p>此钩子会在每次 <code>forward()</code> 返回后被调用；其应该有如下签名：</p>
<div class="highlight"><pre><span></span><code><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</code></pre></div>
<p>其中 <code>input</code> 仅包含传给模块（<code>forward()</code>）的位置参数，传给模块的关键字参数不会传给钩子。钩子可以修改 <code>output</code>，也可以原位修改 <code>input</code>，但是这并不会影响到前向计算，因为钩子在 <code>forward()</code> 返回后才被调用。</p>
<h4 id="register_pre_hook">register_pre_hook()<a class="headerlink" href="#register_pre_hook" title="Permanent link">&para;</a></h4>
<p>为模块注册一个前向前钩子。</p>
<p>此钩子会在每次 <code>forward()</code> 调用前被调用；其应该有如下签名：</p>
<div class="highlight"><pre><span></span><code><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</code></pre></div>
<p>其中 <code>input</code> 仅包含传给模块（<code>forward()</code>）的位置参数，传给模块的关键字参数不会传给钩子。钩子可以修改 <code>input</code>，返回修改后的值。</p>
<h4 id="register_full_backward_hook">register_full_backward_hook()<a class="headerlink" href="#register_full_backward_hook" title="Permanent link">&para;</a></h4>
<p>为模块注册一个反向钩子。</p>
<p>此钩子会在每次 <code>backward()</code> 返回后被调用；其应该有如下签名：</p>
<div class="highlight"><pre><span></span><code><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</code></pre></div>
<p>其中 <code>grad_input</code> 和 <code>grad_output</code> 是分别包含了对于输入和输出的梯度的元组。此钩子不应修改其参数，但可以可选地返回一个新的对于输入的梯度以替代 <code>grad_input</code> 用于接下来的计算。<code>grad_input</code> 仅对应于传给模块的位置参数，传给模块的关键字参数将被忽略；<code>grad_input</code> 和 <code>grad_output</code> 中对应于非张量的元素为 <code>None</code>。</p>
<h4 id="register_parameter">register_parameter()<a class="headerlink" href="#register_parameter" title="Permanent link">&para;</a></h4>
<p>为模块添加一个参数。</p>
<p>该参数可以作为属性访问（使用给定的名称）。</p>
<div class="highlight"><pre><span></span><code><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
<span class="c1"># name        参数的名称</span>
<span class="c1"># param       要添加的参数</span>
</code></pre></div>
<h4 id="requires_grad_">requires_grad_()<a class="headerlink" href="#requires_grad_" title="Permanent link">&para;</a></h4>
<p>设置 autograd 是否应该记录模块参数参与的运算，通过设置参数的 <code>requires_grad</code> 属性。</p>
<p>此方法有助于冻结部分模块以精调，或单独训练模型的各个部分（例如 GAN 训练）。</p>
<h4 id="state_dict">state_dict()<a class="headerlink" href="#state_dict" title="Permanent link">&para;</a></h4>
<p>返回包含了模块完整状态的字典。</p>
<p>参数和持久缓冲区都包含在内；字典的键对应于参数和缓冲区的名称。</p>
<h4 id="to">to()<a class="headerlink" href="#to" title="Permanent link">&para;</a></h4>
<p>移动参数和缓冲区到指定设备，或转换其数据类型。此方法<strong>原位</strong>修改模块。</p>
<div class="highlight"><pre><span></span><code><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">to</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">to</span><span class="p">(</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">channels_last</span><span class="p">)</span>
<span class="c1"># device          要移动到的设备</span>
<span class="c1"># dtype           要转换为的浮点或复数数据类型</span>
<span class="c1"># tensor          张量实例,其设备和数据类型作为此模块所有参数和缓冲区要移动和转换的目标</span>
<span class="c1"># memory_format   要转换为的内存格式</span>
</code></pre></div>
<p>其函数签名类似于 <code>torch.Tensor.to()</code>，但 <code>dtype</code> 仅接受浮点或复数类型，并且只有浮点或复数参数和缓冲区会被转型；整数参数和缓冲区的类型保持不变。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1913</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3420</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5113</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2325</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1913</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3420</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5113</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2325</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1914</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3420</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5112</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2324</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1914</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3420</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5112</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2324</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.3741</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">,</span>  <span class="mf">0.2382</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.5593</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4443</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.6122</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">,</span> <span class="mf">0.1150</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6122</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">,</span> <span class="mf">0.1150</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6122</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">,</span> <span class="mf">0.1150</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span>
</code></pre></div>
<h4 id="train">train()<a class="headerlink" href="#train" title="Permanent link">&para;</a></h4>
<p>设置模块为训练模式。</p>
<p>仅对某些模块有效，请参阅特定模块的文档以了解其在训练/测试模式下的行为细节。</p>
<h4 id="training">training<a class="headerlink" href="#training" title="Permanent link">&para;</a></h4>
<p>若为 <code>True</code>，表示模块处于训练模式；若为 <code>False</code>，表示模块处于测试模式。</p>
<h4 id="type">type()<a class="headerlink" href="#type" title="Permanent link">&para;</a></h4>
<p>将所有参数和缓冲区转换为指定数据类型。</p>
<h4 id="zero_grad">zero_grad()<a class="headerlink" href="#zero_grad" title="Permanent link">&para;</a></h4>
<p>设置所有模型参数的梯度为 0。见 <code>torch.optim.Optimizer.zero_grad()</code>。</p>
<h3 id="sequential">Sequential<a class="headerlink" href="#sequential" title="Permanent link">&para;</a></h3>
<p>模块的顺序容器。模块将以它们被传入到初始化函数的顺序被添加，并以同样的顺序组成流水线。</p>
<p>整个容器可以被当作一个模块进行调用，对其执行的变换会被应用于其保存的每个模块（每个模块都被注册为 <code>Sequential</code> 实例的子模块）。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Using Sequential to create a small model. When `model` is run,</span>
<span class="c1"># input will first be passed to `Conv2d(1,20,5)`. The output of</span>
<span class="c1"># `Conv2d(1,20,5)` will be used as the input to the first</span>
<span class="c1"># `ReLU`; the output of the first `ReLU` will become the input</span>
<span class="c1"># for `Conv2d(20,64,5)`. Finally, the output of</span>
<span class="c1"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
</code></pre></div>
<h2 id="线性层">线性层<a class="headerlink" href="#线性层" title="Permanent link">&para;</a></h2>
<h3 id="linear">Linear<a class="headerlink" href="#linear" title="Permanent link">&para;</a></h3>
<p>全连接层。对输入数据应用线性变换 <span class="arithmatex">\(y=xA^{\rm T}+b\)</span>。</p>
<p>此模块支持 TensorFloat32。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># in_features    输入特征数</span>
<span class="c1"># out_features   输出特征数</span>
<span class="c1"># bias           是否使用偏置</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,*,H_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(*\)</span> 表示任意个额外的维度， <span class="arithmatex">\(H_{\rm in}={\rm in\_features}\)</span>。</li>
<li>输出形状： <span class="arithmatex">\((N,*,H_{\rm out})\)</span>，其中 <span class="arithmatex">\(H_{\rm out}={\rm out\_features}\)</span>。</li>
<li>参数：<ul>
<li><code>weight</code>：可学习的权重张量，形状为 <code>[out_features, in_features]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=1/{\rm in\_features}\)</span>。</li>
<li><code>bias</code>：可学习的偏置张量，形状为 <code>[out_features,]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=1/{\rm in\_features}\)</span>。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">linear1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear1</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0285</span><span class="p">,</span>  <span class="mf">0.0458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0013</span><span class="p">,</span>  <span class="mf">0.2764</span><span class="p">,</span>  <span class="mf">0.0984</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1178</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1910</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0530</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1364</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1013</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0151</span><span class="p">,</span>  <span class="mf">0.1885</span><span class="p">,</span>  <span class="mf">0.1719</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3091</span><span class="p">,</span>  <span class="mf">0.1960</span><span class="p">,</span>  <span class="mf">0.0883</span><span class="p">,</span>  <span class="mf">0.3000</span><span class="p">,</span>  <span class="mf">0.2087</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.2881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3007</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1525</span><span class="p">,</span>  <span class="mf">0.2777</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0527</span><span class="p">,</span>  <span class="mf">0.1353</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1470</span><span class="p">,</span>  <span class="mf">0.3103</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1338</span><span class="p">,</span>  <span class="mf">0.2371</span><span class="p">,</span>
          <span class="mf">0.0037</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1666</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1625</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1679</span><span class="p">,</span>  <span class="mf">0.0930</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0913</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0347</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3040</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1508</span><span class="p">,</span>  <span class="mf">0.1716</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.0769</span><span class="p">,</span>  <span class="mf">0.3150</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">linear1</span><span class="o">.</span><span class="n">bias</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.2535</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0148</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2111</span><span class="p">,</span>  <span class="mf">0.1926</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<h3 id="lazylinear">LazyLinear<a class="headerlink" href="#lazylinear" title="Permanent link">&para;</a></h3>
<p>和 <code>torch.nn.Linear</code> 模块相同，除了 <code>in_features</code> 参数通过推断得到。</p>
<p>此模块中，<code>weight</code> 和 <code>bias</code> 都属于 <code>torch.nn.UninitializedParameter</code> 类。它们将在第一次调用 <code>forward()</code> 后被初始化，然后模块会变成一个常规的 <code>torch.nn.Linear</code> 模块。<code>in_features</code> 参数从 <code>input.shape[-1]</code> 推断得到。</p>
<h2 id="卷积层">卷积层<a class="headerlink" href="#卷积层" title="Permanent link">&para;</a></h2>
<h3 id="conv1d">Conv1d<a class="headerlink" href="#conv1d" title="Permanent link">&para;</a></h3>
<p>一维卷积层。</p>
<p>此模块支持 TensorFloat32。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># in_channels     输入通道数</span>
<span class="c1"># out_channels    输出通道数</span>
<span class="c1"># kernel_size     卷积核大小</span>
<span class="c1"># stride          卷积步长</span>
<span class="c1"># padding         输入的两端填充的个数</span>
<span class="c1"># padding_mode    填充模式.若为`zeros`,则填充零;……</span>
<span class="c1"># dilation        卷积核元素的间隔</span>
<span class="c1"># groups          控制输入通道和输出通道之间的连接.例如若为`1`,则所有的输入通道连接所有的输出通道;</span>
<span class="c1">#                 若为`2`,则输入通道和输出通道各均分为2组,每个输入通道只会连接同组的输出通道;</span>
<span class="c1">#                 若为`in_channels`,则每个输入通道单独生成几个输出通道.此参数必须是</span>
<span class="c1">#                 `in_channels`和`out_channels`的公约数</span>
<span class="c1"># bias            若为`True`,为输出加上一个可以学习的偏置</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C_{\rm in},L_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(L\)</span> 表示长，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C_{\rm out},L_{\rm out})\)</span>。</li>
<li>参数：<ul>
<li><code>weight</code>：可学习的权重张量，形状为 <code>[out_channels, in_channels // groups, kernel_size]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
<li><code>bias</code>：可学习的偏置张量，形状为 <code>[out_channels,]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                   <span class="c1"># 卷积核长度为3,步长为1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>                   <span class="c1"># 步长为3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1"># 左右各用1个零填充</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<h3 id="conv2d">Conv2d<a class="headerlink" href="#conv2d" title="Permanent link">&para;</a></h3>
<p>二维卷积层。</p>
<p>此模块支持 TensorFloat32。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># in_channels     输入通道数</span>
<span class="c1"># out_channels    输出通道数</span>
<span class="c1"># kernel_size     卷积核大小,可以是单个整数(同时表示高和宽)或两个整数组成的元组(分别表示高和宽),下同</span>
<span class="c1"># stride          卷积步长</span>
<span class="c1"># padding         输入的四边填充的行/列数,可以是单个整数(同时表示上下填充的行数和左右填充的列数)或</span>
<span class="c1">#                 两个整数组成的元组(分别表示上下填充的行数和左右填充的列数)</span>
<span class="c1"># padding_mode    填充模式.若为`zeros`,则填充零;……</span>
<span class="c1"># dilation        卷积核元素的间隔</span>
<span class="c1"># groups          控制输入通道和输出通道之间的连接.例如若为`1`,则所有的输入通道连接所有的输出通道;</span>
<span class="c1">#                 若为`2`,则输入通道和输出通道各均分为2组,每个输入通道只会连接同组的输出通道;</span>
<span class="c1">#                 若为`in_channels`,则每个输入通道单独生成几个输出通道.此参数必须是</span>
<span class="c1">#                 `in_channels`和`out_channels`的公约数</span>
<span class="c1"># bias            若为`True`,为输出加上一个可以学习的偏置</span>
</code></pre></div>
<blockquote>
<p><code>kernel_size</code> 等参数的具体意义请参见 <a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An Introduction to different Types of Convolutions in Deep Learning</a>。</p>
</blockquote>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C_{\rm in},H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C_{\rm out},H_{\rm out}, W_{\rm out})\)</span>。</li>
<li>参数：<ul>
<li><code>weight</code>：可学习的权重张量，形状为 <code>[out_channels, in_channels // groups, kernel_size[0], kernel_size[1]]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
<li><code>bias</code>：可学习的偏置张量，形状为 <code>[out_channels,]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                 <span class="c1"># 卷积核大小为(3,3),步长为1</span>
                                                   <span class="c1"># 将1个通道(卷积特征)映射到32个通道(卷积特征)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>            <span class="c1"># 卷积核大小为(3,5)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>                 <span class="c1"># 步长为3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># 上下/左右各填充1行/1列零</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">24</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">conv4</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<h3 id="conv3d">Conv3d<a class="headerlink" href="#conv3d" title="Permanent link">&para;</a></h3>
<p>三维卷积层。</p>
<p>此模块支持 TensorFloat32。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
<span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># in_channels     输入通道数</span>
<span class="c1"># out_channels    输出通道数</span>
<span class="c1"># kernel_size     卷积核大小,可以是单个整数(同时表示深,高,宽)或三个整数组成的元组(分别表示深,高,宽),下同</span>
<span class="c1"># stride          卷积步长</span>
<span class="c1"># padding         输入的六面填充的层数,可以是单个整数(同时表示三个方向填充的层数)或三个整数组成的元组(分别表示</span>
<span class="c1">#                 深,高,宽三个方向填充的层数)</span>
<span class="c1"># padding_mode    填充模式.若为`zeros`,则填充零;……</span>
<span class="c1"># dilation        卷积核元素的间隔</span>
<span class="c1"># groups          控制输入通道和输出通道之间的连接.例如若为`1`,则所有的输入通道连接所有的输出通道;</span>
<span class="c1">#                 若为`2`,则输入通道和输出通道各均分为2组,每个输入通道只会连接同组的输出通道;</span>
<span class="c1">#                 若为`in_channels`,则每个输入通道单独生成几个输出通道.此参数必须是</span>
<span class="c1">#                 `in_channels`和`out_channels`的公约数</span>
<span class="c1"># bias            若为`True`,为输出加上一个可以学习的偏置</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C_{\rm in},D_{\rm in}, H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(D\)</span> 表示深， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C_{\rm out},D_{\rm out},H_{\rm out}, W_{\rm out})\)</span>。</li>
<li>参数：<ul>
<li><code>weight</code>：可学习的权重张量，形状为 <code>[out_channels, in_channels // groups, kernel_size[0], kernel_size[1], kernel_size[2]]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
<li><code>bias</code>：可学习的偏置张量，形状为 <code>[out_channels,]</code>，初始值服从 <span class="arithmatex">\((-\sqrt{k},\sqrt{k})\)</span> 区间上的均匀分布，其中 <span class="arithmatex">\(k=\cdots\)</span>。</li>
</ul>
</li>
</ul>
<h2 id="汇聚层池化层">汇聚层（池化层）<a class="headerlink" href="#汇聚层池化层" title="Permanent link">&para;</a></h2>
<h3 id="maxpool1d">MaxPool1d<a class="headerlink" href="#maxpool1d" title="Permanent link">&para;</a></h3>
<p>一维最大汇聚层。见 <code>torch.nn.functional.max_pool1d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的两端填充的负无穷的个数</span>
<span class="c1"># dilation        滑动窗口元素的间隔</span>
<span class="c1"># return_indices  若为`True`,将最大值连同索引一起返回,用于之后调用`MaxUnpool1d`</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,L_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(L\)</span> 表示长，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,L_{\rm out})\)</span>。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]])</span>
</code></pre></div>
<h3 id="maxpool2d">MaxPool2d<a class="headerlink" href="#maxpool2d" title="Permanent link">&para;</a></h3>
<p>二维最大汇聚层。见 <code>torch.nn.functional.max_pool2d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小,可以是单个整数(同时表示高和宽)或两个整数组成的元组(分别表示高和宽),下同</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的四边填充的负无穷的行/列数,可以是单个整数(同时表示上下填充的行数和</span>
<span class="c1">#                 左右填充的列数)或两个整数组成的元组(分别表示上下填充的行数和左右填充的列数)</span>
<span class="c1"># dilation        滑动窗口元素的间隔</span>
<span class="c1"># return_indices  若为`True`,将最大值连同索引一起返回,用于之后调用`MaxUnpool2d`</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,H_{\rm out}, W_{\rm out})\)</span>。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mp3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="maxpool3d">MaxPool3d<a class="headerlink" href="#maxpool3d" title="Permanent link">&para;</a></h3>
<p>三维最大汇聚层。见 <code>torch.nn.functional.max_pool3d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小,可以是单个整数(同时表示深,高,宽)或三个整数组成的元组(分别表示深,高,宽),下同</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的六面填充的负无穷的层数,可以是单个整数(同时表示三个方向填充的层数)或</span>
<span class="c1">#                 三个整数组成的元组(分别表示深,高,宽三个方向填充的层数)</span>
<span class="c1"># dilation        滑动窗口元素的间隔</span>
<span class="c1"># return_indices  若为`True`,将最大值连同索引一起返回,用于之后调用`MaxUnpool3d`</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,D_{\rm in},H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(D\)</span> 表示深， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,D_{\rm out},H_{\rm out}, W_{\rm out})\)</span>。</li>
</ul>
<h3 id="avgpool1d">AvgPool1d<a class="headerlink" href="#avgpool1d" title="Permanent link">&para;</a></h3>
<p>一维平均汇聚层。见 <code>torch.nn.functional.avg_pool1d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
<span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的两端填充的零的个数</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
<span class="c1"># count_include_pad  若为`True`,则平均计算将包括填充的零</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,L_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(L\)</span> 表示长，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,L_{\rm out})\)</span>。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">4.6667</span><span class="p">,</span> <span class="mf">5.6667</span><span class="p">,</span> <span class="mf">7.0000</span><span class="p">,</span> <span class="mf">5.6667</span><span class="p">,</span> <span class="mf">5.3333</span><span class="p">,</span> <span class="mf">3.6667</span><span class="p">,</span> <span class="mf">5.0000</span><span class="p">,</span> <span class="mf">4.6667</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">4.6667</span><span class="p">,</span> <span class="mf">7.0000</span><span class="p">,</span> <span class="mf">5.3333</span><span class="p">,</span> <span class="mf">5.0000</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mf">4.6667</span><span class="p">,</span> <span class="mf">7.0000</span><span class="p">,</span> <span class="mf">5.3333</span><span class="p">,</span> <span class="mf">5.0000</span><span class="p">,</span> <span class="mf">6.0000</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="avgpool2d">AvgPool2d<a class="headerlink" href="#avgpool2d" title="Permanent link">&para;</a></h3>
<p>二维平均汇聚层。见 <code>torch.nn.functional.avg_pool2d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
<span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小,可以是单个整数(同时表示高和宽)或两个整数组成的元组(分别表示高和宽),下同</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的四边填充的零的行/列数,可以是单个整数(同时表示上下填充的行数和</span>
<span class="c1">#                 左右填充的列数)或两个整数组成的元组(分别表示上下填充的行数和左右填充的列数)</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
<span class="c1"># count_include_pad  若为`True`,则平均计算将包括填充的零</span>
<span class="c1"># divisor_override   若指定了此参数,则将被用作平均计算的分母,替代滑动窗口的元素数量</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,H_{\rm out}, W_{\rm out})\)</span>。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[[[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[[</span><span class="mf">3.4444</span><span class="p">,</span> <span class="mf">4.2222</span><span class="p">,</span> <span class="mf">4.8889</span><span class="p">,</span> <span class="mf">4.5556</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">2.7778</span><span class="p">,</span> <span class="mf">2.5556</span><span class="p">,</span> <span class="mf">3.2222</span><span class="p">,</span> <span class="mf">3.3333</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">4.1111</span><span class="p">,</span> <span class="mf">3.7778</span><span class="p">,</span> <span class="mf">2.6667</span><span class="p">,</span> <span class="mf">2.6667</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">3.8889</span><span class="p">,</span> <span class="mf">2.7778</span><span class="p">,</span> <span class="mf">2.3333</span><span class="p">,</span> <span class="mf">2.4444</span><span class="p">]]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[[</span><span class="mf">3.4444</span><span class="p">,</span> <span class="mf">4.8889</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">4.1111</span><span class="p">,</span> <span class="mf">2.6667</span><span class="p">]]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ap3</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[[</span><span class="mf">3.4444</span><span class="p">,</span> <span class="mf">4.8889</span><span class="p">,</span> <span class="mf">4.5000</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">4.1111</span><span class="p">,</span> <span class="mf">2.6667</span><span class="p">,</span> <span class="mf">1.3333</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">4.0000</span><span class="p">,</span> <span class="mf">3.0000</span><span class="p">,</span> <span class="mf">2.7500</span><span class="p">]]]])</span>
</code></pre></div>
<h3 id="avgpool3d">AvgPool3d<a class="headerlink" href="#avgpool3d" title="Permanent link">&para;</a></h3>
<p>三维平均汇聚层。见 <code>torch.nn.functional.avg_pool3d()</code>。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># kernel_size     滑动窗口的大小,可以是单个整数(同时表示深,高,宽)或三个整数组成的元组(分别表示深,高,宽),下同</span>
<span class="c1"># stride          滑动窗口的步长,默认为`kernel_size`</span>
<span class="c1"># padding         输入的六面填充的零的层数,可以是单个整数(同时表示三个方向填充的层数)或</span>
<span class="c1">#                 三个整数组成的元组(分别表示深,高,宽三个方向填充的层数)</span>
<span class="c1"># ceil_mode       若为`True`,则保证输入张量的每个元素都会被一个滑动窗口覆盖</span>
<span class="c1"># count_include_pad  若为`True`,则平均计算将包括填充的零</span>
<span class="c1"># divisor_override   若指定了此参数,则将被用作平均计算的分母,替代滑动窗口的元素数量</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C,D_{\rm in},H_{\rm in}, W_{\rm in})\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模， <span class="arithmatex">\(C\)</span> 表示通道数， <span class="arithmatex">\(D\)</span> 表示深， <span class="arithmatex">\(H\)</span> 表示高， <span class="arithmatex">\(W\)</span> 表示宽，下同。</li>
<li>输出形状： <span class="arithmatex">\((N,C,D_{\rm out},H_{\rm out}, W_{\rm out})\)</span>。</li>
</ul>
<h2 id="循环层">循环层<a class="headerlink" href="#循环层" title="Permanent link">&para;</a></h2>
<h3 id="gru">GRU<a class="headerlink" href="#gru" title="Permanent link">&para;</a></h3>
<p>GRU 层。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>           <span class="c1"># GRU可以视作简化的LSTM,各参数含义与LSTM相同</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hn</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</code></pre></div>
<h3 id="lstm">LSTM<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h3>
<blockquote>
<p>参考：<a href="https://www.cnblogs.com/marsggbo/p/12123755.html">理解 PyTorch 中 LSTM 的输入输出参数含义</a></p>
</blockquote>
<p>LSTM 层。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">])</span> <span class="c1"># 输入向量x的维数为5,隐状态h的维数为10,堆叠2层</span>
                                           <span class="c1"># 在每层(最上层除外)的输出位置增加一个dropout层</span>
                                           <span class="c1"># 多层LSTM中,上层的输入是下层的隐状态</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>         <span class="c1"># 一批64个序列,每个序列有20个5维向量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>            <span class="c1"># 第一个参数为层数与方向数的乘积,单向和双向LSTM</span>
                                           <span class="c1">#   的方向数分别为1和2</span>
                                           <span class="c1"># 第二个参数为输入序列的数量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>            <span class="c1"># 第三个参数为隐状态维数</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span> <span class="c1"># 输入h,c的初值,输出h,c的终值</span>
                                            <span class="c1"># 若不输入初值,则默认为0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>                   <span class="c1"># 从前往后输出最上层的所有隐状态</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hn</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>                    <span class="c1"># 输出每一(层,方向)的最终隐状态</span>
                                           <span class="c1"># 对于单向LSTM, hn[-1]==output[-1]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 双向LSTM,相当于将输入向量正向和反向各</span>
                                                 <span class="c1">#   输入一次</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                  <span class="c1"># 层数*方向数=4</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>                   <span class="c1"># 输出最上层的所有隐状态,拼接正向与反向的输出</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hn</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>                    <span class="c1"># 每一(层,方向)的最终隐状态</span>
</code></pre></div>
<blockquote>
<p>尤其需要注意的是，这里接受的输入张量的形状为<code>(seq_len, batch, input_size)</code>，而常见的输入的形状为<code>(batch, seq_len, input_size)</code>，为此需要使用<code>transpose()</code>或<code>permute()</code>方法交换维度。参见<a href="https://discuss.pytorch.org/t/for-beginners-do-not-use-view-or-reshape-to-swap-dimensions-of-tensors/75524">For beginners: Do not use view() or reshape() to swap dimensions of tensors!</a></p>
</blockquote>
<h2 id="归一化层">归一化层<a class="headerlink" href="#归一化层" title="Permanent link">&para;</a></h2>
<h3 id="batchnorm1d">BatchNorm1d<a class="headerlink" href="#batchnorm1d" title="Permanent link">&para;</a></h3>
<h3 id="batchnorm2d">BatchNorm2d<a class="headerlink" href="#batchnorm2d" title="Permanent link">&para;</a></h3>
<h3 id="batchnorm3d">BatchNorm3d<a class="headerlink" href="#batchnorm3d" title="Permanent link">&para;</a></h3>
<h2 id="transformer-层">Transformer 层<a class="headerlink" href="#transformer-层" title="Permanent link">&para;</a></h2>
<h2 id="嵌入层">嵌入层<a class="headerlink" href="#嵌入层" title="Permanent link">&para;</a></h2>
<h3 id="embedding">Embedding<a class="headerlink" href="#embedding" title="Permanent link">&para;</a></h3>
<p>嵌入层。</p>
<p>此模块保存固定词汇表规模和维数的嵌入，输入索引列表，输出相应的嵌入。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
<span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
<span class="n">_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># num_embeddings      词汇表规模</span>
<span class="c1"># embedding_dim       嵌入维数</span>
<span class="c1"># padding_idx         指定索引的嵌入向量默认为全0,并且在训练过程中不会更新</span>
<span class="c1"># max_norm            若嵌入向量的范数大于此参数,则重新规范化到范数等于此参数</span>
<span class="c1"># norm_type           lp范数的p值</span>
<span class="c1"># scale_grad_by_freq  若为`True`,则梯度乘以小批次中词频的倒数</span>
<span class="c1"># sparse              若为`True`,则对于`weight`矩阵的梯度将会是一个稀疏张量</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>   <span class="c1"># 词汇表规模 = 10, 嵌入维数 = 3, 共30个参数</span>
                                      <span class="c1"># 注意10表示词汇表规模,输入为0-9之间的整数而非10维向量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.0251</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6902</span><span class="p">,</span>  <span class="mf">0.7172</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.6431</span><span class="p">,</span>  <span class="mf">0.0748</span><span class="p">,</span>  <span class="mf">0.6969</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.4970</span><span class="p">,</span>  <span class="mf">1.3448</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9685</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.3677</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7265</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1685</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">1.4970</span><span class="p">,</span>  <span class="mf">1.3448</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9685</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.4362</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4004</span><span class="p">,</span>  <span class="mf">0.9400</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.6431</span><span class="p">,</span>  <span class="mf">0.0748</span><span class="p">,</span>  <span class="mf">0.6969</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.9124</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3616</span><span class="p">,</span>  <span class="mf">1.1151</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">padding_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>    <span class="c1"># 默认为全0</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7895</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7089</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0364</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6778</span><span class="p">,</span>  <span class="mf">0.5803</span><span class="p">,</span>  <span class="mf">0.2678</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="o">...</span>     <span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">padding_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>   <span class="c1"># 手动修改</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">embedding</span><span class="o">.</span><span class="n">weight</span>
<span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7895</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7089</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0364</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6778</span><span class="p">,</span>  <span class="mf">0.5803</span><span class="p">,</span>  <span class="mf">0.2678</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note 注意">
<p class="admonition-title">Note</p>
<p>当 <code>max_norm</code> 不为 <code>None</code> 时，嵌入层的前向方法会原位修改 <code>weight</code> 张量的值（如果嵌入向量的范数超限）。由于需要计算梯度的张量不能被原位修改，如果在调用嵌入层的前向方法之前要对 <code>weight</code> 张量执行可微运算就需要克隆 <code>weight</code> 张量，例如：
<div class="highlight"><pre><span></span><code><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>  <span class="c1"># weight must be cloned for this to be differentiable</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>            <span class="c1"># modifies weight in-place</span>
<span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
</div>
<h2 id="丢弃层">丢弃层<a class="headerlink" href="#丢弃层" title="Permanent link">&para;</a></h2>
<h3 id="dropout">Dropout<a class="headerlink" href="#dropout" title="Permanent link">&para;</a></h3>
<p>一维丢弃层。</p>
<p>在训练模式下，以给定概率 <span class="arithmatex">\(p\)</span> 将张量的每个元素随机置零，剩余的元素乘以 <span class="arithmatex">\(1/(1-p)\)</span>。每次调用丢弃层的结果是独立的。</p>
<p>在测试模式下，直接返回输入张量。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># p        元素置零的概率</span>
<span class="c1"># inplace  若为`True`,则原位执行此操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.1218</span><span class="p">,</span>  <span class="mf">0.1338</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0065</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6416</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.8897</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6002</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6922</span><span class="p">,</span>  <span class="mf">0.0689</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.3392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5207</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2739</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9653</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6608</span><span class="p">,</span>  <span class="mf">0.9212</span><span class="p">,</span>  <span class="mf">0.0579</span><span class="p">,</span>  <span class="mf">0.9670</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.2436</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2832</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.7794</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2004</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3844</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0414</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9306</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">1.9340</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.5664</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.4008</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7688</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">3.8680</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.1218</span><span class="p">,</span>  <span class="mf">0.1338</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0065</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6416</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.8897</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6002</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6922</span><span class="p">,</span>  <span class="mf">0.0689</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.3392</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5207</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2739</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9653</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6608</span><span class="p">,</span>  <span class="mf">0.9212</span><span class="p">,</span>  <span class="mf">0.0579</span><span class="p">,</span>  <span class="mf">0.9670</span><span class="p">]])</span>
</code></pre></div>
<h3 id="dropout2d">Dropout2d<a class="headerlink" href="#dropout2d" title="Permanent link">&para;</a></h3>
<p>二维丢弃层。</p>
<p>在训练模式下，以给定概率 <span class="arithmatex">\(p\)</span> 将张量 <span class="arithmatex">\((N,C,H,W)\)</span> 的每个通道随机置零，剩余的通道乘以 <span class="arithmatex">\(1/(1-p)\)</span>。通常用于 <code>nn.Conv2d</code> 模块的输出。每次调用丢弃层的结果是独立的。</p>
<p>在测试模式下，直接返回输入张量。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># p        通道置零的概率</span>
<span class="c1"># inplace  若为`True`,则原位执行此操作</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">1.7200</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7948</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.1551</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8467</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">1.0479</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6172</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.8419</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8668</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.4776</span><span class="p">,</span>  <span class="mf">1.7682</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.0376</span><span class="p">,</span>  <span class="mf">0.8871</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">0.8826</span><span class="p">,</span>  <span class="mf">1.5624</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.4573</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0573</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">1.4288</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6288</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.2000</span><span class="p">,</span>  <span class="mf">1.3250</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">1.8099</span><span class="p">,</span>  <span class="mf">0.7262</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.5595</span><span class="p">,</span>  <span class="mf">1.4562</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.7452</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1875</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0116</span><span class="p">,</span>  <span class="mf">0.5224</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.1152</span><span class="p">,</span>  <span class="mf">0.1012</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.5634</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1202</span><span class="p">]]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">output</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">2.0957</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2344</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">1.6837</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7336</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.9551</span><span class="p">,</span>  <span class="mf">3.5364</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">2.0752</span><span class="p">,</span>  <span class="mf">1.7741</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">1.7651</span><span class="p">,</span>  <span class="mf">3.1247</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">2.9146</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1147</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">3.6198</span><span class="p">,</span>  <span class="mf">1.4524</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">1.1190</span><span class="p">,</span>  <span class="mf">2.9124</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0000</span><span class="p">]]]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">1.7200</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7948</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.1551</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8467</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">1.0479</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6172</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.8419</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8668</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.4776</span><span class="p">,</span>  <span class="mf">1.7682</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.0376</span><span class="p">,</span>  <span class="mf">0.8871</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">0.8826</span><span class="p">,</span>  <span class="mf">1.5624</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.4573</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0573</span><span class="p">]],</span>

         <span class="p">[[</span><span class="o">-</span><span class="mf">1.4288</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6288</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.2000</span><span class="p">,</span>  <span class="mf">1.3250</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">1.8099</span><span class="p">,</span>  <span class="mf">0.7262</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.5595</span><span class="p">,</span>  <span class="mf">1.4562</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.7452</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1875</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.0116</span><span class="p">,</span>  <span class="mf">0.5224</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">0.1152</span><span class="p">,</span>  <span class="mf">0.1012</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.5634</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1202</span><span class="p">]]]])</span>
</code></pre></div>
<h2 id="激活函数">激活函数<a class="headerlink" href="#激活函数" title="Permanent link">&para;</a></h2>
<h3 id="elu">ELU<a class="headerlink" href="#elu" title="Permanent link">&para;</a></h3>
<p>ELU 激活函数层。见 <code>torch.nn.functional.elu</code>。</p>
<div class="arithmatex">\[
{\rm ELU}(x)=\max(0,x)+\min(0,\alpha(\exp(x)-1))
\]</div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># alpha    α值</span>
<span class="c1"># inplace  若为`True`,则进行原位操作</span>
</code></pre></div>
<p><img alt="" src="https://pytorch.org/docs/stable/_images/ELU.png" /></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">elu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0358</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9567</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9125</span><span class="p">,</span>  <span class="mf">0.7638</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">elu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.6451</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6159</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5985</span><span class="p">,</span>  <span class="mf">0.7638</span><span class="p">])</span>
</code></pre></div>
<h3 id="leakyrelu">LeakyReLU<a class="headerlink" href="#leakyrelu" title="Permanent link">&para;</a></h3>
<p>Leaky ReLU 激活函数层。见 <code>torch.nn.functional.leaky_relu</code>。</p>
<div class="arithmatex">\[
{\rm LeakyReLU}(x)=\max(0,x)+{\rm negative\_slope*\min(0,x)}
\]</div>
<p><img alt="" src="https://pytorch.org/docs/stable/_images/LeakyReLU.png" /></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">lrelu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.4089</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1398</span><span class="p">,</span>  <span class="mf">1.3921</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5492</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lrelu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0141</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0114</span><span class="p">,</span>  <span class="mf">1.3921</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0055</span><span class="p">])</span>
</code></pre></div>
<h3 id="relu">ReLU<a class="headerlink" href="#relu" title="Permanent link">&para;</a></h3>
<p>ReLU 激活函数层。见 <code>torch.nn.functional.relu</code>。</p>
<div class="arithmatex">\[
{\rm ReLU}(x)=\max(0,x)
\]</div>
<p><img alt="" src="https://pytorch.org/docs/stable/_images/ReLU.png" /></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5151</span><span class="p">,</span>  <span class="mf">0.0423</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8955</span><span class="p">,</span>  <span class="mf">0.0784</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">relu</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0423</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0784</span><span class="p">])</span>
</code></pre></div>
<h3 id="sigmoid">Sigmoid<a class="headerlink" href="#sigmoid" title="Permanent link">&para;</a></h3>
<p>Logistic 激活函数层。见 <code>torch.sigmoid</code>、<code>torch.special.expit</code>。</p>
<div class="arithmatex">\[
\sigma(x)=\frac{1}{1+\exp(-x)}
\]</div>
<p><img alt="" src="https://pytorch.org/docs/stable/_images/Sigmoid.png" /></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">logistic</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0796</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5545</span><span class="p">,</span>  <span class="mf">1.6273</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3333</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">logistic</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.4801</span><span class="p">,</span> <span class="mf">0.3648</span><span class="p">,</span> <span class="mf">0.8358</span><span class="p">,</span> <span class="mf">0.2086</span><span class="p">])</span>
</code></pre></div>
<h3 id="softmax-logsoftmax">Softmax, LogSoftmax<a class="headerlink" href="#softmax-logsoftmax" title="Permanent link">&para;</a></h3>
<p>Softmax 层。<code>torch.nn.LogSoftmax</code> 相当于在 Softmax 层的基础上再对所有元素求（自然）对数。</p>
<div class="arithmatex">\[
{\rm Softmax}(x_i)=\frac{\exp(x_i)}{\sum_j\exp(x_j)}\\
{\rm LogSoftmax}(x_i)=\ln \frac{\exp(x_i)}{\sum_j\exp(x_j)}
\]</div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">sm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sm</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0321</span><span class="p">,</span> <span class="mf">0.0871</span><span class="p">,</span> <span class="mf">0.2369</span><span class="p">,</span> <span class="mf">0.6439</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsm</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>            <span class="c1"># logsoftmax() = softmax() + log()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">3.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4402</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sm</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">3.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4402</span><span class="p">])</span>
</code></pre></div>
<h3 id="tanh">Tanh<a class="headerlink" href="#tanh" title="Permanent link">&para;</a></h3>
<p>tanh 激活函数层。见 <code>torch.tanh</code>。</p>
<div class="arithmatex">\[
\tanh(x)=\frac{\exp(x)-\exp(-x)}{\exp(x)+\exp(-x)}
\]</div>
<p><img alt="" src="https://pytorch.org/docs/stable/_images/Tanh.png" /></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.1921</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0885</span><span class="p">,</span>  <span class="mf">0.2970</span><span class="p">,</span>  <span class="mf">0.3345</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tanh</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.8312</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7963</span><span class="p">,</span>  <span class="mf">0.2886</span><span class="p">,</span>  <span class="mf">0.3225</span><span class="p">])</span>
</code></pre></div>
<h2 id="损失函数">损失函数<a class="headerlink" href="#损失函数" title="Permanent link">&para;</a></h2>
<h3 id="bceloss">BCELoss<a class="headerlink" href="#bceloss" title="Permanent link">&para;</a></h3>
<p>二元交叉熵损失函数层。
$$
l_n=-w_n(t_n\log y_n+(1-t_n)\log (1-y_n))\
l=\sum_n l_n {\rm 或} l=\frac{1}{N}\sum_n l_n
$$
其中 <span class="arithmatex">\(N\)</span> 为批次规模， <span class="arithmatex">\(w_n\)</span> 为  <code>weight</code> 参数指定的权重。</p>
<blockquote>
<p>若 <span class="arithmatex">\(y_n\)</span> 取 <span class="arithmatex">\(0\)</span> 或 <span class="arithmatex">\(1\)</span>，则 <span class="arithmatex">\(l_n\)</span> 表达式中的对数项之一就会在数学上无意义。PyTorch 选择设 <span class="arithmatex">\(\log(0)=-\infty\)</span>，但损失表达式中存在无穷项会产生一些问题：</p>
<ol>
<li>若 <span class="arithmatex">\(t_n=0\)</span> 或 <span class="arithmatex">\(1-t_n=0\)</span>，则会出现 0 乘以无穷。</li>
<li>梯度计算链中也会存在无穷项，因为 <span class="arithmatex">\(\frac{\partial l_n}{\partial y_n}=-w_n(\frac{t_n}{y_n}-\frac{1-t_n}{1-y_n})\)</span>。</li>
</ol>
<p>PyTorch 的解决方法是为对数项应用最小值 -100，这样损失值总是有限值，并且反向计算也是线性的。</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># weight         为每个类别手动指定的权重,应为长度为C的一维张量.默认为全1张量</span>
<span class="c1"># size_average   deprecated</span>
<span class="c1"># reduce         deprecated</span>
<span class="c1"># reduction      指定对输出应用的归约方法.若为`&#39;none&#39;`,则不归约;若为`&#39;sum&#39;`,则对输出的所有元素求和;</span>
<span class="c1">#                若为`&#39;mean&#39;`,则对输出的所有元素求平均</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.5620</span><span class="p">,</span> <span class="mf">0.1098</span><span class="p">,</span> <span class="mf">0.8769</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.2746</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.3577</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.9293</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">.5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">50.</span><span class="p">)</span>
</code></pre></div>
<h3 id="crossentropyloss">CrossEntropyLoss<a class="headerlink" href="#crossentropyloss" title="Permanent link">&para;</a></h3>
<p>交叉熵损失函数层。相当于将 <code>LogSoftmax</code> 和 <code>NLLLoss</code> 组合为一个模块。</p>
<p>通常用于多分类问题（<span class="arithmatex">\(C\)</span> 个类别）；输入张量应当包含的是生的、未归一化的每个类别的分数，形状为 <span class="arithmatex">\((batch\_size,C)\)</span> ；目标张量应当是批次规模长度的一维张量，其中每个值是 <span class="arithmatex">\([0, C-1]\)</span> 范围内的整数索引，代表正确的类别。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># weight         为每个类别手动指定的权重,应为长度为C的一维张量.默认为全1张量</span>
<span class="c1"># size_average   deprecated</span>
<span class="c1"># ignore_index   忽略所有类别为指定索引的样本</span>
<span class="c1"># reduce         deprecated</span>
<span class="c1"># reduction      指定对输出应用的归约方法.若为`&#39;none&#39;`,则不归约;若为`&#39;sum&#39;`,则对输出的所有元素求和;</span>
<span class="c1">#                若为`&#39;mean&#39;`,则对输出的所有元素求平均</span>
</code></pre></div>
<ul>
<li>输入形状： <span class="arithmatex">\((N,C)\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模，<span class="arithmatex">\(C\)</span> 表示类别数；或 <span class="arithmatex">\((N,C,d_1,d_2,\cdots,d_k)\)</span>，其中 <span class="arithmatex">\(d_i\)</span> 表示额外的维度。</li>
<li>目标形状： <span class="arithmatex">\((N)\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模，每一个值是 <span class="arithmatex">\([0, C-1]\)</span> 范围内的整数索引；或 <span class="arithmatex">\((N,d_1,d_2,\cdots,d_k)\)</span>，其中 <span class="arithmatex">\(d_i\)</span> 表示额外的维度。</li>
<li>输出形状：标量；若 <code>reduction</code> 为 <code>'none'</code>，则与目标形状相同。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>    <span class="c1"># 输出分数</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>                  <span class="c1"># 标签</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.8230</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.0230</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.2230</span><span class="p">)</span>

<span class="c1"># CrossEntropyLoss() = softmax() + log() + NLLLoss() = logsoftmax() + NLLLoss()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.4377</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3976</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3221</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mf">1.8402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1696</span><span class="p">,</span>  <span class="mf">0.4744</span><span class="p">],</span>
                      <span class="p">[</span><span class="o">-</span><span class="mf">3.4641</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2303</span><span class="p">,</span>  <span class="mf">0.3552</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.4197</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.4377</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3976</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3221</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mf">1.8402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1696</span><span class="p">,</span>  <span class="mf">0.4744</span><span class="p">],</span>
                      <span class="p">[</span><span class="o">-</span><span class="mf">3.4641</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2303</span><span class="p">,</span>  <span class="mf">0.3552</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.4197</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.4377</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3976</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3221</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mf">1.8402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1696</span><span class="p">,</span>  <span class="mf">0.4744</span><span class="p">],</span>
                      <span class="p">[</span><span class="o">-</span><span class="mf">3.4641</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2303</span><span class="p">,</span>  <span class="mf">0.3552</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">logsoftmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">logsoftmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.4197</span><span class="p">)</span>
</code></pre></div>
<h3 id="kldivloss">KLDivLoss<a class="headerlink" href="#kldivloss" title="Permanent link">&para;</a></h3>
<h3 id="mseloss">MSELoss<a class="headerlink" href="#mseloss" title="Permanent link">&para;</a></h3>
<p>均方差损失函数层。</p>
<div class="arithmatex">\[
l_n=(y_n-t_n)^2\\
l=\sum_n l_n\ {\rm 或}\ l=\frac{1}{N}\sum_n l_n
\]</div>
<p>其中 <span class="arithmatex">\(N\)</span> 为批次规模。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># size_average    deprecated</span>
<span class="c1"># reduce          deprecated</span>
<span class="c1"># reduction       指定对输出应用的归约方法.若为`&#39;none&#39;`,则不归约;若为`&#39;sum&#39;`,则对输出的所有元素求和;</span>
<span class="c1">#                 若为`&#39;mean&#39;`,则对输出的所有元素求平均</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">2.2500</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">9.</span><span class="p">)</span>
</code></pre></div>
<h3 id="nllloss">NLLLoss<a class="headerlink" href="#nllloss" title="Permanent link">&para;</a></h3>
<p>负对数似然损失层。</p>
<div class="arithmatex">\[
l_n = -w_{y_n}x_{n,y_n}\\
l=\sum_n l_n\ {\rm 或}\ l=\frac{1}{N}\sum_n l_n
\]</div>
<p>其中 <span class="arithmatex">\(x\)</span> 为输入，<span class="arithmatex">\(y\)</span> 为目标，<span class="arithmatex">\(w\)</span> 为 <code>weight</code> 参数指定的权重，<span class="arithmatex">\(N\)</span> 为批次规模。</p>
<p>通常用于多分类问题（<span class="arithmatex">\(C\)</span> 个类别）；输入张量应当包含的是每个类别的概率的（自然）对数，形状为 <span class="arithmatex">\((batch\_size,C)\)</span> ；目标张量应当是批次规模长度的一维张量，其中每个值是 <span class="arithmatex">\([0, C-1]\)</span> 范围内的整数索引，代表正确的类别。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># weight         为每个类别手动指定的权重,应为长度为C的一维张量.默认为全1张量</span>
<span class="c1"># size_average   deprecated</span>
<span class="c1"># ignore_index   忽略所有类别为指定索引的样本</span>
<span class="c1"># reduce         deprecated</span>
<span class="c1"># reduction      指定对输出应用的归约方法.若为`&#39;none&#39;`,则不归约;若为`&#39;sum&#39;`,则对输出的所有元素求和;</span>
<span class="c1">#                若为`&#39;mean&#39;`,则对输出的所有元素求平均</span>
</code></pre></div>
<ul>
<li>输入形状：<span class="arithmatex">\((N,C)\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模，<span class="arithmatex">\(C\)</span> 表示类别数；或 <span class="arithmatex">\((N,C,d_1,d_2,\cdots,d_k)\)</span>，其中 <span class="arithmatex">\(d_i\)</span> 表示额外的维度。</li>
<li>目标形状：<span class="arithmatex">\((N)\)</span>，其中 <span class="arithmatex">\(N\)</span> 表示批次规模，每一个值是 <span class="arithmatex">\([0, C-1]\)</span> 范围内的整数索引；或 <span class="arithmatex">\((N,d_1,d_2,\cdots,d_k)\)</span>，其中 <span class="arithmatex">\(d_i\)</span> 表示额外的维度。</li>
<li>输出形状：标量；若 <code>reduction</code> 为 <code>'none'</code>，则与目标形状相同。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.4377</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3976</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3221</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mf">1.8402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1696</span><span class="p">,</span>  <span class="mf">0.4744</span><span class="p">],</span>
                      <span class="p">[</span><span class="o">-</span><span class="mf">3.4641</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2303</span><span class="p">,</span>  <span class="mf">0.3552</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">lsm</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.4736</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3089</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2334</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.3287</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3385</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6945</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">4.2759</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0421</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4566</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.4197</span><span class="p">)</span>         <span class="c1"># 0.4197 = (0.4736 + 0.3287 + 0.4566) / 3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.4012</span><span class="p">)</span>         <span class="c1"># 0.4012 = (0.4736 + 0.3287) / 2</span>
</code></pre></div>
<h3 id="l1loss">L1Loss<a class="headerlink" href="#l1loss" title="Permanent link">&para;</a></h3>
<p>平均绝对误差损失函数层。</p>
<div class="arithmatex">\[
l_n=|y_n-t_n|\\
l=\sum_n l_n\ {\rm 或}\ l=\frac{1}{N}\sum_n l_n
\]</div>
<p>其中 <span class="arithmatex">\(N\)</span> 为批次规模。</p>
<p>支持实数值和复数值输入。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># size_average    deprecated</span>
<span class="c1"># reduce          deprecated</span>
<span class="c1"># reduction       指定对输出应用的归约方法.若为`&#39;none&#39;`,则不归约;若为`&#39;sum&#39;`,则对输出的所有元素求和;</span>
<span class="c1">#                 若为`&#39;mean&#39;`,则对输出的所有元素求平均</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">1.2500</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">5.</span><span class="p">)</span>
</code></pre></div>
<h2 id="数据并行模组">数据并行模组<a class="headerlink" href="#数据并行模组" title="Permanent link">&para;</a></h2>
<h3 id="dataparallel">DataParallel<a class="headerlink" href="#dataparallel" title="Permanent link">&para;</a></h3>
<h3 id="paralleldistributeddataparallel">parallel.DistributedDataParallel<a class="headerlink" href="#paralleldistributeddataparallel" title="Permanent link">&para;</a></h3>
<p>在模块级别实现基于 <code>torch.distributed</code> 包的分布式数据并行。</p>
<p>此容器通过沿批次维度分割输入数据并分配到各指定设备来并行化指定模块的运行。模块被复制到每一台机器和每一个设备上，每一个模型副本处理输入数据的一部分。在反向传递的过程中，来自每一个模型副本的梯度会被平均。</p>
<p>创建此类的对象需要 <code>torch.distributed</code> 已经初始化，通过调用 <code>torch.distributed.init_process_group()</code>。</p>
<p>要在一台有 N 个 GPU 的主机上使用 <code>DistributedDataParallel</code>，你需要 spawn N 个进程，并保证每个进程独占地使用一个 GPU。这可以通过为每个进程设定环境变量 <code>CUDA_VISIBLE_DEVICES</code> 或调用 <code>torch.cuda.set_device(i)</code> 来实现。在每一个进程中，你需要参照下面的方法构造模块：</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;...&#39;</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">output_device</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<p>当使用 GPU 时，<code>nccl</code> 后端是目前最快和最推荐使用的后端。该后端同时适用于单节点和多节点分布式训练。</p>
<p>一个模型训练在 M 个节点上并且批次规模为 N，相比其训练在单个节点上并且批次规模为 MN，在损失在批次的各样本间求和（而非求平均）的情况下，前者的梯度将是后者的 M 分之一。当你想要得到一个与本地训练在数学上等价的分布式训练过程时，你需要将这一点考虑在内。但在大部分情况下，你可以将 <code>DistributedDataParallel</code> 包装的模型、 <code>DateParallel</code> 包装的模型和单个 GPU 上的普通模型同等对待。</p>
<p>模型参数不会在进程间广播；<code>DistributedDataParallel</code> 模块对梯度执行 All-Reduce 操作，并假定所有进程中的参数被优化器以同样的方式修改。缓冲区（例如 BatchNorm 数据）在每一次迭代中从 rank 0 进程的模型副本广播到所有其他模型副本。</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">broadcast_buffers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">process_group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bucket_cap_mb</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_reduction</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gradient_as_bucket_view</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># module             要并行化的模块</span>
<span class="c1"># device_ids         1)对于单设备模块,`device_ids`只能包含一个设备的id,其代表此进程的模块所放置的CUDA设备</span>
<span class="c1">#                    2)对于多设备模块,`device_ids`必须为`None`</span>
<span class="c1">#                    在这两种情况下,当`device_ids`为`None`时,前向计算的输入数据和实际的模块都必须放置在</span>
<span class="c1">#                    正确的设备上</span>
<span class="c1"># output_device      单CUDA设备模块的输出放置的设备位置.对于多设备模块和CPU模块,此参数必须为`None`,并且模块本身</span>
<span class="c1">#                    决定了输出的位置</span>
<span class="c1"># broadcast_buffers</span>
<span class="c1"># process_group      用于进行分布式数据All-Reduce的进程组.若为`None`,则使用默认进程组,即由</span>
<span class="c1">#                    `torch.distributed.init_process_group()`创建的进程组</span>
</code></pre></div>
<h2 id="实用功能">实用功能<a class="headerlink" href="#实用功能" title="Permanent link">&para;</a></h2>
<h3 id="flatten">Flatten<a class="headerlink" href="#flatten" title="Permanent link">&para;</a></h3>
<p>展开张量的若干个连续维度，用于 <code>Sequential</code> 顺序模型。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">flatten</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">60</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># 展开第1到第2个维度</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">flatten</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</code></pre></div>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    2023-12-11
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="../../../javascripts/tex-mml-chtml.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.cs/net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>