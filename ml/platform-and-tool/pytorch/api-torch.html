
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="xyx">
      
      
        <link rel="canonical" href="https://xyxxxxx.github.io/note/ml/platform-and-tool/pytorch/api-torch.html">
      
      
        <link rel="prev" href="torchserve.html">
      
      
        <link rel="next" href="api-nn.html">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.1">
    
    
      
        <title>API: torch - 笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.45e1311d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="light-green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torch" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="笔记" class="md-header__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API: torch
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../index.html" class="md-tabs__link">
        
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/index.html" class="md-tabs__link">
          
  
    
  
  数学

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../cs/dsa/data-structure/index.html" class="md-tabs__link">
          
  
    
  
  CS

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../python/index.html" class="md-tabs__link">
          
  
    
  
  Python

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../index.html" class="md-tabs__link">
          
  
    
  
  机器学习

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../reference-and-tool/linux/linux-command.html" class="md-tabs__link">
          
  
    
  
  参考和工具

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../web/simple-html.html" class="md-tabs__link">
          
  
    
  
  前端

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="笔记" class="md-nav__button md-logo" aria-label="笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/algebra/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    代数
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            代数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/elementary-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/linear-algebra-understanding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数理解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/algebra/abstract-algebra.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    抽象代数
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/analysis/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分析
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/multivariate-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多元微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/matrix-calculus.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    矩阵微积分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/differential-equation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微分方程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/complex-analysis.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/analysis/mathematical-physics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学物理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    应用数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            应用数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/optimization/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数学优化
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_2" id="__nav_2_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_2">
            <span class="md-nav__icon md-icon"></span>
            数学优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-set.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/convex-optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    凸优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/duality.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对偶性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/optimization/nlp.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非线性优化
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    概率论与数理统计
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_3" id="__nav_2_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_3">
            <span class="md-nav__icon md-icon"></span>
            概率论与数理统计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/probability-of-event.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    事件的概率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/random-variable.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/probability-theory-and-mathematical-statistics/limit-theorems.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    极限定理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/applied-mathematics/stochastic-process/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    随机过程
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4_4" id="__nav_2_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_4">
            <span class="md-nav__icon md-icon"></span>
            随机过程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/stochastic-process-introduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    随机过程基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/markov-chain.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    马尔可夫链
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/applied-mathematics/stochastic-process/poisson-process.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泊松过程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../math/discrete-mathematics/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    离散数学
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            离散数学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/mathematical-logic.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学逻辑
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/set-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    集合论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/enumerative-combinatorics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    组合数学
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/polynomial.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多项式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/graph-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/discrete-mathematics/number-theory.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数论
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    CS
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            CS
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    数据结构与算法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构与算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/data-structure/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    数据结构
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            数据结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/array-and-linked-list.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数组和链表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/stack-and-queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    栈和队列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/binary-search-tree.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    二叉搜索树
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/hash-table.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    哈希表
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/graph.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/data-structure/heap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    堆
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/dsa/algorithm/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    算法
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            算法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/common-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常见算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/divide-and-conquer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分而治之
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/dynamic-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动态规划
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/greedy-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贪心算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/backtracking.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回溯法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/network-flow-algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络流算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/algorithm/linear-programming.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性规划
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/dsa/leetcode-examples.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leetcode 例题
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/net/net-model/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    网络模型
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2_2" id="__nav_3_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_2">
            <span class="md-nav__icon md-icon"></span>
            网络模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/transport-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    传输层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/network-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/net/net-model/application-layer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    应用层
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cs/information-theory/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    信息论
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            信息论
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cs/information-theory/entropy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    熵、相对熵与互信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Python
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/runtime-environment-devtool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运行环境与开发工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/data-type-and-operation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型与操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/function.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/control-flow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    控制流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/container-type.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    容器类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/iterator-and-generator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迭代器与生成器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/oop.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向对象编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/process-and-thread.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    进程与线程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/error-handling-and-unit-test.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    错误处理与单元测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/module-and-package.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模块与包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/standard-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    标准库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_13" id="__nav_4_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_13">
            <span class="md-nav__icon md-icon"></span>
            标准库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/argparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    argparse——命令行选项、参数和子命令解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base64——Base16, Base32, Base64, Base85 数据编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/builtins.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    builtins——内建对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.abc.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections.abc——容器的抽象基类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/collections.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    collections——容器数据类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/configparser.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configparser——配置文件解析器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/concurrent.futures.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    concurrent.futures——启动并行任务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/copy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    copy——浅层和深层复制操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/csv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    csv——CSV 文件读写
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/datetime.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    datetime——基本日期和时间类型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/enum.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    enum——对枚举的支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functions.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    内置函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/functools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    functools——高阶函数和可调用对象上的操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/glob.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    glob——Unix 风格路径名模式扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/graphlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphlib——操作类似图的结构的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hashlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hashlib——安全哈希与消息摘要
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/hmac.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hmac——基于密钥的消息验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/importlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    importlib——import 的实现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/inspect.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    inspect——检查对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/io.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    io——处理流的核心工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/itertools.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    itertools——为高效循环而创建迭代器的函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json——JSON 编码和解码器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/keyword.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    keyword——检验 Python 关键字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/marshal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marshal——内部 Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    math——数学函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    multiprocessing——基于进程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/operator.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    operator——标准运算符替代函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os——多种操作系统接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/os.path.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    os.path——常用路径操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pathlib.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pathlib——面向对象的文件系统路径
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pickle.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pickle——Python 对象序列化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/platform.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    platform——获取底层平台的标识数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/pprint.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pprint——数据美化输出
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/queue.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    queue——一个同步的队列类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    random——生成伪随机数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/re.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    re——正则表达式操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/secrets.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    secrets——生成安全随机数字用于管理密码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/select.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    select——等待 I/O 完成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shlex.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shlex——简单的词法分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/shutil.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    shutil——高阶文件操作
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    signal——设置异步事件处理程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/socket.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    socket——底层网络接口
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/subprocess.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    subprocess——子进程管理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/sys.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sys——系统相关的参数和函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tarfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tarfile——读写 tar 归档文件
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/tempfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tempfile——生成临时文件和目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/threading.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    threading——基于线程的并行
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/time.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    time——时间的访问和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/timeit.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timeit——测量小段代码的执行时间
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/types.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    types——动态类型创建和内置类型名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/typing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    typing——类型提示支持
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.parse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.parse——用于解析 URL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/urllib.request.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    urllib.request——用于打开 URL 的可扩展库
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/uuid.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    uuid——RFC 4122 定义的 UUID 对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/weakref.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    weakref——弱引用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/standard-library/zipfile.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zipfile——使用 ZIP 存档
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_14" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../python/common-library/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    常用库
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_14" id="__nav_4_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_14">
            <span class="md-nav__icon md-icon"></span>
            常用库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/beautifulsoup.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BeautifulSoup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/click.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    click
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/filelock.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    filelock
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pillow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pillow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/pyyaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyYAML (yaml)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/requests.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    requests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/rich.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rich
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/common-library/websocket-client.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    websocket-client (websocket)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/style-guide.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    风格指南
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    机器学习
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    统计学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            统计学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/nb.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/perceptron.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    感知器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../statistical-learning/svm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    支持向量机
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/fnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前馈神经网络（FNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/cnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积神经网络（CNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rnn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    循环神经网络（RNN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/seq2seq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列到序列模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/transformer.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/self-supervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自监督学习模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/gan.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成对抗网络（GAN）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/rl.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deep-learning/auto-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    常用技术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            常用技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/optimization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/normalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    归一化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/generalization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泛化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/anomaly-detection.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    异常检测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/adversarial-attack.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗攻击
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/explainable-ml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型可解释性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/transfer-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/model-compression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型压缩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../technique/life-long-learning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    终身学习
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../nlp/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    自然语言处理专题
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            自然语言处理专题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/text-processing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    文本处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/language-model.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/sentiment-classification.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    朴素贝叶斯和情感分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/logistic-regression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    逻辑回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/embedding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/neural-network.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/part-of-speech-tagging.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词性标注和命名实体检测
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../distributed/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    分布式训练
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    平台和工具
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            平台和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../numpy/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    NumPy
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            NumPy
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../pandas/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pandas
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            pandas
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/get-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    快速入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/api.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../matplotlib/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    matplotlib
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_4" id="__nav_5_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_4">
            <span class="md-nav__icon md-icon"></span>
            matplotlib
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matplotlib/example.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    示例
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../tensorflow/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_5" id="__nav_5_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_5">
            <span class="md-nav__icon md-icon"></span>
            TensorFlow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/tensorflow.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-config.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-distribute.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.distribute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-image.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-keras.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.keras
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-linalg.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.linalg
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.math
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-random.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.random
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-signal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.signal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-strings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.strings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-train.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tf.train
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/api-tfds.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: tfds
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_6" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_6" id="__nav_5_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_7_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="pytorch.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchvision.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="torchserve.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchserve
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    API: torch
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="api-torch.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    API: torch
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#张量" class="md-nav__link">
    <span class="md-ellipsis">
      张量
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#device" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dtype" class="md-nav__link">
    <span class="md-ellipsis">
      dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#__getitem__-__setitem__-__delitem__" class="md-nav__link">
    <span class="md-ellipsis">
      __getitem__(), __setitem__(), __delitem__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_" class="md-nav__link">
    <span class="md-ellipsis">
      apply_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bool" class="md-nav__link">
    <span class="md-ellipsis">
      bool()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contiguous" class="md-nav__link">
    <span class="md-ellipsis">
      contiguous()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu" class="md-nav__link">
    <span class="md-ellipsis">
      cpu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data_ptr" class="md-nav__link">
    <span class="md-ellipsis">
      data_ptr()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detach" class="md-nav__link">
    <span class="md-ellipsis">
      detach()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device_1" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dim" class="md-nav__link">
    <span class="md-ellipsis">
      dim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expand" class="md-nav__link">
    <span class="md-ellipsis">
      expand()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expand_as" class="md-nav__link">
    <span class="md-ellipsis">
      expand_as()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fill_" class="md-nav__link">
    <span class="md-ellipsis">
      fill_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_device" class="md-nav__link">
    <span class="md-ellipsis">
      get_device()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grad" class="md-nav__link">
    <span class="md-ellipsis">
      grad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grad_fn" class="md-nav__link">
    <span class="md-ellipsis">
      grad_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_contiguous" class="md-nav__link">
    <span class="md-ellipsis">
      is_contiguous()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_cuda" class="md-nav__link">
    <span class="md-ellipsis">
      is_cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_leaf" class="md-nav__link">
    <span class="md-ellipsis">
      is_leaf()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#item" class="md-nav__link">
    <span class="md-ellipsis">
      item()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#new_full-new_ones-new_zeros" class="md-nav__link">
    <span class="md-ellipsis">
      new_full(), new_ones(), new_zeros()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal_" class="md-nav__link">
    <span class="md-ellipsis">
      normal_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numpy" class="md-nav__link">
    <span class="md-ellipsis">
      numpy()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random_" class="md-nav__link">
    <span class="md-ellipsis">
      random_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#repeat" class="md-nav__link">
    <span class="md-ellipsis">
      repeat()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad_" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retain_grad" class="md-nav__link">
    <span class="md-ellipsis">
      retain_grad()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter_" class="md-nav__link">
    <span class="md-ellipsis">
      scatter_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#select" class="md-nav__link">
    <span class="md-ellipsis">
      select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shape" class="md-nav__link">
    <span class="md-ellipsis">
      shape()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    <span class="md-ellipsis">
      size()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t" class="md-nav__link">
    <span class="md-ellipsis">
      T
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to" class="md-nav__link">
    <span class="md-ellipsis">
      to()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tolist" class="md-nav__link">
    <span class="md-ellipsis">
      tolist()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#type" class="md-nav__link">
    <span class="md-ellipsis">
      type()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unfold" class="md-nav__link">
    <span class="md-ellipsis">
      unfold()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uniform_" class="md-nav__link">
    <span class="md-ellipsis">
      uniform_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#view" class="md-nav__link">
    <span class="md-ellipsis">
      view()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#view_as" class="md-nav__link">
    <span class="md-ellipsis">
      view_as()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_" class="md-nav__link">
    <span class="md-ellipsis">
      zero_()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量类型操作" class="md-nav__link">
    <span class="md-ellipsis">
      张量类型操作
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量类型操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_default_dtype" class="md-nav__link">
    <span class="md-ellipsis">
      get_default_dtype()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_complex" class="md-nav__link">
    <span class="md-ellipsis">
      is_complex()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isfinite" class="md-nav__link">
    <span class="md-ellipsis">
      isfinite()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_floating_point" class="md-nav__link">
    <span class="md-ellipsis">
      is_floating_point()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isinf" class="md-nav__link">
    <span class="md-ellipsis">
      isinf()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnan" class="md-nav__link">
    <span class="md-ellipsis">
      isnan()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      is_tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_default_dtype" class="md-nav__link">
    <span class="md-ellipsis">
      set_default_dtype()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量创建" class="md-nav__link">
    <span class="md-ellipsis">
      张量创建
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量创建">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arange" class="md-nav__link">
    <span class="md-ellipsis">
      arange()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#as_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      as_tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clone" class="md-nav__link">
    <span class="md-ellipsis">
      clone()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eye" class="md-nav__link">
    <span class="md-ellipsis">
      eye()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_numpy" class="md-nav__link">
    <span class="md-ellipsis">
      from_numpy()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full" class="md-nav__link">
    <span class="md-ellipsis">
      full()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linspace" class="md-nav__link">
    <span class="md-ellipsis">
      linspace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logspace" class="md-nav__link">
    <span class="md-ellipsis">
      logspace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ones" class="md-nav__link">
    <span class="md-ellipsis">
      ones()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zeros" class="md-nav__link">
    <span class="md-ellipsis">
      zeros()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量操作" class="md-nav__link">
    <span class="md-ellipsis">
      张量操作
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cat" class="md-nav__link">
    <span class="md-ellipsis">
      cat()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chunk" class="md-nav__link">
    <span class="md-ellipsis">
      chunk()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flatten" class="md-nav__link">
    <span class="md-ellipsis">
      flatten()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flip" class="md-nav__link">
    <span class="md-ellipsis">
      flip()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fliplr-flipud" class="md-nav__link">
    <span class="md-ellipsis">
      fliplr(), flipud()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#index_select" class="md-nav__link">
    <span class="md-ellipsis">
      index_select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked_select" class="md-nav__link">
    <span class="md-ellipsis">
      masked_select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#movedim" class="md-nav__link">
    <span class="md-ellipsis">
      movedim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#narrow" class="md-nav__link">
    <span class="md-ellipsis">
      narrow()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nonezero" class="md-nav__link">
    <span class="md-ellipsis">
      nonezero()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#permute" class="md-nav__link">
    <span class="md-ellipsis">
      permute()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#repeat_interleave" class="md-nav__link">
    <span class="md-ellipsis">
      repeat_interleave()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshape" class="md-nav__link">
    <span class="md-ellipsis">
      reshape()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roll" class="md-nav__link">
    <span class="md-ellipsis">
      roll()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rot90" class="md-nav__link">
    <span class="md-ellipsis">
      rot90()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter_1" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#split" class="md-nav__link">
    <span class="md-ellipsis">
      split()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#squeeze" class="md-nav__link">
    <span class="md-ellipsis">
      squeeze()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack" class="md-nav__link">
    <span class="md-ellipsis">
      stack()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swapaxes" class="md-nav__link">
    <span class="md-ellipsis">
      swapaxes()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swapdims" class="md-nav__link">
    <span class="md-ellipsis">
      swapdims()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t_1" class="md-nav__link">
    <span class="md-ellipsis">
      t()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#take" class="md-nav__link">
    <span class="md-ellipsis">
      take()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#take_along_dim" class="md-nav__link">
    <span class="md-ellipsis">
      take_along_dim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tile" class="md-nav__link">
    <span class="md-ellipsis">
      tile()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transpose" class="md-nav__link">
    <span class="md-ellipsis">
      transpose()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unbind" class="md-nav__link">
    <span class="md-ellipsis">
      unbind()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsqueeze" class="md-nav__link">
    <span class="md-ellipsis">
      unsqueeze()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vstack-hstack" class="md-nav__link">
    <span class="md-ellipsis">
      vstack(), hstack()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#数学运算" class="md-nav__link">
    <span class="md-ellipsis">
      数学运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数学运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#abs" class="md-nav__link">
    <span class="md-ellipsis">
      abs()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add-sub" class="md-nav__link">
    <span class="md-ellipsis">
      add(), sub()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-any" class="md-nav__link">
    <span class="md-ellipsis">
      all(), any()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allclose" class="md-nav__link">
    <span class="md-ellipsis">
      allclose()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amax-amin" class="md-nav__link">
    <span class="md-ellipsis">
      amax(), amin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#angle" class="md-nav__link">
    <span class="md-ellipsis">
      angle()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmax-argmin" class="md-nav__link">
    <span class="md-ellipsis">
      argmax(), argmin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argsort" class="md-nav__link">
    <span class="md-ellipsis">
      argsort()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bincount" class="md-nav__link">
    <span class="md-ellipsis">
      bincount()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bmm" class="md-nav__link">
    <span class="md-ellipsis">
      bmm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ceil-floor" class="md-nav__link">
    <span class="md-ellipsis">
      ceil(), floor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clamp" class="md-nav__link">
    <span class="md-ellipsis">
      clamp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conj" class="md-nav__link">
    <span class="md-ellipsis">
      conj()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_nonzero" class="md-nav__link">
    <span class="md-ellipsis">
      count_nonzero()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross" class="md-nav__link">
    <span class="md-ellipsis">
      cross()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cummax-cummin" class="md-nav__link">
    <span class="md-ellipsis">
      cummax(), cummin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cumsum-cumprod" class="md-nav__link">
    <span class="md-ellipsis">
      cumsum(), cumprod()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deg2rad-rad2deg" class="md-nav__link">
    <span class="md-ellipsis">
      deg2rad(), rad2deg()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#det" class="md-nav__link">
    <span class="md-ellipsis">
      det()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diag" class="md-nav__link">
    <span class="md-ellipsis">
      diag()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagonal" class="md-nav__link">
    <span class="md-ellipsis">
      diagonal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diff" class="md-nav__link">
    <span class="md-ellipsis">
      diff()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dist" class="md-nav__link">
    <span class="md-ellipsis">
      dist()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dot" class="md-nav__link">
    <span class="md-ellipsis">
      dot()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equal" class="md-nav__link">
    <span class="md-ellipsis">
      equal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exp" class="md-nav__link">
    <span class="md-ellipsis">
      exp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fmax-fmin" class="md-nav__link">
    <span class="md-ellipsis">
      fmax(), fmin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frac" class="md-nav__link">
    <span class="md-ellipsis">
      frac()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcd-lcm" class="md-nav__link">
    <span class="md-ellipsis">
      gcd(), lcm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gt-ge-eq-le-lt-ne" class="md-nav__link">
    <span class="md-ellipsis">
      gt(), ge(), eq(), le(), lt(), ne()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hypot" class="md-nav__link">
    <span class="md-ellipsis">
      hypot()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inner" class="md-nav__link">
    <span class="md-ellipsis">
      inner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lerp" class="md-nav__link">
    <span class="md-ellipsis">
      lerp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log-log10-log2" class="md-nav__link">
    <span class="md-ellipsis">
      log(), log10(), log2()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logaddexp-logaddexp2" class="md-nav__link">
    <span class="md-ellipsis">
      logaddexp(), logaddexp2()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logit" class="md-nav__link">
    <span class="md-ellipsis">
      logit()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logsumexp" class="md-nav__link">
    <span class="md-ellipsis">
      logsumexp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lu" class="md-nav__link">
    <span class="md-ellipsis">
      lu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matmul" class="md-nav__link">
    <span class="md-ellipsis">
      matmul()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max-min-mean-std-median" class="md-nav__link">
    <span class="md-ellipsis">
      max(), min(), mean(), std(), median()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mm" class="md-nav__link">
    <span class="md-ellipsis">
      mm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mul-div-fmod-pow" class="md-nav__link">
    <span class="md-ellipsis">
      mul(), div(), fmod(), pow()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neg" class="md-nav__link">
    <span class="md-ellipsis">
      neg()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outer" class="md-nav__link">
    <span class="md-ellipsis">
      outer()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantile" class="md-nav__link">
    <span class="md-ellipsis">
      quantile()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-imag" class="md-nav__link">
    <span class="md-ellipsis">
      real(), imag()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reciprocal" class="md-nav__link">
    <span class="md-ellipsis">
      reciprocal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#round" class="md-nav__link">
    <span class="md-ellipsis">
      round()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      sigmoid()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sign" class="md-nav__link">
    <span class="md-ellipsis">
      sign()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sin-cos-tan-arcsin-arccos-arctan-sinh-cosh-tanh-arcsinh-arccosh-arctanh" class="md-nav__link">
    <span class="md-ellipsis">
      sin(), cos(), tan(), arcsin(), arccos(), arctan(), sinh(), cosh(), tanh(), arcsinh(), arccosh(), arctanh()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sort" class="md-nav__link">
    <span class="md-ellipsis">
      sort()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sqrt" class="md-nav__link">
    <span class="md-ellipsis">
      sqrt()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#square" class="md-nav__link">
    <span class="md-ellipsis">
      square()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum-prod" class="md-nav__link">
    <span class="md-ellipsis">
      sum(), prod()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      tanh()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topk" class="md-nav__link">
    <span class="md-ellipsis">
      topk()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trace" class="md-nav__link">
    <span class="md-ellipsis">
      trace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tril" class="md-nav__link">
    <span class="md-ellipsis">
      tril()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#triu" class="md-nav__link">
    <span class="md-ellipsis">
      triu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trunc" class="md-nav__link">
    <span class="md-ellipsis">
      trunc()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vdot" class="md-nav__link">
    <span class="md-ellipsis">
      vdot()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#逻辑运算" class="md-nav__link">
    <span class="md-ellipsis">
      逻辑运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="逻辑运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bitwise_and-bitwise_or-bitwise_xor-bitwise_not" class="md-nav__link">
    <span class="md-ellipsis">
      bitwise_and(), bitwise_or(), bitwise_xor(), bitwise_not()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isin" class="md-nav__link">
    <span class="md-ellipsis">
      isin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logical_and-logical_or-logical_xor-logical_not" class="md-nav__link">
    <span class="md-ellipsis">
      logical_and(), logical_or(), logical_xor(), logical_not()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#其他运算" class="md-nav__link">
    <span class="md-ellipsis">
      其他运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="其他运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numel" class="md-nav__link">
    <span class="md-ellipsis">
      numel()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unique" class="md-nav__link">
    <span class="md-ellipsis">
      unique()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#随机数和随机抽样" class="md-nav__link">
    <span class="md-ellipsis">
      随机数和随机抽样
    </span>
  </a>
  
    <nav class="md-nav" aria-label="随机数和随机抽样">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bernoulli" class="md-nav__link">
    <span class="md-ellipsis">
      bernoulli()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_rng_state" class="md-nav__link">
    <span class="md-ellipsis">
      get_rng_state()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#initial_seed" class="md-nav__link">
    <span class="md-ellipsis">
      initial_seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual_seed" class="md-nav__link">
    <span class="md-ellipsis">
      manual_seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multinomial" class="md-nav__link">
    <span class="md-ellipsis">
      multinomial()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal" class="md-nav__link">
    <span class="md-ellipsis">
      normal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson" class="md-nav__link">
    <span class="md-ellipsis">
      poisson()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rand" class="md-nav__link">
    <span class="md-ellipsis">
      rand()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randint" class="md-nav__link">
    <span class="md-ellipsis">
      randint()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randn" class="md-nav__link">
    <span class="md-ellipsis">
      randn()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randperm" class="md-nav__link">
    <span class="md-ellipsis">
      randperm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seed" class="md-nav__link">
    <span class="md-ellipsis">
      seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_rng_state" class="md-nav__link">
    <span class="md-ellipsis">
      set_rng_state()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#禁用梯度计算" class="md-nav__link">
    <span class="md-ellipsis">
      禁用梯度计算
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#序列化" class="md-nav__link">
    <span class="md-ellipsis">
      序列化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="序列化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    <span class="md-ellipsis">
      save()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    <span class="md-ellipsis">
      load()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#保存和加载张量" class="md-nav__link">
    <span class="md-ellipsis">
      保存和加载张量
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#保存和加载-torchnnmodules" class="md-nav__link">
    <span class="md-ellipsis">
      保存和加载 torch.nn.Modules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-nn.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-nn-functional.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-optim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-autograd.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-cuda.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-backends.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-distributed.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-multiprocessing.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-math.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.fft, torch.linalg, torch.special
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-sparse.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-utils-tensorboard.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lightning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="api-lightning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API: lightning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../horovod.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    horovod
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../nni/index.html" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    nni
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7_8" id="__nav_5_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_8">
            <span class="md-nav__icon md-icon"></span>
            nni
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nni/tuner.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    调参器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    参考和工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            参考和工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
        
          
          <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Linux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/linux/linux-command-line-tool.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux 命令行工具
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文件格式
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            文件格式
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/json.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    json
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/yaml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/xml.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xml
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/file-format/markdown.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    编码
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            编码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/charset-and-encoding.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    字符集和字符编码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/encoding/base64.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base64
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            文本工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/regular-expression.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    正则表达式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/text-tool/vim.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vim
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    构建工具
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            构建工具
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/build-tool/make.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    make
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/git.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference-and-tool/vocabulary.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    词汇表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    前端
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            前端
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-html.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple HTML
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../web/simple-css.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simple CSS
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#张量" class="md-nav__link">
    <span class="md-ellipsis">
      张量
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#device" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dtype" class="md-nav__link">
    <span class="md-ellipsis">
      dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#__getitem__-__setitem__-__delitem__" class="md-nav__link">
    <span class="md-ellipsis">
      __getitem__(), __setitem__(), __delitem__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apply_" class="md-nav__link">
    <span class="md-ellipsis">
      apply_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backward" class="md-nav__link">
    <span class="md-ellipsis">
      backward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bool" class="md-nav__link">
    <span class="md-ellipsis">
      bool()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#contiguous" class="md-nav__link">
    <span class="md-ellipsis">
      contiguous()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cpu" class="md-nav__link">
    <span class="md-ellipsis">
      cpu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data_ptr" class="md-nav__link">
    <span class="md-ellipsis">
      data_ptr()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detach" class="md-nav__link">
    <span class="md-ellipsis">
      detach()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device_1" class="md-nav__link">
    <span class="md-ellipsis">
      device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dim" class="md-nav__link">
    <span class="md-ellipsis">
      dim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expand" class="md-nav__link">
    <span class="md-ellipsis">
      expand()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#expand_as" class="md-nav__link">
    <span class="md-ellipsis">
      expand_as()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fill_" class="md-nav__link">
    <span class="md-ellipsis">
      fill_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_device" class="md-nav__link">
    <span class="md-ellipsis">
      get_device()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grad" class="md-nav__link">
    <span class="md-ellipsis">
      grad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grad_fn" class="md-nav__link">
    <span class="md-ellipsis">
      grad_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_contiguous" class="md-nav__link">
    <span class="md-ellipsis">
      is_contiguous()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_cuda" class="md-nav__link">
    <span class="md-ellipsis">
      is_cuda()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_leaf" class="md-nav__link">
    <span class="md-ellipsis">
      is_leaf()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#item" class="md-nav__link">
    <span class="md-ellipsis">
      item()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#new_full-new_ones-new_zeros" class="md-nav__link">
    <span class="md-ellipsis">
      new_full(), new_ones(), new_zeros()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal_" class="md-nav__link">
    <span class="md-ellipsis">
      normal_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numpy" class="md-nav__link">
    <span class="md-ellipsis">
      numpy()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random_" class="md-nav__link">
    <span class="md-ellipsis">
      random_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#repeat" class="md-nav__link">
    <span class="md-ellipsis">
      repeat()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#requires_grad_" class="md-nav__link">
    <span class="md-ellipsis">
      requires_grad_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retain_grad" class="md-nav__link">
    <span class="md-ellipsis">
      retain_grad()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter_" class="md-nav__link">
    <span class="md-ellipsis">
      scatter_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#select" class="md-nav__link">
    <span class="md-ellipsis">
      select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shape" class="md-nav__link">
    <span class="md-ellipsis">
      shape()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    <span class="md-ellipsis">
      size()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t" class="md-nav__link">
    <span class="md-ellipsis">
      T
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#to" class="md-nav__link">
    <span class="md-ellipsis">
      to()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tolist" class="md-nav__link">
    <span class="md-ellipsis">
      tolist()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#type" class="md-nav__link">
    <span class="md-ellipsis">
      type()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unfold" class="md-nav__link">
    <span class="md-ellipsis">
      unfold()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#uniform_" class="md-nav__link">
    <span class="md-ellipsis">
      uniform_()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#view" class="md-nav__link">
    <span class="md-ellipsis">
      view()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#view_as" class="md-nav__link">
    <span class="md-ellipsis">
      view_as()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_" class="md-nav__link">
    <span class="md-ellipsis">
      zero_()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量类型操作" class="md-nav__link">
    <span class="md-ellipsis">
      张量类型操作
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量类型操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#get_default_dtype" class="md-nav__link">
    <span class="md-ellipsis">
      get_default_dtype()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_complex" class="md-nav__link">
    <span class="md-ellipsis">
      is_complex()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isfinite" class="md-nav__link">
    <span class="md-ellipsis">
      isfinite()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_floating_point" class="md-nav__link">
    <span class="md-ellipsis">
      is_floating_point()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isinf" class="md-nav__link">
    <span class="md-ellipsis">
      isinf()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnan" class="md-nav__link">
    <span class="md-ellipsis">
      isnan()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#is_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      is_tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_default_dtype" class="md-nav__link">
    <span class="md-ellipsis">
      set_default_dtype()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量创建" class="md-nav__link">
    <span class="md-ellipsis">
      张量创建
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量创建">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arange" class="md-nav__link">
    <span class="md-ellipsis">
      arange()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#as_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      as_tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clone" class="md-nav__link">
    <span class="md-ellipsis">
      clone()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eye" class="md-nav__link">
    <span class="md-ellipsis">
      eye()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_numpy" class="md-nav__link">
    <span class="md-ellipsis">
      from_numpy()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full" class="md-nav__link">
    <span class="md-ellipsis">
      full()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linspace" class="md-nav__link">
    <span class="md-ellipsis">
      linspace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logspace" class="md-nav__link">
    <span class="md-ellipsis">
      logspace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ones" class="md-nav__link">
    <span class="md-ellipsis">
      ones()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor_1" class="md-nav__link">
    <span class="md-ellipsis">
      tensor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zeros" class="md-nav__link">
    <span class="md-ellipsis">
      zeros()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#张量操作" class="md-nav__link">
    <span class="md-ellipsis">
      张量操作
    </span>
  </a>
  
    <nav class="md-nav" aria-label="张量操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cat" class="md-nav__link">
    <span class="md-ellipsis">
      cat()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chunk" class="md-nav__link">
    <span class="md-ellipsis">
      chunk()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flatten" class="md-nav__link">
    <span class="md-ellipsis">
      flatten()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flip" class="md-nav__link">
    <span class="md-ellipsis">
      flip()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fliplr-flipud" class="md-nav__link">
    <span class="md-ellipsis">
      fliplr(), flipud()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#index_select" class="md-nav__link">
    <span class="md-ellipsis">
      index_select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked_select" class="md-nav__link">
    <span class="md-ellipsis">
      masked_select()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#movedim" class="md-nav__link">
    <span class="md-ellipsis">
      movedim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#narrow" class="md-nav__link">
    <span class="md-ellipsis">
      narrow()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nonezero" class="md-nav__link">
    <span class="md-ellipsis">
      nonezero()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#permute" class="md-nav__link">
    <span class="md-ellipsis">
      permute()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#repeat_interleave" class="md-nav__link">
    <span class="md-ellipsis">
      repeat_interleave()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshape" class="md-nav__link">
    <span class="md-ellipsis">
      reshape()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roll" class="md-nav__link">
    <span class="md-ellipsis">
      roll()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rot90" class="md-nav__link">
    <span class="md-ellipsis">
      rot90()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scatter_1" class="md-nav__link">
    <span class="md-ellipsis">
      scatter()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#split" class="md-nav__link">
    <span class="md-ellipsis">
      split()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#squeeze" class="md-nav__link">
    <span class="md-ellipsis">
      squeeze()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack" class="md-nav__link">
    <span class="md-ellipsis">
      stack()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swapaxes" class="md-nav__link">
    <span class="md-ellipsis">
      swapaxes()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swapdims" class="md-nav__link">
    <span class="md-ellipsis">
      swapdims()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t_1" class="md-nav__link">
    <span class="md-ellipsis">
      t()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#take" class="md-nav__link">
    <span class="md-ellipsis">
      take()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#take_along_dim" class="md-nav__link">
    <span class="md-ellipsis">
      take_along_dim()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tile" class="md-nav__link">
    <span class="md-ellipsis">
      tile()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transpose" class="md-nav__link">
    <span class="md-ellipsis">
      transpose()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unbind" class="md-nav__link">
    <span class="md-ellipsis">
      unbind()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsqueeze" class="md-nav__link">
    <span class="md-ellipsis">
      unsqueeze()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vstack-hstack" class="md-nav__link">
    <span class="md-ellipsis">
      vstack(), hstack()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#数学运算" class="md-nav__link">
    <span class="md-ellipsis">
      数学运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数学运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#abs" class="md-nav__link">
    <span class="md-ellipsis">
      abs()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add-sub" class="md-nav__link">
    <span class="md-ellipsis">
      add(), sub()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#all-any" class="md-nav__link">
    <span class="md-ellipsis">
      all(), any()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#allclose" class="md-nav__link">
    <span class="md-ellipsis">
      allclose()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amax-amin" class="md-nav__link">
    <span class="md-ellipsis">
      amax(), amin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#angle" class="md-nav__link">
    <span class="md-ellipsis">
      angle()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argmax-argmin" class="md-nav__link">
    <span class="md-ellipsis">
      argmax(), argmin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#argsort" class="md-nav__link">
    <span class="md-ellipsis">
      argsort()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bincount" class="md-nav__link">
    <span class="md-ellipsis">
      bincount()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bmm" class="md-nav__link">
    <span class="md-ellipsis">
      bmm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ceil-floor" class="md-nav__link">
    <span class="md-ellipsis">
      ceil(), floor()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clamp" class="md-nav__link">
    <span class="md-ellipsis">
      clamp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conj" class="md-nav__link">
    <span class="md-ellipsis">
      conj()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#count_nonzero" class="md-nav__link">
    <span class="md-ellipsis">
      count_nonzero()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross" class="md-nav__link">
    <span class="md-ellipsis">
      cross()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cummax-cummin" class="md-nav__link">
    <span class="md-ellipsis">
      cummax(), cummin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cumsum-cumprod" class="md-nav__link">
    <span class="md-ellipsis">
      cumsum(), cumprod()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deg2rad-rad2deg" class="md-nav__link">
    <span class="md-ellipsis">
      deg2rad(), rad2deg()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#det" class="md-nav__link">
    <span class="md-ellipsis">
      det()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diag" class="md-nav__link">
    <span class="md-ellipsis">
      diag()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diagonal" class="md-nav__link">
    <span class="md-ellipsis">
      diagonal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diff" class="md-nav__link">
    <span class="md-ellipsis">
      diff()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dist" class="md-nav__link">
    <span class="md-ellipsis">
      dist()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dot" class="md-nav__link">
    <span class="md-ellipsis">
      dot()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#equal" class="md-nav__link">
    <span class="md-ellipsis">
      equal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exp" class="md-nav__link">
    <span class="md-ellipsis">
      exp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fmax-fmin" class="md-nav__link">
    <span class="md-ellipsis">
      fmax(), fmin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frac" class="md-nav__link">
    <span class="md-ellipsis">
      frac()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcd-lcm" class="md-nav__link">
    <span class="md-ellipsis">
      gcd(), lcm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gt-ge-eq-le-lt-ne" class="md-nav__link">
    <span class="md-ellipsis">
      gt(), ge(), eq(), le(), lt(), ne()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hypot" class="md-nav__link">
    <span class="md-ellipsis">
      hypot()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inner" class="md-nav__link">
    <span class="md-ellipsis">
      inner()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lerp" class="md-nav__link">
    <span class="md-ellipsis">
      lerp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log-log10-log2" class="md-nav__link">
    <span class="md-ellipsis">
      log(), log10(), log2()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logaddexp-logaddexp2" class="md-nav__link">
    <span class="md-ellipsis">
      logaddexp(), logaddexp2()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logit" class="md-nav__link">
    <span class="md-ellipsis">
      logit()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logsumexp" class="md-nav__link">
    <span class="md-ellipsis">
      logsumexp()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lu" class="md-nav__link">
    <span class="md-ellipsis">
      lu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matmul" class="md-nav__link">
    <span class="md-ellipsis">
      matmul()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max-min-mean-std-median" class="md-nav__link">
    <span class="md-ellipsis">
      max(), min(), mean(), std(), median()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mm" class="md-nav__link">
    <span class="md-ellipsis">
      mm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mul-div-fmod-pow" class="md-nav__link">
    <span class="md-ellipsis">
      mul(), div(), fmod(), pow()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neg" class="md-nav__link">
    <span class="md-ellipsis">
      neg()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outer" class="md-nav__link">
    <span class="md-ellipsis">
      outer()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantile" class="md-nav__link">
    <span class="md-ellipsis">
      quantile()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#real-imag" class="md-nav__link">
    <span class="md-ellipsis">
      real(), imag()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reciprocal" class="md-nav__link">
    <span class="md-ellipsis">
      reciprocal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#round" class="md-nav__link">
    <span class="md-ellipsis">
      round()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      sigmoid()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sign" class="md-nav__link">
    <span class="md-ellipsis">
      sign()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sin-cos-tan-arcsin-arccos-arctan-sinh-cosh-tanh-arcsinh-arccosh-arctanh" class="md-nav__link">
    <span class="md-ellipsis">
      sin(), cos(), tan(), arcsin(), arccos(), arctan(), sinh(), cosh(), tanh(), arcsinh(), arccosh(), arctanh()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sort" class="md-nav__link">
    <span class="md-ellipsis">
      sort()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sqrt" class="md-nav__link">
    <span class="md-ellipsis">
      sqrt()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#square" class="md-nav__link">
    <span class="md-ellipsis">
      square()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sum-prod" class="md-nav__link">
    <span class="md-ellipsis">
      sum(), prod()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      tanh()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topk" class="md-nav__link">
    <span class="md-ellipsis">
      topk()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trace" class="md-nav__link">
    <span class="md-ellipsis">
      trace()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tril" class="md-nav__link">
    <span class="md-ellipsis">
      tril()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#triu" class="md-nav__link">
    <span class="md-ellipsis">
      triu()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trunc" class="md-nav__link">
    <span class="md-ellipsis">
      trunc()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vdot" class="md-nav__link">
    <span class="md-ellipsis">
      vdot()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#逻辑运算" class="md-nav__link">
    <span class="md-ellipsis">
      逻辑运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="逻辑运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bitwise_and-bitwise_or-bitwise_xor-bitwise_not" class="md-nav__link">
    <span class="md-ellipsis">
      bitwise_and(), bitwise_or(), bitwise_xor(), bitwise_not()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isin" class="md-nav__link">
    <span class="md-ellipsis">
      isin()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logical_and-logical_or-logical_xor-logical_not" class="md-nav__link">
    <span class="md-ellipsis">
      logical_and(), logical_or(), logical_xor(), logical_not()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#其他运算" class="md-nav__link">
    <span class="md-ellipsis">
      其他运算
    </span>
  </a>
  
    <nav class="md-nav" aria-label="其他运算">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numel" class="md-nav__link">
    <span class="md-ellipsis">
      numel()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unique" class="md-nav__link">
    <span class="md-ellipsis">
      unique()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#随机数和随机抽样" class="md-nav__link">
    <span class="md-ellipsis">
      随机数和随机抽样
    </span>
  </a>
  
    <nav class="md-nav" aria-label="随机数和随机抽样">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bernoulli" class="md-nav__link">
    <span class="md-ellipsis">
      bernoulli()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_rng_state" class="md-nav__link">
    <span class="md-ellipsis">
      get_rng_state()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#initial_seed" class="md-nav__link">
    <span class="md-ellipsis">
      initial_seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual_seed" class="md-nav__link">
    <span class="md-ellipsis">
      manual_seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multinomial" class="md-nav__link">
    <span class="md-ellipsis">
      multinomial()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normal" class="md-nav__link">
    <span class="md-ellipsis">
      normal()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson" class="md-nav__link">
    <span class="md-ellipsis">
      poisson()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rand" class="md-nav__link">
    <span class="md-ellipsis">
      rand()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randint" class="md-nav__link">
    <span class="md-ellipsis">
      randint()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randn" class="md-nav__link">
    <span class="md-ellipsis">
      randn()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randperm" class="md-nav__link">
    <span class="md-ellipsis">
      randperm()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seed" class="md-nav__link">
    <span class="md-ellipsis">
      seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#set_rng_state" class="md-nav__link">
    <span class="md-ellipsis">
      set_rng_state()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#禁用梯度计算" class="md-nav__link">
    <span class="md-ellipsis">
      禁用梯度计算
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#序列化" class="md-nav__link">
    <span class="md-ellipsis">
      序列化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="序列化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#save" class="md-nav__link">
    <span class="md-ellipsis">
      save()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load" class="md-nav__link">
    <span class="md-ellipsis">
      load()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#保存和加载张量" class="md-nav__link">
    <span class="md-ellipsis">
      保存和加载张量
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#保存和加载-torchnnmodules" class="md-nav__link">
    <span class="md-ellipsis">
      保存和加载 torch.nn.Modules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="torch">torch<a class="headerlink" href="#torch" title="Permanent link">&para;</a></h1>
<p>[toc]</p>
<h2 id="张量">张量<a class="headerlink" href="#张量" title="Permanent link">&para;</a></h2>
<h3 id="device">device<a class="headerlink" href="#device" title="Permanent link">&para;</a></h3>
<p><code>torch.device</code> 实例代表张量被分配到的设备，其包含了设备类型（<code>'cpu'</code> 或 <code>'cuda'</code>）和可选的该类型的设备序号。如果设备序号没有指定，则默认为该类型的当前设备（由 <code>torch.cuda.current_device()</code> 给出）。</p>
<p>张量的设备可以通过 <code>device</code> 属性得到。</p>
<p><code>torch.device</code> 实例可以通过字符串或者字符串加上设备序号来构造：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="c1"># 0号CPU设备.多核CPU通常被视为一个设备,因此CPU通常只有0号设备</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>    <span class="c1"># 0号CUDA设备</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>      <span class="c1"># 当前CUDA设备</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 0号CUDA设备</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 0号CUDA设备</span>
</code></pre></div>
<h3 id="dtype">dtype<a class="headerlink" href="#dtype" title="Permanent link">&para;</a></h3>
<p><code>torch.dtype</code> 实例代表张量的数据类型。PyTorch 有如下数据类型：</p>
<table>
<thead>
<tr>
<th>Data type</th>
<th>dtype</th>
<th>Legacy Constructors</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td><code>torch.float32</code> or <code>torch.float</code></td>
<td><code>torch.*.FloatTensor</code></td>
</tr>
<tr>
<td>64-bit floating point</td>
<td><code>torch.float64</code> or <code>torch.double</code></td>
<td><code>torch.*.DoubleTensor</code></td>
</tr>
<tr>
<td>64-bit complex</td>
<td><code>torch.complex64</code> or <code>torch.cfloat</code></td>
<td></td>
</tr>
<tr>
<td>128-bit complex</td>
<td><code>torch.complex128</code> or <code>torch.cdouble</code></td>
<td></td>
</tr>
<tr>
<td>16-bit floating point [1]</td>
<td><code>torch.float16</code> or <code>torch.half</code></td>
<td><code>torch.*.HalfTensor</code></td>
</tr>
<tr>
<td>16-bit floating point [2]</td>
<td><code>torch.bfloat16</code></td>
<td><code>torch.*.BFloat16Tensor</code></td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td><code>torch.uint8</code></td>
<td><code>torch.*.ByteTensor</code></td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td><code>torch.int8</code></td>
<td><code>torch.*.CharTensor</code></td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td><code>torch.int16</code> or <code>torch.short</code></td>
<td><code>torch.*.ShortTensor</code></td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td><code>torch.int32</code> or <code>torch.int</code></td>
<td><code>torch.*.IntTensor</code></td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td><code>torch.int64</code> or <code>torch.long</code></td>
<td><code>torch.*.LongTensor</code></td>
</tr>
<tr>
<td>Boolean</td>
<td><code>torch.bool</code></td>
<td><code>torch.*.BoolTensor</code></td>
</tr>
</tbody>
</table>
<p>[1]：有时被称为 binary16：使用一个符号位、5 个指数位和 10 个有效数字位，可以表示更大的精度。</p>
<p>[2]：有时被称为脑浮点（brain floating point）：使用一个符号位、8 个指数位和 7 个有效数字位，可以表示更大的范围。</p>
<p>当参与数学运算的张量的数据类型不同时，我们将数据类型转换为满足以下规则的最小数据类型：</p>
<ul>
<li>若标量操作数的数据类型比张量操作数的等级更高（复数 &gt; 浮点数 &gt; 整数 &gt; 布尔值），则转换为有足够大小能够容纳该类别操作数的类型。</li>
<li>若零维张量操作数的数据类型比多维张量操作数的等级更高，则转换为有足够大小能够容纳该类别操作数的类型。</li>
<li>若标量操作数/零维张量操作数/多维张量操作数的数据类型比其余标量操作数/零维张量操作数/多维张量操作数的等级更高或规模更大，则转换为有足够大小能够容纳该类别操作数的类型。</li>
</ul>
<p>下面给出一些示例：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 零维张量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">long_zerodim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">int_zerodim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="c1"># 多维张量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">float_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">double_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">complex_float_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">complex_double_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">int_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">long_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">uint_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">double_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bool_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

<span class="c1"># 整数标量操作数被推断为`torch.int64`类型,因此结果为`torch.int64`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int64</span>

<span class="c1"># 整数标量操作数被推断为`torch.int64`类型,不比张量操作数(`torch.int32`)的等级更高,</span>
<span class="c1"># 因此结果为张量操作数的`torch.int32`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">int_tensor</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int32</span>

<span class="c1"># 浮点数标量操作数被推断为`torch.float32`类型,比张量操作数(`torch.int32`)的等级更高,</span>
<span class="c1"># 因此结果为标量操作数的`torch.float32`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">int_tensor</span> <span class="o">+</span> <span class="mf">5.</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>

<span class="c1"># 浮点数标量操作数的数据类型(`torch.float32`)比整数标量操作数(`torch.int64`)的等级更高,</span>
<span class="c1"># 因此结果为浮点数张量操作数的`torch.float32`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>

<span class="c1"># 零维张量操作数(`torch.int64`)的数据类型不比多维张量操作数(`torch.int32`)的等级更高,</span>
<span class="c1"># 因此结果为多维张量操作数的`torch.int32`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">int_tensor</span> <span class="o">+</span> <span class="n">long_zerodim</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int32</span>

<span class="c1"># 浮点数张量操作数(`torch.float32`)的数据类型比整数张量操作数(`torch.int64`)的等级更高,</span>
<span class="c1"># 因此结果为浮点数张量操作数的`torch.float32`类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">long_tensor</span><span class="p">,</span> <span class="n">float_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>

<span class="c1"># 张量操作数(`torch.int64`)的数据类型比张量操作数(`torch.int32`)的规模更大,</span>
<span class="c1"># 因此结果为能够容纳两者的`torch.int64`类型.下同</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">long_tensor</span> <span class="o">+</span> <span class="n">int_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">float_tensor</span> <span class="o">+</span> <span class="n">double_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float64</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">complex_float_tensor</span> <span class="o">+</span> <span class="n">complex_double_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">complex128</span>

<span class="c1"># 布尔类型可以转换为各种整数类型</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">bool_tensor</span> <span class="o">+</span> <span class="n">long_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">bool_tensor</span> <span class="o">+</span> <span class="n">uint_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">uint8</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">bool_tensor</span> <span class="o">+</span> <span class="n">int_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">torch</span><span class="o">.</span><span class="n">int32</span>
</code></pre></div>
<h3 id="tensor">Tensor<a class="headerlink" href="#tensor" title="Permanent link">&para;</a></h3>
<p>PyTorch 张量。</p>
<h4 id="__getitem__-__setitem__-__delitem__">__getitem__(), __setitem__(), __delitem__()<a class="headerlink" href="#__getitem__-__setitem__-__delitem__" title="Permanent link">&para;</a></h4>
<p>对张量进行循秩访问或切片。切片是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>
<h4 id="apply_">apply_()<a class="headerlink" href="#apply_" title="Permanent link">&para;</a></h4>
<p>对张量的所有元素应用指定函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">apply_</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
</code></pre></div>
<blockquote>
<p>此方法仅适用于 CPU 张量，并且不应在有高性能要求的代码块中使用。</p>
</blockquote>
<h4 id="backward">backward()<a class="headerlink" href="#backward" title="Permanent link">&para;</a></h4>
<p>计算当前张量（作为根节点）对于计算图中叶节点的梯度。</p>
<div class="highlight"><pre><span></span><code><span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">gradient</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># gradient        最终的损失值对于当前张量的梯度,相当于当前张量与此参数作内积得到最终的损失值.若当前张量只包含一个元素,</span>
<span class="c1">#                 则此参数可以为`None`</span>
<span class="c1"># retain_graph    若为`False`,则计算图在反向计算结束后将被释放.注意在几乎所有情况下将此参数设为`True`都不是必需的,</span>
<span class="c1">#                 通常都会有更高效的替代方法.默认为`create_graph`的值</span>
<span class="c1"># create_graph    若为`True`,则会构建导数的计算图,用于计算更高阶的导数</span>
<span class="c1"># inputs          叶节点张量的序列,只有对于这些张量的梯度会被累积到`grad`属性中.若为`None`,则对于所有叶节点的梯度都会被累积</span>
</code></pre></div>
<h4 id="bool">bool()<a class="headerlink" href="#bool" title="Permanent link">&para;</a></h4>
<p>等价于 <code>self.to(torch.bool)</code>。</p>
<h4 id="contiguous">contiguous()<a class="headerlink" href="#contiguous" title="Permanent link">&para;</a></h4>
<p>返回张量的一个各元素在内存上相邻的副本。</p>
<p>如果张量的各元素已经在内存上相邻，则直接返回该张量对象。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="ow">is</span> <span class="n">a</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="kc">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>
<span class="kc">True</span>
</code></pre></div>
<h4 id="cpu">cpu()<a class="headerlink" href="#cpu" title="Permanent link">&para;</a></h4>
<p>返回张量的一个位于内存中的副本。</p>
<p>如果张量已经位于内存中，则直接返回该张量对象。</p>
<h4 id="cuda">cuda()<a class="headerlink" href="#cuda" title="Permanent link">&para;</a></h4>
<p>返回张量的一个位于显存中的副本。可以通过 <code>device</code> 参数指定 CUDA 设备，默认为当前 CUDA 设备。</p>
<p>如果张量已经位于指定 CUDA 设备的显存中，则直接返回该张量对象。</p>
<h4 id="data_ptr">data_ptr()<a class="headerlink" href="#data_ptr" title="Permanent link">&para;</a></h4>
<p>返回张量的第一个元素的内存地址。</p>
<h4 id="detach">detach()<a class="headerlink" href="#detach" title="Permanent link">&para;</a></h4>
<p>返回张量的一个视图，其等于原张量，但在计算图之外，不参与梯度计算。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">AddBackward0</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.</span><span class="p">)</span>       <span class="c1"># 在计算图之外,共享内存</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">3.</span><span class="p">)</span>       <span class="c1"># 在计算图之外,不共享内存</span>
<span class="o">&gt;&gt;&gt;</span> 
</code></pre></div>
<h4 id="device_1">device<a class="headerlink" href="#device_1" title="Permanent link">&para;</a></h4>
<p>返回张量所位于的设备。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<h4 id="dim">dim()<a class="headerlink" href="#dim" title="Permanent link">&para;</a></h4>
<p>返回张量的维数。</p>
<h4 id="expand">expand()<a class="headerlink" href="#expand" title="Permanent link">&para;</a></h4>
<p>将张量在指定维度上以复制的方式扩展，复制的多个部分实际上是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>    <span class="c1"># `-1`表示此维度保持不变</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>       <span class="c1"># 共享内存</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>                       <span class="c1"># 共享内存</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
</code></pre></div>
<h4 id="expand_as">expand_as()<a class="headerlink" href="#expand_as" title="Permanent link">&para;</a></h4>
<p>将张量以复制的方式扩展为指定张量的形状，复制的多个部分实际上是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
</code></pre></div>
<h4 id="fill_">fill_()<a class="headerlink" href="#fill_" title="Permanent link">&para;</a></h4>
<p>以指定值填充张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.3756</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0195</span><span class="p">,</span>  <span class="mf">1.2633</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2588</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
</code></pre></div>
<h4 id="get_device">get_device()<a class="headerlink" href="#get_device" title="Permanent link">&para;</a></h4>
<p>对于 CUDA 张量，返回其所位于的 GPU 设备的序号；对于 CPU 张量，抛出一个错误。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
<span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
<span class="c1"># RuntimeError: get_device is not implemented for type torch.FloatTensor</span>
</code></pre></div>
<h4 id="grad">grad<a class="headerlink" href="#grad" title="Permanent link">&para;</a></h4>
<p>调用 <code>loss.backward()</code> 后计算的损失对此张量的梯度值的累积。由于多次调用 <code>loss.backward()</code> 后梯度值会进行累加，因此需要在必要时调用 <code>optimizer.zero_grad()</code> 以清零。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 参数</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">])</span>  <span class="c1"># 样本1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>            <span class="c1"># 反向计算</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">])</span>  <span class="c1"># 样本2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">10.</span><span class="p">])</span>              <span class="c1"># 梯度值累加</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>  <span class="c1"># 创建更新参数的优化器</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.1000</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>              <span class="c1"># 参数被更新</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.0400</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># 清零所有参数的累积梯度值</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>                <span class="c1"># 归零</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
</code></pre></div>
<h4 id="grad_fn">grad_fn<a class="headerlink" href="#grad_fn" title="Permanent link">&para;</a></h4>
<p>返回得到此张量的运算相应的 <code>torch.autograd.Function</code> 对象。</p>
<h4 id="is_contiguous">is_contiguous()<a class="headerlink" href="#is_contiguous" title="Permanent link">&para;</a></h4>
<p>若张量的各元素在内存中相邻，则返回 <code>True</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>     <span class="c1"># 内存中是相邻的整数 0, 1, ..., 11</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>     <span class="c1"># 新视图改变了数据的解释方式,此时张量中的相邻元素在内存中仍然是相邻的</span>
<span class="kc">True</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>     <span class="c1"># 新视图改变了数据的解释方式,但此时张量中的相邻元素在内存中已不再相邻</span>
<span class="kc">False</span>
</code></pre></div>
<h4 id="is_cuda">is_cuda()<a class="headerlink" href="#is_cuda" title="Permanent link">&para;</a></h4>
<p>若张量保存在 GPU（显存）上，则返回 <code>True</code>。</p>
<h4 id="is_leaf">is_leaf()<a class="headerlink" href="#is_leaf" title="Permanent link">&para;</a></h4>
<p>若张量是计算图中的叶节点，则返回 <code>True</code>。</p>
<h4 id="item">item()<a class="headerlink" href="#item" title="Permanent link">&para;</a></h4>
<p>对于只有一个元素的张量，返回该元素的值。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="mi">1</span>
</code></pre></div>
<h4 id="new_full-new_ones-new_zeros">new_full(), new_ones(), new_zeros()<a class="headerlink" href="#new_full-new_ones-new_zeros" title="Permanent link">&para;</a></h4>
<p><code>new_full()</code> 返回一个指定形状和所有元素值的张量，并且该张量与调用对象有相同的 <code>torch.dtype</code> 和 <code>torch.device</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">new_full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mf">3.141592</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div>
<p><code>new_ones()</code>/<code>new_zeros()</code> 返回一个指定形状的全 1/全 0 张量，并且该张量与调用对象有相同的 <code>torch.dtype</code> 和 <code>torch.device</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">new_ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div>
<h4 id="normal_">normal_()<a class="headerlink" href="#normal_" title="Permanent link">&para;</a></h4>
<p>填充张量，其中每个元素服从给定平均值和标准差的正态分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.5150</span><span class="p">,</span>  <span class="mf">0.4457</span><span class="p">,</span>  <span class="mf">0.1200</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.8085</span><span class="p">,</span>  <span class="mf">0.6454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0869</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2552</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4674</span><span class="p">]])</span>
</code></pre></div>
<h4 id="numpy">numpy()<a class="headerlink" href="#numpy" title="Permanent link">&para;</a></h4>
<p>将张量作为 <code>numpy.ndarray</code> 实例返回。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.7129</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6347</span><span class="p">,</span>  <span class="mf">0.4912</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3418</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">0.7128906</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.6347297</span> <span class="p">,</span>  <span class="mf">0.49121562</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3418238</span> <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div>
<h4 id="random_">random_()<a class="headerlink" href="#random_" title="Permanent link">&para;</a></h4>
<p>填充张量，其中每个元素服从给定区间内的离散均匀分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span>
</code></pre></div>
<h4 id="repeat">repeat()<a class="headerlink" href="#repeat" title="Permanent link">&para;</a></h4>
<p>将张量在某些维度上重复。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>     <span class="c1"># 沿轴0重复2次</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]])</span>
</code></pre></div>
<h4 id="requires_grad">requires_grad<a class="headerlink" href="#requires_grad" title="Permanent link">&para;</a></h4>
<p>若需要计算对此张量的梯度，返回 <code>True</code>。</p>
<h4 id="requires_grad_">requires_grad_()<a class="headerlink" href="#requires_grad_" title="Permanent link">&para;</a></h4>
<p>设置是否需要计算对此张量的梯度。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1482</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2680</span><span class="p">,</span>  <span class="mf">1.4278</span><span class="p">,</span>  <span class="mf">1.7212</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>          <span class="c1"># 相当于 w.requires_grad = True</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1482</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2680</span><span class="p">,</span>  <span class="mf">1.4278</span><span class="p">,</span>  <span class="mf">1.7212</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>     <span class="c1"># 相当于 w.requires_grad = False</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1482</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2680</span><span class="p">,</span>  <span class="mf">1.4278</span><span class="p">,</span>  <span class="mf">1.7212</span><span class="p">])</span>
</code></pre></div>
<h4 id="retain_grad">retain_grad()<a class="headerlink" href="#retain_grad" title="Permanent link">&para;</a></h4>
<p>对于计算图中需要计算梯度但不是叶节点的张量，启用 <code>grad</code> 属性。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">w</span> <span class="o">@</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">])</span>    <span class="c1"># 保留了对此张量的梯度值</span>
</code></pre></div>
<h4 id="scatter">scatter()<a class="headerlink" href="#scatter" title="Permanent link">&para;</a></h4>
<p><code>scatter_()</code> 的非原位版本。</p>
<h4 id="scatter_">scatter_()<a class="headerlink" href="#scatter_" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">Tensor</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>
<p>将张量 <code>src</code> 的所有值写入到张量 <code>self</code> 中由 <code>dim</code> 和张量 <code>index</code> 指定的索引位置。</p>
<p>例如，对于二维张量，<code>self</code> 被更新为：</p>
<div class="highlight"><pre><span></span><code><span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
</code></pre></div>
<p>对于三维张量，<code>self</code> 被更新为：</p>
<div class="highlight"><pre><span></span><code><span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
<span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 2</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">src</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indices</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">labels</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
</code></pre></div>
<h4 id="select">select()<a class="headerlink" href="#select" title="Permanent link">&para;</a></h4>
<p>对张量沿指定维度的指定索引进行切片，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>        <span class="c1"># 等价于 a[1,:,:]</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>        <span class="c1"># 等价于 a[:,:,1]</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">21</span><span class="p">]])</span>
</code></pre></div>
<h4 id="shape">shape()<a class="headerlink" href="#shape" title="Permanent link">&para;</a></h4>
<p>返回张量的形状。</p>
<h4 id="size">size()<a class="headerlink" href="#size" title="Permanent link">&para;</a></h4>
<p>返回张量的形状。</p>
<h4 id="t">T<a class="headerlink" href="#t" title="Permanent link">&para;</a></h4>
<p>反转张量的所有维度，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</code></pre></div>
<h4 id="to">to()<a class="headerlink" href="#to" title="Permanent link">&para;</a></h4>
<p>更改张量的 <code>dtype</code> 或 <code>device</code> 属性。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Initially dtype=float32, device=cpu</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">cuda0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cuda0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cuda0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</code></pre></div>
<h4 id="tolist">tolist()<a class="headerlink" href="#tolist" title="Permanent link">&para;</a></h4>
<p>将张量作为（嵌套的）Python 列表返回。位于 GPU 的张量会自动地先被移动到 CPU。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="p">[[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]]</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="mi">1</span>
</code></pre></div>
<h4 id="type">type()<a class="headerlink" href="#type" title="Permanent link">&para;</a></h4>
<p>以字符串的形式返回张量的数据类型，或将张量转换为特定数据类型。</p>
<p>如果目标数据类型就是当前数据类型，则直接返回当前张量实例，否则创建新的张量实例并返回。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">type</span><span class="p">()</span>
<span class="s1">&#39;torch.LongTensor&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
</code></pre></div>
<h4 id="unfold">unfold()<a class="headerlink" href="#unfold" title="Permanent link">&para;</a></h4>
<p>返回张量的一个视图，其包含张量沿指定维度的所有指定大小的切片。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">dimension</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]])</span>
</code></pre></div>
<h4 id="uniform_">uniform_()<a class="headerlink" href="#uniform_" title="Permanent link">&para;</a></h4>
<p>填充张量，其中每个元素服从给定上下限的均匀分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.2333</span><span class="p">,</span> <span class="mf">0.9299</span><span class="p">,</span> <span class="mf">0.6257</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.3921</span><span class="p">,</span> <span class="mf">0.8509</span><span class="p">,</span> <span class="mf">0.9099</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.0791</span><span class="p">,</span> <span class="mf">0.0876</span><span class="p">,</span> <span class="mf">0.1711</span><span class="p">]])</span>
</code></pre></div>
<h4 id="view">view()<a class="headerlink" href="#view" title="Permanent link">&para;</a></h4>
<p>返回张量的一个视图，其与原张量数据相同，但形状不同。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>       <span class="c1"># 共享内存</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">()</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">()</span>
<span class="kc">True</span>                            <span class="c1"># 共享内存</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>           <span class="c1"># -1表示该维度的规模将根据元素总数和其他维度的规模</span>
                                <span class="c1"># 推算得到</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
</code></pre></div>
<h4 id="view_as">view_as()<a class="headerlink" href="#view_as" title="Permanent link">&para;</a></h4>
<p>返回张量的一个视图，其与原张量数据相同，但变为指定张量的形状。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
</code></pre></div>
<h4 id="zero_">zero_()<a class="headerlink" href="#zero_" title="Permanent link">&para;</a></h4>
<p>用 0 填充张量。</p>
<h2 id="张量类型操作">张量类型操作<a class="headerlink" href="#张量类型操作" title="Permanent link">&para;</a></h2>
<h3 id="get_default_dtype">get_default_dtype()<a class="headerlink" href="#get_default_dtype" title="Permanent link">&para;</a></h3>
<p>返回默认的浮点类型。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float64</span>
</code></pre></div>
<h3 id="is_complex">is_complex()<a class="headerlink" href="#is_complex" title="Permanent link">&para;</a></h3>
<p>若输入张量的数据类型是复类型，即 <code>torch.complex64</code>、<code>torch.complex128</code> 两者之一，则返回 <code>True</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="o">+</span><span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_complex</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="isfinite">isfinite()<a class="headerlink" href="#isfinite" title="Permanent link">&para;</a></h3>
<p>返回一个布尔张量，其每个元素表示输入张量的对应元素是否是有限的。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)]))</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span>  <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">False</span><span class="p">,</span>  <span class="kc">False</span><span class="p">])</span>
</code></pre></div>
<h3 id="is_floating_point">is_floating_point()<a class="headerlink" href="#is_floating_point" title="Permanent link">&para;</a></h3>
<p>若输入张量的数据类型是浮点类型，即 <code>torch.float64</code>、<code>torch.float32</code>、<code>torch.float16</code> 和 <code>torch.bfloat16</code> 其中之一，则返回 <code>True</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="isinf">isinf()<a class="headerlink" href="#isinf" title="Permanent link">&para;</a></h3>
<p>返回一个布尔张量，其每个元素表示输入张量的对应元素是否是无限的。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)]))</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">False</span><span class="p">])</span>
</code></pre></div>
<h3 id="isnan">isnan()<a class="headerlink" href="#isnan" title="Permanent link">&para;</a></h3>
<p>返回一个布尔张量，其每个元素表示输入张量的对应元素是否是 NaN。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">),</span> <span class="mi">2</span><span class="p">]))</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
</code></pre></div>
<h3 id="is_tensor">is_tensor()<a class="headerlink" href="#is_tensor" title="Permanent link">&para;</a></h3>
<p>若实例是 PyTorch 张量，则返回 <code>True</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="set_default_dtype">set_default_dtype()<a class="headerlink" href="#set_default_dtype" title="Permanent link">&para;</a></h3>
<p>设置默认的浮点类型。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">dtype</span>    <span class="c1"># Python浮点数推断为`torch.float32`类型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">3</span><span class="n">j</span><span class="p">])</span><span class="o">.</span><span class="n">dtype</span>   <span class="c1"># Python复数推断为`torch.complex64`类型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">complex64</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">dtype</span>    <span class="c1"># Python浮点数推断为`torch.float64`类型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">float64</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mi">3</span><span class="n">j</span><span class="p">])</span><span class="o">.</span><span class="n">dtype</span>   <span class="c1"># Python复数推断为`torch.complex128`类型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">complex128</span>
</code></pre></div>
<h2 id="张量创建">张量创建<a class="headerlink" href="#张量创建" title="Permanent link">&para;</a></h2>
<h3 id="arange">arange()<a class="headerlink" href="#arange" title="Permanent link">&para;</a></h3>
<p>根据给定的初值，末值和步长创建一维张量。与 Python 的 <code>range()</code> 用法相同。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.5000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">])</span>
</code></pre></div>
<h3 id="as_tensor">as_tensor()<a class="headerlink" href="#as_tensor" title="Permanent link">&para;</a></h3>
<p>将数据转换为张量。如果数据是张量，并且转换前后的数据类型和设备相同，则直接返回该张量；如果数据本身是 <code>numpy.ndarray</code> 实例，并且转换前后的数据类型和设备相同，则返回的张量是该实例的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<h3 id="clone">clone()<a class="headerlink" href="#clone" title="Permanent link">&para;</a></h3>
<p>返回张量的一个副本。亦为 <code>Tensor</code> 方法。</p>
<div class="admonition note 注意">
<p class="admonition-title">Note</p>
<p>此函数返回的张量副本继承了原张量的 <code>requires_grad</code> 和 <code>grad_fn</code> 属性。若要创建一个与原张量没有 autograd 关系的张量副本，请使用 <code>Tensor.detach()</code> 方法。</p>
</div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">grad_fn</span>
<span class="o">&lt;</span><span class="n">AddBackward0</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x10a928310</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="o">.</span><span class="n">grad_fn</span>
<span class="o">&lt;</span><span class="n">CloneBackward0</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x10a928310</span><span class="o">&gt;</span>
</code></pre></div>
<h3 id="eye">eye()<a class="headerlink" href="#eye" title="Permanent link">&para;</a></h3>
<p>返回指定行列数的方阵（二维张量），其中对角元素为 1、其余元素为 0。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
</code></pre></div>
<h3 id="from_numpy">from_numpy()<a class="headerlink" href="#from_numpy" title="Permanent link">&para;</a></h3>
<p>由 NumPy 数组（<code>numpy.ndarray</code> 实例）创建张量。返回张量与 NumPy 数组共享内存。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>         <span class="c1"># 返回张量与NumPy数组共享内存</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<h3 id="full">full()<a class="headerlink" href="#full" title="Permanent link">&para;</a></h3>
<p>返回指定形状的用指定值填充的张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mf">3.141592</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">]])</span>
</code></pre></div>
<h3 id="linspace">linspace()<a class="headerlink" href="#linspace" title="Permanent link">&para;</a></h3>
<p>根据给定的初值、末值和项数创建一维张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">2.5000</span><span class="p">,</span>  <span class="mf">5.0000</span><span class="p">,</span>  <span class="mf">7.5000</span><span class="p">,</span> <span class="mf">10.0000</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
</code></pre></div>
<h3 id="logspace">logspace()<a class="headerlink" href="#logspace" title="Permanent link">&para;</a></h3>
<p>根据给定的底数和指数的初值、末值和项数创建一维张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>           <span class="c1"># 默认底数为10</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.0000e+00</span><span class="p">,</span> <span class="mf">3.1623e+02</span><span class="p">,</span> <span class="mf">1.0000e+05</span><span class="p">,</span> <span class="mf">3.1623e+07</span><span class="p">,</span> <span class="mf">1.0000e+10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.0000e+00</span><span class="p">,</span> <span class="mf">5.6569e+00</span><span class="p">,</span> <span class="mf">3.2000e+01</span><span class="p">,</span> <span class="mf">1.8102e+02</span><span class="p">,</span> <span class="mf">1.0240e+03</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">])</span>
</code></pre></div>
<h3 id="ones">ones()<a class="headerlink" href="#ones" title="Permanent link">&para;</a></h3>
<p>返回指定形状的全 1 张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</code></pre></div>
<h3 id="tensor_1">tensor()<a class="headerlink" href="#tensor_1" title="Permanent link">&para;</a></h3>
<p>由数据创建张量。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
<span class="c1"># data           张量的初始数据,可以是数字、列表、元组、`numpy.ndarray`实例等</span>
<span class="c1"># dtype          张量的数据类型,默认从`data`中推断(推断的结果一定是CPU数据类型)</span>
<span class="c1"># device         张量位于的设备,默认使用数据类型相应的设备:若为CPU数据类型,则使用CPU;若为CUDA数据类型,</span>
<span class="c1">#                则使用当前的CUDA设备</span>
<span class="c1"># requires_grad  若为`True`,则autograd应记录此张量参与的运算</span>
<span class="c1"># pin_memory     若为`True`,则张量将被分配到锁页内存中.仅对位于CPU的张量有效</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.9</span><span class="p">,</span> <span class="mf">5.2</span><span class="p">]])</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1000</span><span class="p">,</span>  <span class="mf">1.2000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.2000</span><span class="p">,</span>  <span class="mf">3.1000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.9000</span><span class="p">,</span>  <span class="mf">5.2000</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>   <span class="c1"># 从数据推断类型</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.11111</span><span class="p">,</span> <span class="mf">0.222222</span><span class="p">,</span> <span class="mf">0.3333333</span><span class="p">]],</span>
<span class="o">...</span>              <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
<span class="o">...</span>              <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">))</span>   <span class="c1"># 创建一个`torch.cuda.DoubleTensor`</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1111</span><span class="p">,</span>  <span class="mf">0.2222</span><span class="p">,</span>  <span class="mf">0.3333</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.14159</span><span class="p">)</span>  <span class="c1"># 创建一个标量(0维张量)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">3.1416</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span>       <span class="c1"># 创建一个空张量(形状为(0,))</span>
<span class="n">tensor</span><span class="p">([])</span>
</code></pre></div>
<h3 id="zeros">zeros()<a class="headerlink" href="#zeros" title="Permanent link">&para;</a></h3>
<p>返回指定形状的全 0 张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<h2 id="张量操作">张量操作<a class="headerlink" href="#张量操作" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">提示</p>
<p>下列张量操作函数中的大部分都是 <code>torch.Tensor</code> 方法，即张量可以调用下列函数的同名方法，相当于将张量自身作为函数的第一个张量参数。</p>
</div>
<h3 id="cat">cat()<a class="headerlink" href="#cat" title="Permanent link">&para;</a></h3>
<p>沿指定轴拼接张量。不是 <code>torch.Tensor</code> 方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</code></pre></div>
<h3 id="chunk">chunk()<a class="headerlink" href="#chunk" title="Permanent link">&para;</a></h3>
<p>将张量沿第一个维度划分为若干个块，其中每个块都是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]),</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]),</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>       <span class="c1"># 轴0的规模为3,无法划分为更多个块</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]),</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]]))</span>
</code></pre></div>
<h3 id="flatten">flatten()<a class="headerlink" href="#flatten" title="Permanent link">&para;</a></h3>
<p>将张量展开为向量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                       <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
                      <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
                       <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># 从轴1开始展开,即保留轴0</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</code></pre></div>
<h3 id="flip">flip()<a class="headerlink" href="#flip" title="Permanent link">&para;</a></h3>
<p>沿指定维度翻转张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>         <span class="c1"># 沿轴0翻转</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>         <span class="c1"># 沿轴1翻转</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span>  <span class="mi">8</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flip</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>    <span class="c1"># 沿轴0和轴1翻转</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<h3 id="fliplr-flipud">fliplr(), flipud()<a class="headerlink" href="#fliplr-flipud" title="Permanent link">&para;</a></h3>
<p>左右/上下翻转张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">fliplr</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span>  <span class="mi">8</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">flipud</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
</code></pre></div>
<h3 id="index_select">index_select()<a class="headerlink" href="#index_select" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定维度的指定索引组成的子张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
</code></pre></div>
<h3 id="masked_select">masked_select()<a class="headerlink" href="#masked_select" title="Permanent link">&para;</a></h3>
<p>根据布尔张量（掩码）返回由张量的部分元素组成的一维张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.3552</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3825</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8297</span><span class="p">,</span>  <span class="mf">0.3477</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2035</span><span class="p">,</span>  <span class="mf">1.2252</span><span class="p">,</span>  <span class="mf">0.5002</span><span class="p">,</span>  <span class="mf">0.6248</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1307</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0608</span><span class="p">,</span>  <span class="mf">0.1244</span><span class="p">,</span>  <span class="mf">2.0139</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>                           <span class="c1"># 比较运算产生与张量形状相同的掩码</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mask</span>
<span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.2252</span><span class="p">,</span>  <span class="mf">0.5002</span><span class="p">,</span>  <span class="mf">0.6248</span><span class="p">,</span>  <span class="mf">2.0139</span><span class="p">])</span>   <span class="c1"># `True`对应的元素组成的一维张量</span>
</code></pre></div>
<h3 id="movedim">movedim()<a class="headerlink" href="#movedim" title="Permanent link">&para;</a></h3>
<p>移动张量指定轴的位置，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">movedim</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<h3 id="narrow">narrow()<a class="headerlink" href="#narrow" title="Permanent link">&para;</a></h3>
<p>截取张量沿指定维度的部分索引区间，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
</code></pre></div>
<h3 id="nonezero">nonezero()<a class="headerlink" href="#nonezero" title="Permanent link">&para;</a></h3>
<p>返回张量的所有非零元素的索引坐标。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</code></pre></div>
<h3 id="permute">permute()<a class="headerlink" href="#permute" title="Permanent link">&para;</a></h3>
<p>重新排序张量的各个维度，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
         <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">21</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">22</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="repeat_interleave">repeat_interleave()<a class="headerlink" href="#repeat_interleave" title="Permanent link">&para;</a></h3>
<p>（原位）重复张量的元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>         <span class="c1"># 展开并重复</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 沿轴0重复</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 沿轴1重复</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>                    <span class="c1"># 分别重复1/2次</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</code></pre></div>
<h3 id="reshape">reshape()<a class="headerlink" href="#reshape" title="Permanent link">&para;</a></h3>
<p>改变张量的形状。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>      <span class="c1"># 保持各元素的顺序</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
</code></pre></div>
<h3 id="roll">roll()<a class="headerlink" href="#roll" title="Permanent link">&para;</a></h3>
<p>循环移动张量沿指定维度的元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>         <span class="c1"># 沿轴0移动1步</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>        <span class="c1"># 沿轴0反向移动1步</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>         <span class="c1"># 沿轴1移动1步</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">11</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">roll</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># 沿轴0移动1步并沿轴1移动2步</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">]])</span>
</code></pre></div>
<h3 id="rot90">rot90()<a class="headerlink" href="#rot90" title="Permanent link">&para;</a></h3>
<p>旋转多维张量 90° 若干次，在指定的两个轴所决定的平面内。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
<span class="c1"># input   要旋转的多维张量</span>
<span class="c1"># k       旋转90°的次数.若大于0,则从第一个轴旋转至第二个轴;若小于0,则从第二个轴旋转至第一个轴</span>
<span class="c1"># dims    指定的两个轴</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="scatter_1">scatter()<a class="headerlink" href="#scatter_1" title="Permanent link">&para;</a></h3>
<p><code>torch.Tensor.scatter_()</code> 的非原位版本。</p>
<h3 id="split">split()<a class="headerlink" href="#split" title="Permanent link">&para;</a></h3>
<p>将张量沿指定维度的索引划分为多个区间，其中每个子张量都是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">36</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>           <span class="c1"># 沿轴0每2个索引划分</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span><span class="p">,</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>               <span class="c1"># 沿轴1每3个索引划分</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span><span class="p">,</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>               <span class="c1"># 最后一个部分不足4个索引 </span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">29</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">34</span><span class="p">,</span> <span class="mi">35</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># 沿轴1划分</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a0</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">12</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">18</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">24</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">30</span><span class="p">]])</span>
</code></pre></div>
<h3 id="squeeze">squeeze()<a class="headerlink" href="#squeeze" title="Permanent link">&para;</a></h3>
<p>移除张量的规模为 1 的维度，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>           <span class="c1"># 移除所有规模为1的维度</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>        <span class="c1"># 移除指定规模为1的维度</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</code></pre></div>
<h3 id="stack">stack()<a class="headerlink" href="#stack" title="Permanent link">&para;</a></h3>
<p>沿新的指定维度拼接形状相同的张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</code></pre></div>
<h3 id="swapaxes">swapaxes()<a class="headerlink" href="#swapaxes" title="Permanent link">&para;</a></h3>
<p><code>torch.transpose()</code> 的别名。</p>
<h3 id="swapdims">swapdims()<a class="headerlink" href="#swapdims" title="Permanent link">&para;</a></h3>
<p><code>torch.transpose()</code> 的别名。</p>
<h3 id="t_1">t()<a class="headerlink" href="#t_1" title="Permanent link">&para;</a></h3>
<p>转置二维张量，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
</code></pre></div>
<h3 id="take">take()<a class="headerlink" href="#take" title="Permanent link">&para;</a></h3>
<p>返回张量展开后的指定索引的元素组成的一维张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">5</span><span class="p">])</span>
</code></pre></div>
<h3 id="take_along_dim">take_along_dim()<a class="headerlink" href="#take_along_dim" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定维度的指定索引的元素组成的张量，其中每个索引都需要单独指定，通常与 <code>torch.argmax()</code>、<code>torch.argmin()</code>、<code>torch.argsort()</code> 配合使用。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">take_along_dim</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
</code></pre></div>
<h3 id="tile">tile()<a class="headerlink" href="#tile" title="Permanent link">&para;</a></h3>
<p>重复张量的元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">2</span><span class="p">,))</span>       <span class="c1"># 沿轴0重复2次</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>     <span class="c1"># 沿轴0,轴1分别重复2次</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</code></pre></div>
<h3 id="transpose">transpose()<a class="headerlink" href="#transpose" title="Permanent link">&para;</a></h3>
<p>交换张量的指定两个维度，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
</code></pre></div>
<h3 id="unbind">unbind()<a class="headerlink" href="#unbind" title="Permanent link">&para;</a></h3>
<p>移除张量的一个指定维度，返回沿此维度的所有切片组成的元组。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">]))</span>
</code></pre></div>
<h3 id="unsqueeze">unsqueeze()<a class="headerlink" href="#unsqueeze" title="Permanent link">&para;</a></h3>
<p>在张量的指定位置插入一个规模为 1 的维度，返回原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<h3 id="vstack-hstack">vstack(), hstack()<a class="headerlink" href="#vstack-hstack" title="Permanent link">&para;</a></h3>
<p>纵向（沿轴 0）/横向（沿轴 1）堆叠张量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</code></pre></div>
<h2 id="数学运算">数学运算<a class="headerlink" href="#数学运算" title="Permanent link">&para;</a></h2>
<div class="admonition info 信息">
<p class="admonition-title">Info</p>
<p>下列所有数学运算函数都是 <code>torch.Tensor</code> 方法，即张量可以调用下列函数的同名方法，相当于将张量自身作为函数的第一个张量参数。张量的这些方法同时有非原位操作和原位操作两个版本，后者的方法名增加了后缀 <code>_</code>，例如：
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>      <span class="c1"># 返回新张量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>   <span class="c1"># 原张量不变</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">abs_</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>      <span class="c1"># 返回原张量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>      <span class="c1"># 原张量被修改</span>
</code></pre></div></p>
</div>
<h3 id="abs">abs()<a class="headerlink" href="#abs" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用绝对值函数，或对复张量的所有元素计算模。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.2736</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2038</span><span class="p">,</span>  <span class="mf">0.9149</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2633</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.2736</span><span class="p">,</span> <span class="mf">1.2038</span><span class="p">,</span> <span class="mf">0.9149</span><span class="p">,</span> <span class="mf">0.2633</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">3</span><span class="n">j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.4142</span><span class="p">,</span> <span class="mf">2.8284</span><span class="p">,</span> <span class="mf">4.2426</span><span class="p">])</span>
</code></pre></div>
<h3 id="add-sub">add(), sub()<a class="headerlink" href="#add-sub" title="Permanent link">&para;</a></h3>
<p>张量逐元素加法/减法。符号 <code>+, -</code> 重载了这些方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span>                    <span class="c1"># 张量+标量: 扩张的张量加法</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>    <span class="c1"># 同前</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>      <span class="c1"># 张量+子张量: 扩张的张量加法</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">14</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">a</span>                    <span class="c1"># 张量+张量: 张量加法</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">22</span><span class="p">]])</span>
</code></pre></div>
<h3 id="all-any">all(), any()<a class="headerlink" href="#all-any" title="Permanent link">&para;</a></h3>
<p>若张量（沿指定维度）的所有/任意元素检测为 <code>True</code>，则返回的布尔张量的相应元素为 <code>True</code> 。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>           <span class="c1"># 所有元素为`True`</span>
<span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># 沿轴0的所有元素为`True`</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>          <span class="c1"># 沿轴1的所有元素为`True`</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>           <span class="c1"># 任意元素为`True`</span>
<span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># 沿轴0的任意元素为`True`</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>          <span class="c1"># 沿轴1的任意元素为`True`</span>
<span class="n">tensor</span><span class="p">([</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
</code></pre></div>
<h3 id="allclose">allclose()<a class="headerlink" href="#allclose" title="Permanent link">&para;</a></h3>
<p>若两个张量<a href="https://pytorch.org/docs/stable/generated/torch.allclose.html">在容许限度内</a>逐元素相等，则返回 <code>True</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">10000.</span><span class="p">,</span> <span class="mf">1e-07</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">10000.1</span><span class="p">,</span> <span class="mf">1e-08</span><span class="p">]))</span>
<span class="kc">False</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">10000.</span><span class="p">,</span> <span class="mf">1e-08</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">10000.1</span><span class="p">,</span> <span class="mf">1e-09</span><span class="p">]))</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="amax-amin">amax(), amin()<a class="headerlink" href="#amax-amin" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定维度的最大值/最小值。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.2656</span><span class="p">,</span>  <span class="mf">0.5158</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9120</span><span class="p">,</span>  <span class="mf">0.1984</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amax</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.5158</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amin</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">0.9120</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.3866</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6860</span><span class="p">,</span>  <span class="mf">1.6496</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7280</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2662</span><span class="p">,</span>  <span class="mf">1.0654</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1922</span><span class="p">,</span>  <span class="mf">0.4900</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.0274</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1158</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4285</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1089</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1412</span><span class="p">,</span>  <span class="mf">1.2908</span><span class="p">,</span>  <span class="mf">0.7853</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9393</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>             <span class="c1"># 沿轴1的最大值</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.6496</span><span class="p">,</span> <span class="mf">1.0654</span><span class="p">,</span> <span class="mf">1.0274</span><span class="p">,</span> <span class="mf">1.2908</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>        <span class="c1"># 沿轴0和轴1的最大值</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">1.6496</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.7280</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2662</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4285</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9393</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">2.4285</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<p><code>amax()</code>/<code>amin()</code> 和 <code>max()</code>/<code>min()</code> 的区别在于：</p>
<ul>
<li><code>amax()</code>/<code>amin()</code> 支持沿多个维度归约</li>
<li><code>amax()</code>/<code>amin()</code> 不返回索引</li>
<li><code>amax()</code>/<code>amin()</code> 将梯度均摊到多个最大值上，而 <code>max()</code>/<code>min()</code> 只将梯度传播给某一个最大值</li>
</ul>
</blockquote>
<h3 id="angle">angle()<a class="headerlink" href="#angle" title="Permanent link">&para;</a></h3>
<p>对复张量的所有元素计算角度（以弧度为单位）。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">3</span><span class="n">j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">angle</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.7854</span><span class="p">,</span>  <span class="mf">2.3562</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7854</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">angle</span><span class="p">()</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">45.</span><span class="p">,</span> <span class="mf">135.</span><span class="p">,</span> <span class="o">-</span><span class="mf">45.</span><span class="p">])</span>
</code></pre></div>
<h3 id="argmax-argmin">argmax(), argmin()<a class="headerlink" href="#argmax-argmin" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定维度的最大值/最小值的索引。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.6751</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7609</span><span class="p">,</span>  <span class="mf">0.8919</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0545</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.3398</span><span class="p">,</span>  <span class="mf">0.2663</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2686</span><span class="p">,</span>  <span class="mf">0.2450</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7401</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8805</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3402</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1936</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4907</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3948</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0691</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3132</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.6092</span><span class="p">,</span>  <span class="mf">0.5419</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2993</span><span class="p">,</span>  <span class="mf">0.3195</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>        <span class="c1"># 沿轴1的最大值的索引</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<h3 id="argsort">argsort()<a class="headerlink" href="#argsort" title="Permanent link">&para;</a></h3>
<p>返回对张量沿指定维度的元素进行排序的索引序列。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0785</span><span class="p">,</span>  <span class="mf">1.5267</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8521</span><span class="p">,</span>  <span class="mf">0.4065</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1598</span><span class="p">,</span>  <span class="mf">0.0788</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0745</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2700</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.2208</span><span class="p">,</span>  <span class="mf">1.0722</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7064</span><span class="p">,</span>  <span class="mf">1.2564</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0669</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2318</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8229</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9280</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>       <span class="c1"># 升序排序</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>      <span class="c1"># 错误的排序结果:`argsort()`经常返回错误的排序结果,建议使用`sort()`函数</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>      
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>            <span class="c1"># 没有指定维度时,默认为最后一个维度</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 降序排序</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
</code></pre></div>
<h3 id="bincount">bincount()<a class="headerlink" href="#bincount" title="Permanent link">&para;</a></h3>
<p>计数非负整数张量的各个元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bincount</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>                        <span class="c1"># 0,1,2,3的出现次数</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.5000</span><span class="p">,</span> <span class="mf">0.1000</span><span class="p">,</span> <span class="mf">2.4000</span><span class="p">,</span> <span class="mf">0.5000</span><span class="p">])</span>    <span class="c1"># 0,1,2,3的合计权重</span>
</code></pre></div>
<h3 id="bmm">bmm()<a class="headerlink" href="#bmm" title="Permanent link">&para;</a></h3>
<p>批量矩阵乘法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>     <span class="c1"># 相同索引的矩阵对应相乘</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</code></pre></div>
<h3 id="ceil-floor">ceil(), floor()<a class="headerlink" href="#ceil-floor" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用向上/向下取整函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.6341</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4208</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0900</span><span class="p">,</span>  <span class="mf">0.5826</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">ceil</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">floor</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">])</span>
</code></pre></div>
<h3 id="clamp">clamp()<a class="headerlink" href="#clamp" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用下限和上限。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.7120</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0299</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3184</span><span class="p">,</span>  <span class="mf">2.1593</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8883</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>       <span class="c1"># ReLU激活函数</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">1.0605</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.5617</span><span class="p">])</span>
</code></pre></div>
<h3 id="conj">conj()<a class="headerlink" href="#conj" title="Permanent link">&para;</a></h3>
<p>对复张量的所有元素取共轭。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.7132</span><span class="o">-</span><span class="mf">0.7579</span><span class="n">j</span><span class="p">,</span>  <span class="mf">0.1200</span><span class="o">+</span><span class="mf">0.8570</span><span class="n">j</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2175</span><span class="o">+</span><span class="mf">0.3542</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4469</span><span class="o">+</span><span class="mf">0.0533</span><span class="n">j</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.7132</span><span class="o">+</span><span class="mf">0.7579</span><span class="n">j</span><span class="p">,</span>  <span class="mf">0.1200</span><span class="o">-</span><span class="mf">0.8570</span><span class="n">j</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2175</span><span class="o">-</span><span class="mf">0.3542</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4469</span><span class="o">-</span><span class="mf">0.0533</span><span class="n">j</span><span class="p">]])</span>
</code></pre></div>
<h3 id="count_nonzero">count_nonzero()<a class="headerlink" href="#count_nonzero" title="Permanent link">&para;</a></h3>
<p>计数张量沿指定轴的非零元素。若没有指定轴，则计数张量的所有非零元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># 沿轴0</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># 沿轴1</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">()</span>    <span class="c1"># 总数</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<h3 id="cross">cross()<a class="headerlink" href="#cross" title="Permanent link">&para;</a></h3>
<p>计算两个三维向量的向量积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.3956</span><span class="p">,</span>  <span class="mf">1.1455</span><span class="p">,</span>  <span class="mf">1.6895</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5849</span><span class="p">,</span>  <span class="mf">1.3672</span><span class="p">,</span>  <span class="mf">0.3599</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1626</span><span class="p">,</span>  <span class="mf">0.7180</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0521</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1339</span><span class="p">,</span>  <span class="mf">0.9902</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0225</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0257</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4725</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2251</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1479</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7005</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9757</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.3904</span><span class="p">,</span>  <span class="mf">0.3726</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1836</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9688</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7153</span><span class="p">,</span>  <span class="mf">0.2159</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>           <span class="c1"># 参与计算的两个张量的形状必须相同,且指定的维度的规模必须为3</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.0844</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5281</span><span class="p">,</span>  <span class="mf">0.6120</span><span class="p">],</span>   <span class="c1"># `dim=1`可以省略,默认为最后一个维度</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">2.4490</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5687</span><span class="p">,</span>  <span class="mf">1.9792</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.8304</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3037</span><span class="p">,</span>  <span class="mf">0.5650</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.2329</span><span class="p">,</span>  <span class="mf">1.9883</span><span class="p">,</span>  <span class="mf">1.0551</span><span class="p">]])</span>
</code></pre></div>
<h3 id="cummax-cummin">cummax(), cummin()<a class="headerlink" href="#cummax-cummin" title="Permanent link">&para;</a></h3>
<p>遍历张量并返回相同形状的张量，其中各个元素表示截至当前索引的最大值/最小值及其索引。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.4993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1668</span><span class="p">,</span>  <span class="mf">1.4890</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5074</span><span class="p">,</span>  <span class="mf">0.3864</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">cummax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">cummax</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.4993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1668</span><span class="p">,</span>  <span class="mf">1.4890</span><span class="p">,</span>  <span class="mf">1.4890</span><span class="p">,</span>  <span class="mf">1.4890</span><span class="p">]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">cummin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">cummin</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.4993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5074</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5074</span><span class="p">]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</code></pre></div>
<h3 id="cumsum-cumprod">cumsum(), cumprod()<a class="headerlink" href="#cumsum-cumprod" title="Permanent link">&para;</a></h3>
<p>遍历张量并返回相同形状的张量，其中各个元素表示截至当前索引的累积和/积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">6.</span><span class="p">,</span>  <span class="mf">24.</span><span class="p">,</span> <span class="mf">120.</span><span class="p">])</span>
</code></pre></div>
<h3 id="deg2rad-rad2deg">deg2rad(), rad2deg()<a class="headerlink" href="#deg2rad-rad2deg" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素从角度值/弧度值转换为弧度值/角度值。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">3</span><span class="n">j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">angle</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.7854</span><span class="p">,</span>  <span class="mf">2.3562</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7854</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">.</span><span class="n">angle</span><span class="p">()</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">45.</span><span class="p">,</span> <span class="mf">135.</span><span class="p">,</span> <span class="o">-</span><span class="mf">45.</span><span class="p">])</span>
</code></pre></div>
<h3 id="det">det()<a class="headerlink" href="#det" title="Permanent link">&para;</a></h3>
<p><code>torch.linalg.det()</code> 的别名。</p>
<h3 id="diag">diag()<a class="headerlink" href="#diag" title="Permanent link">&para;</a></h3>
<p>若张量为向量（一维张量），则返回以该向量的元素作为对角元素的矩阵（二维张量）；若张量为矩阵，则返回该矩阵的对角元素构成的向量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">])</span>
</code></pre></div>
<h3 id="diagonal">diagonal()<a class="headerlink" href="#diagonal" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定平面的对角线元素的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">1.2631</span><span class="p">,</span>  <span class="mf">0.3755</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5977</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8172</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">1.1065</span><span class="p">,</span>  <span class="mf">1.0401</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2235</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7938</span><span class="p">]],</span>

        <span class="p">[[</span><span class="o">-</span><span class="mf">1.7325</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3081</span><span class="p">,</span>  <span class="mf">0.6166</span><span class="p">,</span>  <span class="mf">0.2335</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.0500</span><span class="p">,</span>  <span class="mf">0.7336</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3836</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1015</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="diff">diff()<a class="headerlink" href="#diff" title="Permanent link">&para;</a></h3>
<p>计算张量沿指定维度的相邻元素之间的差，即有 <code>out[i] = input[i+1] - input[i]</code>。递归地调用此函数可以得到更高阶的差。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">16.</span><span class="p">,</span>  <span class="mf">32.</span><span class="p">,</span>  <span class="mf">64.</span><span class="p">,</span> <span class="mf">128.</span><span class="p">,</span> <span class="mf">256.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">16.</span><span class="p">,</span>  <span class="mf">32.</span><span class="p">,</span>  <span class="mf">64.</span><span class="p">,</span> <span class="mf">128.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">,</span> <span class="mf">32.</span><span class="p">,</span> <span class="mf">64.</span><span class="p">])</span>
</code></pre></div>
<h3 id="dist">dist()<a class="headerlink" href="#dist" title="Permanent link">&para;</a></h3>
<p>计算两个张量的差的 <span class="arithmatex">\(l_p\)</span> 范数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># l1范数</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>   <span class="c1"># l2范数</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">1.4142</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>   <span class="c1"># l∞范数</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
</code></pre></div>
<h3 id="dot">dot()<a class="headerlink" href="#dot" title="Permanent link">&para;</a></h3>
<p>计算两个向量（一维张量）的点积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</code></pre></div>
<h3 id="equal">equal()<a class="headerlink" href="#equal" title="Permanent link">&para;</a></h3>
<p>判断两个张量是否完全相等。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">one1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">one2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">one1</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">one2</span><span class="p">)</span>
<span class="kc">True</span>
</code></pre></div>
<h3 id="exp">exp()<a class="headerlink" href="#exp" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用自然指数函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0000e+00</span><span class="p">,</span> <span class="mf">2.7183e+00</span><span class="p">,</span> <span class="mf">7.3891e+00</span><span class="p">,</span> <span class="mf">2.0086e+01</span><span class="p">,</span> <span class="mf">5.4598e+01</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.4841e+02</span><span class="p">,</span> <span class="mf">4.0343e+02</span><span class="p">,</span> <span class="mf">1.0966e+03</span><span class="p">,</span> <span class="mf">2.9810e+03</span><span class="p">,</span> <span class="mf">8.1031e+03</span><span class="p">]])</span>
</code></pre></div>
<h3 id="fmax-fmin">fmax(), fmin()<a class="headerlink" href="#fmax-fmin" title="Permanent link">&para;</a></h3>
<p>张量逐元素比较并取较大值/较小值。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">9.7</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">),</span> <span class="mf">3.1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">fmax</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">9.7000</span><span class="p">,</span> <span class="mf">0.5000</span><span class="p">,</span> <span class="mf">3.1000</span><span class="p">,</span>    <span class="n">inf</span><span class="p">])</span>    <span class="c1"># `nan`不参与比较</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">fmin</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.2000</span><span class="p">,</span>  <span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">3.1000</span><span class="p">,</span>     <span class="n">inf</span><span class="p">])</span>
</code></pre></div>
<h3 id="frac">frac()<a class="headerlink" href="#frac" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素取小数部分。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">frac</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]))</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2000</span><span class="p">])</span>
</code></pre></div>
<h3 id="gcd-lcm">gcd(), lcm()<a class="headerlink" href="#gcd-lcm" title="Permanent link">&para;</a></h3>
<p>张量逐元素计算最大公约数/最小公倍数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">lcm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>              <span class="c1"># 扩张的逐元素计算</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">lcm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">]])</span>
</code></pre></div>
<h3 id="gt-ge-eq-le-lt-ne">gt(), ge(), eq(), le(), lt(), ne()<a class="headerlink" href="#gt-ge-eq-le-lt-ne" title="Permanent link">&para;</a></h3>
<p>张量逐元素比较。符号 <code>&gt;, &gt;=, ==, &lt;=, &lt;, !=</code> 重载了这些方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> 
<span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>   <span class="c1"># 相同形状的布尔类型张量</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&gt;=</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">==</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">!=</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>                <span class="c1"># 可作为张量索引</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">==</span> <span class="n">c</span>                       <span class="c1"># 扩张的逐元素比较</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">]])</span>
</code></pre></div>
<h3 id="hypot">hypot()<a class="headerlink" href="#hypot" title="Permanent link">&para;</a></h3>
<p>张量逐元素计算给定两直角边长的斜边长度，即 <span class="arithmatex">\(\sqrt{x^2+y^2}\)</span>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">hypot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>                   <span class="c1"># 扩张的逐元素计算</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">5.0000</span><span class="p">,</span> <span class="mf">5.6569</span><span class="p">,</span> <span class="mf">6.4031</span><span class="p">])</span>
</code></pre></div>
<h3 id="inner">inner()<a class="headerlink" href="#inner" title="Permanent link">&para;</a></h3>
<p>计算两个向量（一维张量）的内积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">14.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>          <span class="c1"># 高维张量作内积:最后一个维度的规模相等,用于计算内积;其余的维度进行组合</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.8173</span><span class="p">,</span> <span class="mf">1.0874</span><span class="p">,</span> <span class="mf">1.1784</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.3279</span><span class="p">,</span> <span class="mf">0.1234</span><span class="p">,</span> <span class="mf">2.7894</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.4682</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7159</span><span class="p">,</span>  <span class="mf">0.1506</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4034</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3657</span><span class="p">,</span>  <span class="mf">1.0387</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.9892</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6684</span><span class="p">,</span>  <span class="mf">0.1774</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.9482</span><span class="p">,</span>  <span class="mf">1.3261</span><span class="p">,</span>  <span class="mf">0.3917</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.4537</span><span class="p">,</span>  <span class="mf">0.7493</span><span class="p">,</span>  <span class="mf">1.1724</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2291</span><span class="p">,</span>  <span class="mf">0.5749</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2267</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.7920</span><span class="p">,</span>  <span class="mf">0.3607</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3701</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.3666</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5850</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7242</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.9837</span><span class="p">,</span>  <span class="mf">1.1560</span><span class="p">,</span>  <span class="mf">0.2907</span><span class="p">,</span>  <span class="mf">2.6785</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.5671</span><span class="p">,</span>  <span class="mf">0.5452</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6912</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5509</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.1782</span><span class="p">,</span>  <span class="mf">2.9843</span><span class="p">,</span>  <span class="mf">0.7366</span><span class="p">,</span>  <span class="mf">1.5672</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.5115</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4864</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2476</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.4337</span><span class="p">]]])</span>
</code></pre></div>
<h3 id="lerp">lerp()<a class="headerlink" href="#lerp" title="Permanent link">&para;</a></h3>
<p>张量逐元素线性插值。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">start</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.1000</span><span class="p">,</span> <span class="mf">0.2000</span><span class="p">,</span> <span class="mf">0.3000</span><span class="p">,</span> <span class="mf">0.4000</span><span class="p">,</span> <span class="mf">0.5000</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">start</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.5000</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.5000</span><span class="p">,</span> <span class="mf">2.0000</span><span class="p">,</span> <span class="mf">2.5000</span><span class="p">])</span>
</code></pre></div>
<h3 id="log-log10-log2">log(), log10(), log2()<a class="headerlink" href="#log-log10-log2" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用对数函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span>  <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.6931</span><span class="p">,</span> <span class="mf">1.0986</span><span class="p">,</span> <span class="mf">1.3863</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.6094</span><span class="p">,</span> <span class="mf">1.7918</span><span class="p">,</span> <span class="mf">1.9459</span><span class="p">,</span> <span class="mf">2.0794</span><span class="p">,</span> <span class="mf">2.1972</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">log2</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span>  <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.5850</span><span class="p">,</span> <span class="mf">2.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">2.3219</span><span class="p">,</span> <span class="mf">2.5850</span><span class="p">,</span> <span class="mf">2.8074</span><span class="p">,</span> <span class="mf">3.0000</span><span class="p">,</span> <span class="mf">3.1699</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span>  <span class="o">-</span><span class="n">inf</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.3010</span><span class="p">,</span> <span class="mf">0.4771</span><span class="p">,</span> <span class="mf">0.6021</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.6990</span><span class="p">,</span> <span class="mf">0.7782</span><span class="p">,</span> <span class="mf">0.8451</span><span class="p">,</span> <span class="mf">0.9031</span><span class="p">,</span> <span class="mf">0.9542</span><span class="p">]])</span>
</code></pre></div>
<h3 id="logaddexp-logaddexp2">logaddexp(), logaddexp2()<a class="headerlink" href="#logaddexp-logaddexp2" title="Permanent link">&para;</a></h3>
<p>张量逐元素计算指数的和的对数，即 <span class="arithmatex">\(\ln{(e^x+e^y)}\)</span> / <span class="arithmatex">\(\ln{(2^x+2^y)}\)</span>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.3133</span><span class="p">,</span> <span class="mf">2.1269</span><span class="p">,</span> <span class="mf">3.0486</span><span class="p">,</span> <span class="mf">4.0181</span><span class="p">,</span> <span class="mf">5.0067</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logaddexp2</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.5850</span><span class="p">,</span> <span class="mf">2.3219</span><span class="p">,</span> <span class="mf">3.1699</span><span class="p">,</span> <span class="mf">4.0875</span><span class="p">,</span> <span class="mf">5.0444</span><span class="p">])</span>
</code></pre></div>
<h3 id="logit">logit()<a class="headerlink" href="#logit" title="Permanent link">&para;</a></h3>
<p><code>torch.special.logit()</code> 的别名。</p>
<h3 id="logsumexp">logsumexp()<a class="headerlink" href="#logsumexp" title="Permanent link">&para;</a></h3>
<p>计算张量沿指定维度的所有元素的指数的和的对数，即 <span class="arithmatex">\(\ln \sum e^x\)</span>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">6.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.4076</span><span class="p">,</span> <span class="mf">5.4076</span><span class="p">])</span>
</code></pre></div>
<h3 id="lu">lu()<a class="headerlink" href="#lu" title="Permanent link">&para;</a></h3>
<p>计算矩阵的 LU 分解。</p>
<h3 id="matmul">matmul()<a class="headerlink" href="#matmul" title="Permanent link">&para;</a></h3>
<p>张量乘法。符号 <code>@</code> 重载了此方法。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 向量×向量: 内积</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">14</span><span class="p">)</span>

<span class="c1"># 矩阵×向量, 向量×矩阵, 矩阵×矩阵: 矩阵乘法</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>                 <span class="c1"># 向量会自动补全维度</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>                     <span class="c1"># 3x3 x 3(x1) = 3(x1)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">m1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">30</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">42</span><span class="p">])</span>                     <span class="c1"># (1x)3 x 3x3 = (1x)3</span>

<span class="c1"># 矩阵序列×向量: 扩张的矩阵乘法</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm1</span> <span class="o">=</span> <span class="n">m1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm1</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">bm1</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>                     <span class="c1"># [2x]3x3 x 3(x1) = [2x]3(x1)</span>
        <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">50</span><span class="p">]])</span>

<span class="c1"># 矩阵序列×矩阵: 扩张的矩阵乘法</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">bm1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>                    <span class="c1"># [2x]3x3 x 3x3 = [2x]3x3</span>
         <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">]]])</span>

<span class="c1"># 矩阵序列×矩阵序列: 逐元素的矩阵乘法</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm2</span> <span class="o">=</span> <span class="n">m2</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bm2</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">bm1</span><span class="p">,</span> <span class="n">bm2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">]]])</span>

<span class="c1"># 矩阵序列×向量序列: 逐元素的矩阵乘法不适用,会被识别为矩阵序列×矩阵</span>
<span class="c1"># 须将向量序列扩展为矩阵序列</span>
</code></pre></div>
<h3 id="max-min-mean-std-median">max(), min(), mean(), std(), median()<a class="headerlink" href="#max-min-mean-std-median" title="Permanent link">&para;</a></h3>
<p>返回张量元素的统计量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">9.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]),</span>  <span class="c1"># 沿轴0的最大值</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>      <span class="c1"># 沿轴0的索引</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.5000</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.5000</span><span class="p">,</span> <span class="mf">3.5000</span><span class="p">,</span> <span class="mf">4.5000</span><span class="p">,</span> <span class="mf">5.5000</span><span class="p">,</span> <span class="mf">6.5000</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">])</span>

<span class="c1"># 标准差的无偏估计</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">2.8723</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.5000</span><span class="p">,</span> <span class="mf">2.5000</span><span class="p">,</span> <span class="mf">2.5000</span><span class="p">,</span> <span class="mf">2.5000</span><span class="p">,</span> <span class="mf">2.5000</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.4142</span><span class="p">,</span> <span class="mf">1.4142</span><span class="p">])</span>

<span class="c1"># 标准差的有偏估计</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">3.0277</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.5355</span><span class="p">,</span> <span class="mf">3.5355</span><span class="p">,</span> <span class="mf">3.5355</span><span class="p">,</span> <span class="mf">3.5355</span><span class="p">,</span> <span class="mf">3.5355</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.5811</span><span class="p">,</span> <span class="mf">1.5811</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">4.</span><span class="p">)</span>          <span class="c1"># 返回两个中位数中较小的那一个</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">median</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">median</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
</code></pre></div>
<h3 id="mm">mm()<a class="headerlink" href="#mm" title="Permanent link">&para;</a></h3>
<p>矩阵乘法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">m2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.9749</span><span class="p">]])</span>
</code></pre></div>
<h3 id="mul-div-fmod-pow">mul(), div(), fmod(), pow()<a class="headerlink" href="#mul-div-fmod-pow" title="Permanent link">&para;</a></h3>
<p>张量逐元素乘法/除法（多种模式）/除法取余/乘方。符号 <code>*, /, //, %, **</code> 重载了这些方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">100</span>                       <span class="c1"># 张量*标量: 张量的数乘</span>
<span class="n">tensor</span><span class="p">([[</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">700</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">900</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>           <span class="c1"># 张量*子张量: 张量的扩张逐元素乘法</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">*</span> <span class="n">a</span>                         <span class="c1"># 张量*张量: 张量的逐元素乘法</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">81</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.5000</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.5000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">/</span> <span class="mi">2</span>        <span class="c1"># `/` 重载了上述方法</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.5000</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.5000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="s1">&#39;trunc&#39;</span><span class="p">)</span>   <span class="c1"># 向0舍入</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">//</span> <span class="mi">2</span>       <span class="c1"># `//` 重载了上述方法    </span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="s1">&#39;floor&#39;</span><span class="p">)</span>   <span class="c1"># 向下舍入</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">]])</span>
</code></pre></div>
<h3 id="neg">neg()<a class="headerlink" href="#neg" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素取相反数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.1498</span><span class="p">,</span>  <span class="mf">1.7276</span><span class="p">,</span>  <span class="mf">0.8081</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0058</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1498</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7276</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8081</span><span class="p">,</span>  <span class="mf">0.0058</span><span class="p">])</span>
</code></pre></div>
<h3 id="outer">outer()<a class="headerlink" href="#outer" title="Permanent link">&para;</a></h3>
<p>计算两个向量（一维张量）的外积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span>  <span class="c1"># 4维向量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>  <span class="c1"># 3维向量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>      <span class="c1"># 4×3矩阵</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">]])</span>
</code></pre></div>
<h3 id="quantile">quantile()<a class="headerlink" href="#quantile" title="Permanent link">&para;</a></h3>
<p>计算张量沿指定维度的分位数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">5.</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mf">0.4000</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.4000</span><span class="p">]],</span>   <span class="c1"># 1.4 = (2 - 1) / 0.25 * 0.1 + 1</span>
        <span class="p">[[</span> <span class="mf">1.0000</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.0000</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">2.0000</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">4.0000</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">3.0000</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">8.0000</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">3.6000</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">12.8000</span><span class="p">]]])</span>  <span class="c1"># 12.8 = (16 - 8) / 0.25 * 0.15 + 8</span>
</code></pre></div>
<h3 id="real-imag">real(), imag()<a class="headerlink" href="#real-imag" title="Permanent link">&para;</a></h3>
<p>返回复张量元素的实部/虚部，是原张量的一个视图。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0739</span><span class="o">-</span><span class="mf">0.1096</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1704</span><span class="o">+</span><span class="mf">0.5449</span><span class="n">j</span><span class="p">,</span>  <span class="mf">1.4357</span><span class="o">+</span><span class="mf">0.1676</span><span class="n">j</span><span class="p">,</span>  <span class="mf">0.3414</span><span class="o">+</span><span class="mf">0.3973</span><span class="n">j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0739</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1704</span><span class="p">,</span>  <span class="mf">1.4357</span><span class="p">,</span>  <span class="mf">0.3414</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">real</span>            <span class="c1"># 注意`real`是属性而非方法</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0739</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1704</span><span class="p">,</span>  <span class="mf">1.4357</span><span class="p">,</span>  <span class="mf">0.3414</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1096</span><span class="p">,</span>  <span class="mf">0.5449</span><span class="p">,</span>  <span class="mf">0.1676</span><span class="p">,</span>  <span class="mf">0.3973</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">imag</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1096</span><span class="p">,</span>  <span class="mf">0.5449</span><span class="p">,</span>  <span class="mf">0.1676</span><span class="p">,</span>  <span class="mf">0.3973</span><span class="p">])</span>
</code></pre></div>
<h3 id="reciprocal">reciprocal()<a class="headerlink" href="#reciprocal" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素求倒数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">1.0000</span><span class="p">,</span> <span class="mf">0.5000</span><span class="p">,</span> <span class="mf">0.3333</span><span class="p">,</span> <span class="mf">0.2500</span><span class="p">,</span> <span class="mf">0.2000</span><span class="p">])</span>
</code></pre></div>
<h3 id="round">round()<a class="headerlink" href="#round" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素舍入到最接近的整数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.9920</span><span class="p">,</span>  <span class="mf">0.6077</span><span class="p">,</span>  <span class="mf">0.9734</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0362</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">])</span>
</code></pre></div>
<h3 id="sigmoid">sigmoid()<a class="headerlink" href="#sigmoid" title="Permanent link">&para;</a></h3>
<p><code>torch.special.expit()</code> 的别名。</p>
<h3 id="sign">sign()<a class="headerlink" href="#sign" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用符号函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.8365</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8114</span><span class="p">,</span>  <span class="mf">0.6972</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8606</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">])</span>
</code></pre></div>
<h3 id="sin-cos-tan-arcsin-arccos-arctan-sinh-cosh-tanh-arcsinh-arccosh-arctanh">sin(), cos(), tan(), arcsin(), arccos(), arctan(), sinh(), cosh(), tanh(), arcsinh(), arccosh(), arctanh()<a class="headerlink" href="#sin-cos-tan-arcsin-arccos-arctan-sinh-cosh-tanh-arcsinh-arccosh-arctanh" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用三角函数和双曲函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">sin</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.8415</span><span class="p">,</span>  <span class="mf">0.9093</span><span class="p">,</span>  <span class="mf">0.1411</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7568</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9589</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2794</span><span class="p">,</span>  <span class="mf">0.6570</span><span class="p">,</span>  <span class="mf">0.9894</span><span class="p">,</span>  <span class="mf">0.4121</span><span class="p">]])</span>
</code></pre></div>
<h3 id="sort">sort()<a class="headerlink" href="#sort" title="Permanent link">&para;</a></h3>
<p>对张量沿指定维度的元素进行排序。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.3513</span><span class="p">,</span>  <span class="mf">0.5400</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6180</span><span class="p">,</span>  <span class="mf">1.4433</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2388</span><span class="p">,</span>  <span class="mf">1.8336</span><span class="p">,</span>  <span class="mf">0.9740</span><span class="p">,</span>  <span class="mf">0.1217</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.5126</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1115</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6911</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1602</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.1018</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2049</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7836</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1134</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">sorted</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">sorted</span>                <span class="c1"># 排序结果</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.3513</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6180</span><span class="p">,</span>  <span class="mf">0.5400</span><span class="p">,</span>  <span class="mf">1.4433</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.1217</span><span class="p">,</span>  <span class="mf">0.2388</span><span class="p">,</span>  <span class="mf">0.9740</span><span class="p">,</span>  <span class="mf">1.8336</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1115</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6911</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1602</span><span class="p">,</span>  <span class="mf">0.5126</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.1134</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7836</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2049</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1018</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">indices</span>               <span class="c1"># 排序索引</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div>
<h3 id="sqrt">sqrt()<a class="headerlink" href="#sqrt" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用平方根函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0755</span><span class="p">,</span>  <span class="mf">1.0226</span><span class="p">,</span>  <span class="mf">0.0831</span><span class="p">,</span>  <span class="mf">0.4806</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span>    <span class="n">nan</span><span class="p">,</span>  <span class="mf">1.0112</span><span class="p">,</span>  <span class="mf">0.2883</span><span class="p">,</span>  <span class="mf">0.6933</span><span class="p">])</span>
</code></pre></div>
<h3 id="square">square()<a class="headerlink" href="#square" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素应用平方函数，相当于 <code>** 2</code>。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.8848</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7775</span><span class="p">,</span>  <span class="mf">0.4125</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0188</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.7829</span><span class="p">,</span> <span class="mf">3.1595</span><span class="p">,</span> <span class="mf">0.1702</span><span class="p">,</span> <span class="mf">1.0380</span><span class="p">])</span>
</code></pre></div>
<h3 id="sum-prod">sum(), prod()<a class="headerlink" href="#sum-prod" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素求和/求积。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">120</span><span class="p">)</span>
</code></pre></div>
<h3 id="tanh">tanh()<a class="headerlink" href="#tanh" title="Permanent link">&para;</a></h3>
<p>tanh 激活函数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.2798</span><span class="p">,</span>  <span class="mf">2.2348</span><span class="p">,</span>  <span class="mf">0.2324</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9393</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.8564</span><span class="p">,</span>  <span class="mf">0.9774</span><span class="p">,</span>  <span class="mf">0.2283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9595</span><span class="p">])</span>
</code></pre></div>
<h3 id="topk">topk()<a class="headerlink" href="#topk" title="Permanent link">&para;</a></h3>
<p>返回张量沿指定维度的最大的 k 个元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.4138</span><span class="p">,</span>  <span class="mf">1.9770</span><span class="p">,</span>  <span class="mf">0.3198</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4088</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.5680</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2792</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9428</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3237</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0978</span><span class="p">,</span>  <span class="mf">0.8644</span><span class="p">,</span>  <span class="mf">0.2796</span><span class="p">,</span>  <span class="mf">0.3417</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0615</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4025</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3944</span><span class="p">,</span>  <span class="mf">1.5785</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># 沿轴1的最大2个元素</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.9770</span><span class="p">,</span>  <span class="mf">0.4138</span><span class="p">],</span>
               <span class="p">[</span><span class="o">-</span><span class="mf">0.2792</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5680</span><span class="p">],</span>
               <span class="p">[</span> <span class="mf">0.8644</span><span class="p">,</span>  <span class="mf">0.3417</span><span class="p">],</span>
               <span class="p">[</span> <span class="mf">1.5785</span><span class="p">,</span>  <span class="mf">0.0615</span><span class="p">]]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>    <span class="c1"># 沿轴1的最小2个元素</span>
<span class="n">torch</span><span class="o">.</span><span class="n">return_types</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
<span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.4088</span><span class="p">,</span>  <span class="mf">0.3198</span><span class="p">],</span>
               <span class="p">[</span><span class="o">-</span><span class="mf">2.3237</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9428</span><span class="p">],</span>
               <span class="p">[</span><span class="o">-</span><span class="mf">1.0978</span><span class="p">,</span>  <span class="mf">0.2796</span><span class="p">],</span>
               <span class="p">[</span><span class="o">-</span><span class="mf">0.4025</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3944</span><span class="p">]]),</span>
<span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
</code></pre></div>
<h3 id="trace">trace()<a class="headerlink" href="#trace" title="Permanent link">&para;</a></h3>
<p>返回二维张量的对角线元素的和。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">15.</span><span class="p">)</span>
</code></pre></div>
<h3 id="tril">tril()<a class="headerlink" href="#tril" title="Permanent link">&para;</a></h3>
<p>返回二维张量的下三角部分，其余元素被设为 0。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0813</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8619</span><span class="p">,</span>  <span class="mf">0.7105</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0935</span><span class="p">,</span>  <span class="mf">0.1380</span><span class="p">,</span>  <span class="mf">2.2112</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.3409</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9828</span><span class="p">,</span>  <span class="mf">0.0289</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0813</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0935</span><span class="p">,</span>  <span class="mf">0.1380</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.3409</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9828</span><span class="p">,</span>  <span class="mf">0.0289</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.2219</span><span class="p">,</span>  <span class="mf">0.5653</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2521</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2345</span><span class="p">,</span>  <span class="mf">1.2544</span><span class="p">,</span>  <span class="mf">0.3461</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4785</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4477</span><span class="p">,</span>  <span class="mf">0.6049</span><span class="p">,</span>  <span class="mf">0.6368</span><span class="p">,</span>  <span class="mf">0.8775</span><span class="p">,</span>  <span class="mf">0.7145</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.1502</span><span class="p">,</span>  <span class="mf">3.2716</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1243</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5413</span><span class="p">,</span>  <span class="mf">0.3615</span><span class="p">,</span>  <span class="mf">0.6864</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0614</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7344</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3164</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7648</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4024</span><span class="p">,</span>  <span class="mf">0.0978</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.2219</span><span class="p">,</span>  <span class="mf">0.5653</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4785</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4477</span><span class="p">,</span>  <span class="mf">0.6049</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.1502</span><span class="p">,</span>  <span class="mf">3.2716</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1243</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5413</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0614</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7344</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3164</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7648</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4024</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4785</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.1502</span><span class="p">,</span>  <span class="mf">3.2716</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0614</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7344</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3164</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]])</span>
</code></pre></div>
<h3 id="triu">triu()<a class="headerlink" href="#triu" title="Permanent link">&para;</a></h3>
<p>返回二维张量的上三角部分，其余元素被设为 0。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.2309</span><span class="p">,</span>  <span class="mf">0.5207</span><span class="p">,</span>  <span class="mf">2.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2072</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0680</span><span class="p">,</span>  <span class="mf">0.6602</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3480</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5211</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4573</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.2309</span><span class="p">,</span>  <span class="mf">0.5207</span><span class="p">,</span>  <span class="mf">2.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0680</span><span class="p">,</span>  <span class="mf">0.6602</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4573</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.5207</span><span class="p">,</span>  <span class="mf">2.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.6602</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.2309</span><span class="p">,</span>  <span class="mf">0.5207</span><span class="p">,</span>  <span class="mf">2.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.2072</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0680</span><span class="p">,</span>  <span class="mf">0.6602</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5211</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4573</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.5876</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0794</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8373</span><span class="p">,</span>  <span class="mf">0.6654</span><span class="p">,</span>  <span class="mf">0.2604</span><span class="p">,</span>  <span class="mf">1.5235</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2447</span><span class="p">,</span>  <span class="mf">0.9556</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2919</span><span class="p">,</span>  <span class="mf">1.3378</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1768</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0857</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4333</span><span class="p">,</span>  <span class="mf">0.3146</span><span class="p">,</span>  <span class="mf">0.6576</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0432</span><span class="p">,</span>  <span class="mf">0.9348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4410</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.9888</span><span class="p">,</span>  <span class="mf">1.0679</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3337</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6556</span><span class="p">,</span>  <span class="mf">0.4798</span><span class="p">,</span>  <span class="mf">0.2830</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0794</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8373</span><span class="p">,</span>  <span class="mf">0.6654</span><span class="p">,</span>  <span class="mf">0.2604</span><span class="p">,</span>  <span class="mf">1.5235</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2919</span><span class="p">,</span>  <span class="mf">1.3378</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1768</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0857</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0432</span><span class="p">,</span>  <span class="mf">0.9348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4410</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.4798</span><span class="p">,</span>  <span class="mf">0.2830</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.5876</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0794</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8373</span><span class="p">,</span>  <span class="mf">0.6654</span><span class="p">,</span>  <span class="mf">0.2604</span><span class="p">,</span>  <span class="mf">1.5235</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.2447</span><span class="p">,</span>  <span class="mf">0.9556</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2919</span><span class="p">,</span>  <span class="mf">1.3378</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1768</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0857</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.3146</span><span class="p">,</span>  <span class="mf">0.6576</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0432</span><span class="p">,</span>  <span class="mf">0.9348</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4410</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3337</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6556</span><span class="p">,</span>  <span class="mf">0.4798</span><span class="p">,</span>  <span class="mf">0.2830</span><span class="p">]])</span>
</code></pre></div>
<h3 id="trunc">trunc()<a class="headerlink" href="#trunc" title="Permanent link">&para;</a></h3>
<p>对张量的所有元素截断为整数（即向零取整）。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">3.4742</span><span class="p">,</span>  <span class="mf">0.5466</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8008</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9079</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">trunc</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.</span><span class="p">])</span>
</code></pre></div>
<h3 id="vdot">vdot()<a class="headerlink" href="#vdot" title="Permanent link">&para;</a></h3>
<p>计算两个向量（一维张量）的点积。<code>vdot()</code> 和 <code>dot()</code> 的区别在于，计算复向量的点积时，前者会对第一个参数取共轭，而后者不会。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">z1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span><span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">1</span><span class="n">j</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">2</span> <span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">4</span> <span class="o">-</span> <span class="mi">0</span><span class="n">j</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z1</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">16.</span><span class="o">+</span><span class="mf">1.</span><span class="n">j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z2</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">16.</span><span class="o">-</span><span class="mf">1.</span><span class="n">j</span><span class="p">])</span>
</code></pre></div>
<h2 id="逻辑运算">逻辑运算<a class="headerlink" href="#逻辑运算" title="Permanent link">&para;</a></h2>
<h3 id="bitwise_and-bitwise_or-bitwise_xor-bitwise_not">bitwise_and(), bitwise_or(), bitwise_xor(), bitwise_not()<a class="headerlink" href="#bitwise_and-bitwise_or-bitwise_xor-bitwise_not" title="Permanent link">&para;</a></h3>
<p>张量逐元素求按位与/或/异或/非，符号 <code>&amp;, |, ^, ~</code> 重载了这些方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
                    <span class="c1"># 11111111 11111110 00000011 </span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
                    <span class="c1"># 00000001 00000000 00000011</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_and</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># 与</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
      <span class="c1"># 00000001 00000000 00000011</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&amp;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>    <span class="c1"># 或</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
      <span class="c1"># 11111111 11111110 00000011</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">|</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># 异或</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
      <span class="c1"># 11111110 11111110 00000000</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">^</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_not</span><span class="p">()</span>    <span class="c1"># 非</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
      <span class="c1"># 00000000 00000001 11111100</span>
<span class="o">&gt;&gt;&gt;</span> <span class="o">~</span><span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
</code></pre></div>
<h3 id="isin">isin()<a class="headerlink" href="#isin" title="Permanent link">&para;</a></h3>
<p>检查张量中的每个元素是否也是另一张量的元素。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
</code></pre></div>
<h3 id="logical_and-logical_or-logical_xor-logical_not">logical_and(), logical_or(), logical_xor(), logical_not()<a class="headerlink" href="#logical_and-logical_or-logical_xor-logical_not" title="Permanent link">&para;</a></h3>
<p>张量逐元素求逻辑与/或/异或/非，符号 <code>&amp;, |, ^, ~</code> 重载了这些方法。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># 与</span>
<span class="n">tensor</span><span class="p">([</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">&amp;</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>    <span class="c1"># 或</span>
<span class="n">tensor</span><span class="p">([</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">|</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># 异或</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">^</span> <span class="n">b</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">logical_not</span><span class="p">()</span>    <span class="c1"># 非</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="o">~</span><span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">])</span>
</code></pre></div>
<h2 id="其他运算">其他运算<a class="headerlink" href="#其他运算" title="Permanent link">&para;</a></h2>
<h3 id="numel">numel()<a class="headerlink" href="#numel" title="Permanent link">&para;</a></h3>
<p>返回张量的元素数量。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="mi">120</span>
</code></pre></div>
<h3 id="unique">unique()<a class="headerlink" href="#unique" title="Permanent link">&para;</a></h3>
<p>返回张量的所有不重复的元素。</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># input            输入张量</span>
<span class="c1"># sorted           若为`True`,对所有不重复元素在返回前排升序</span>
<span class="c1"># return_inverse   若为`True`,返回每个元素在返回的不重复元素列表中的索引</span>
<span class="c1"># return_counts    若为`True`,返回每个不重复元素的计数</span>
<span class="c1"># dim              沿指定轴执行操作.若为`None`,则展开输入张量           </span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 张量的每个元素对应于返回的不重复元素列表的索引</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>     <span class="c1"># 张量的每个不重复元素的计数</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</code></pre></div>
<h2 id="随机数和随机抽样">随机数和随机抽样<a class="headerlink" href="#随机数和随机抽样" title="Permanent link">&para;</a></h2>
<h3 id="bernoulli">bernoulli()<a class="headerlink" href="#bernoulli" title="Permanent link">&para;</a></h3>
<p>将张量的元素视作概率，进行伯努利分布的一次抽样，并返回抽样结果（0 或 1）。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1796</span><span class="p">,</span> <span class="mf">0.1190</span><span class="p">,</span> <span class="mf">0.2294</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.4665</span><span class="p">,</span> <span class="mf">0.5306</span><span class="p">,</span> <span class="mf">0.0851</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.8514</span><span class="p">,</span> <span class="mf">0.3005</span><span class="p">,</span> <span class="mf">0.1239</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">()</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
</code></pre></div>
<h3 id="get_rng_state">get_rng_state()<a class="headerlink" href="#get_rng_state" title="Permanent link">&para;</a></h3>
<p>返回随机数生成器的状态为一个 <code>torch.ByteTensor</code> 实例。</p>
<h3 id="initial_seed">initial_seed()<a class="headerlink" href="#initial_seed" title="Permanent link">&para;</a></h3>
<p>返回生成随机数的初始种子。</p>
<h3 id="manual_seed">manual_seed()<a class="headerlink" href="#manual_seed" title="Permanent link">&para;</a></h3>
<p>设置生成随机数的种子。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Generator</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x106d3f710</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.7576</span><span class="p">,</span> <span class="mf">0.2793</span><span class="p">,</span> <span class="mf">0.4031</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.7347</span><span class="p">,</span> <span class="mf">0.0293</span><span class="p">,</span> <span class="mf">0.7999</span><span class="p">]])</span>
</code></pre></div>
<h3 id="multinomial">multinomial()<a class="headerlink" href="#multinomial" title="Permanent link">&para;</a></h3>
<p>将张量沿指定维度的元素视作权重，进行有放回或无放回的抽样，并返回抽样结果（索引）的序列。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>       <span class="c1"># 5个元素,被抽取的权重分别为1,1,0,2,1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>          <span class="c1"># 无放回的抽样</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 有放回的抽样</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<h3 id="normal">normal()<a class="headerlink" href="#normal" title="Permanent link">&para;</a></h3>
<p>返回指定形状的随机张量，其中每个元素服从正态分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>             <span class="c1"># 固定的平均值和标准差</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0451</span><span class="p">,</span>  <span class="mf">0.0395</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.5004</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3418</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">))</span>   <span class="c1"># 提供标准差张量,将分别以各个元素作为标准差</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.8626</span><span class="p">,</span>  <span class="mf">2.1291</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2584</span><span class="p">,</span>  <span class="mf">0.5077</span><span class="p">,</span>  <span class="mf">6.8753</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 提供平均值张量,将分别以各个元素作为平均值</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.8550</span><span class="p">,</span> <span class="mf">2.7790</span><span class="p">,</span> <span class="mf">1.9345</span><span class="p">,</span> <span class="mf">5.2598</span><span class="p">,</span> <span class="mf">4.7489</span><span class="p">,</span> <span class="mf">5.6595</span><span class="p">,</span> <span class="mf">6.2162</span><span class="p">,</span> <span class="mf">7.6686</span><span class="p">,</span> <span class="mf">8.3726</span><span class="p">,</span>
        <span class="mf">9.6793</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>  <span class="c1"># 提供平均值和标准差张量,将分别以对应元素作为</span>
                                                                   <span class="c1"># 平均值和标准差</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">0.5446</span><span class="p">,</span>  <span class="mf">1.4169</span><span class="p">,</span>  <span class="mf">3.4642</span><span class="p">,</span>  <span class="mf">4.0688</span><span class="p">,</span>  <span class="mf">3.6801</span><span class="p">,</span>  <span class="mf">5.6200</span><span class="p">,</span>  <span class="mf">7.5751</span><span class="p">,</span>  <span class="mf">8.2085</span><span class="p">,</span>
         <span class="mf">8.6058</span><span class="p">,</span> <span class="mf">12.3369</span><span class="p">])</span>
</code></pre></div>
<h3 id="poisson">poisson()<a class="headerlink" href="#poisson" title="Permanent link">&para;</a></h3>
<p>将张量的元素视作参数，进行泊松分布的一次抽样，并返回抽样结果。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.9541</span><span class="p">,</span> <span class="mf">0.7653</span><span class="p">,</span> <span class="mf">7.3616</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">6.0528</span><span class="p">,</span> <span class="mf">4.8620</span><span class="p">,</span> <span class="mf">2.5844</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">2.4320</span><span class="p">,</span> <span class="mf">1.0934</span><span class="p">,</span> <span class="mf">0.3956</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">8.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
</code></pre></div>
<h3 id="rand">rand()<a class="headerlink" href="#rand" title="Permanent link">&para;</a></h3>
<p>返回指定形状的随机张量，其中每个元素服从 <span class="arithmatex">\((0, 1)\)</span> 区间的均匀分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.8237</span><span class="p">,</span>  <span class="mf">0.5781</span><span class="p">,</span>  <span class="mf">0.6879</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.3816</span><span class="p">,</span>  <span class="mf">0.7249</span><span class="p">,</span>  <span class="mf">0.0998</span><span class="p">]])</span>
</code></pre></div>
<h3 id="randint">randint()<a class="headerlink" href="#randint" title="Permanent link">&para;</a></h3>
<p>返回指定形状的随机张量，其中每个元素等可能地取到 <span class="arithmatex">\([{\rm low}, {\rm high})\)</span> 区间内的各个整数。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
</code></pre></div>
<h3 id="randn">randn()<a class="headerlink" href="#randn" title="Permanent link">&para;</a></h3>
<p>返回指定形状的随机张量，其中每个元素服从标准正态分布。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.5954</span><span class="p">,</span>  <span class="mf">2.8929</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0923</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.1719</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4709</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1996</span><span class="p">]])</span>
</code></pre></div>
<h3 id="randperm">randperm()<a class="headerlink" href="#randperm" title="Permanent link">&para;</a></h3>
<p>返回整数 <code>0</code> 到 <code>n-1</code> 的一个随机排列。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
</code></pre></div>
<h3 id="seed">seed()<a class="headerlink" href="#seed" title="Permanent link">&para;</a></h3>
<p>设置生成随机数的种子为一个不确定的随机数。</p>
<h3 id="set_rng_state">set_rng_state()<a class="headerlink" href="#set_rng_state" title="Permanent link">&para;</a></h3>
<p>设置随机数生成器的状态。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0290</span><span class="p">,</span> <span class="mf">0.4019</span><span class="p">,</span> <span class="mf">0.2598</span><span class="p">,</span> <span class="mf">0.3666</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0583</span><span class="p">,</span> <span class="mf">0.7006</span><span class="p">,</span> <span class="mf">0.0518</span><span class="p">,</span> <span class="mf">0.4681</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0290</span><span class="p">,</span> <span class="mf">0.4019</span><span class="p">,</span> <span class="mf">0.2598</span><span class="p">,</span> <span class="mf">0.3666</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.0583</span><span class="p">,</span> <span class="mf">0.7006</span><span class="p">,</span> <span class="mf">0.0518</span><span class="p">,</span> <span class="mf">0.4681</span><span class="p">])</span>
</code></pre></div>
<h2 id="禁用梯度计算">禁用梯度计算<a class="headerlink" href="#禁用梯度计算" title="Permanent link">&para;</a></h2>
<p>参见<a href="api-autograd.html#局部禁用梯度计算">局部禁用梯度计算</a>。</p>
<h2 id="序列化">序列化<a class="headerlink" href="#序列化" title="Permanent link">&para;</a></h2>
<h3 id="save">save()<a class="headerlink" href="#save" title="Permanent link">&para;</a></h3>
<p>保存对象为文件。按照惯例，保存的文件使用 <code>.pt</code> 或 <code>.pth</code> 后缀名。</p>
<h3 id="load">load()<a class="headerlink" href="#load" title="Permanent link">&para;</a></h3>
<p>从文件中加载通过 <code>torch.save()</code> 保存的对象。</p>
<h3 id="保存和加载张量">保存和加载张量<a class="headerlink" href="#保存和加载张量" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>   <span class="c1"># 保存张量</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s1">&#39;tensor.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensor.pt&#39;</span><span class="p">)</span>          <span class="c1"># 加载张量</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<p><code>torch.save()</code> 和 <code>torch.load()</code> 默认使用 Python 的 pickle 进行序列化，因此你也可以将张量保存为 Python 实例（例如元组、列表、字典）的一部分：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]),</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;tensor_dict.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensor_dict.pt&#39;</span><span class="p">)</span>
<span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]),</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])}</span>
</code></pre></div>
<p>保存张量时张量的视图关系也被保留：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">subsequence</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">([</span><span class="n">sequence</span><span class="p">,</span> <span class="n">subsequence</span><span class="p">],</span> <span class="s1">&#39;tensors.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_sequence</span><span class="p">,</span> <span class="n">loaded_subsequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_subsequence</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_sequence</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span>  <span class="mi">9</span><span class="p">])</span>
</code></pre></div>
<p>实际上，不论视图如何，张量的存储对象都会完整地保存下来：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">large</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">small</span> <span class="o">=</span> <span class="n">large</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">small</span><span class="p">,</span> <span class="s1">&#39;small.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_small</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;small.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_small</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="mi">999</span>
</code></pre></div>
<h3 id="保存和加载-torchnnmodules">保存和加载 <code>torch.nn.Modules</code><a class="headerlink" href="#保存和加载-torchnnmodules" title="Permanent link">&para;</a></h3>
<p>另见：<a href="pytorch.html#保存和加载模型">保存和加载模型</a></p>
<p>在 PyTorch 中，模块的状态常使用“状态字典”进行序列化。模块的状态字典包含了其所有的参数和持久缓冲区：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">bn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
<span class="p">[(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
 <span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">list</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">())</span>
<span class="p">[(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])),</span>
 <span class="p">(</span><span class="s1">&#39;running_var&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])),</span>
 <span class="p">(</span><span class="s1">&#39;num_batches_tracked&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
<span class="n">OrderedDict</span><span class="p">([(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])),</span>
             <span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])),</span>
             <span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])),</span>
             <span class="p">(</span><span class="s1">&#39;running_var&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])),</span>
             <span class="p">(</span><span class="s1">&#39;num_batches_tracked&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))])</span>
</code></pre></div>
<p>出于兼容性的原因，推荐仅保存模块的状态字典而不是整个模块。模块的 <code>load_state_dict()</code> 方法用于从状态字典中还原状态：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;bn.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bn_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bn.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">new_bn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">new_bn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">bn_state_dict</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">All</span> <span class="n">keys</span> <span class="n">matched</span> <span class="n">successfully</span><span class="o">&gt;</span>
</code></pre></div>
<p>自定义模块或者包含其他模块的模块也有状态字典并且可以使用此方法进行保存和加载：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># A module with two linear layers</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
      <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">out0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l0</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">out0_relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">out0_relu</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
<span class="n">OrderedDict</span><span class="p">([(</span><span class="s1">&#39;l0.weight&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1400</span><span class="p">,</span> <span class="mf">0.4563</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0271</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4406</span><span class="p">],</span>
                                   <span class="p">[</span><span class="o">-</span><span class="mf">0.3289</span><span class="p">,</span> <span class="mf">0.2827</span><span class="p">,</span> <span class="mf">0.4588</span><span class="p">,</span> <span class="mf">0.2031</span><span class="p">]])),</span>
             <span class="p">(</span><span class="s1">&#39;l0.bias&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span> <span class="mf">0.0300</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1316</span><span class="p">])),</span>
             <span class="p">(</span><span class="s1">&#39;l1.weight&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([[</span><span class="mf">0.6533</span><span class="p">,</span> <span class="mf">0.3413</span><span class="p">]])),</span>
             <span class="p">(</span><span class="s1">&#39;l1.bias&#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1112</span><span class="p">]))])</span>
<span class="o">&gt;&gt;&gt;</span> 
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mymodule.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">m_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mymodule.pt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">new_m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">new_m</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">m_state_dict</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">All</span> <span class="n">keys</span> <span class="n">matched</span> <span class="n">successfully</span><span class="o">&gt;</span>
</code></pre></div>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    2023-12-11
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="../../../javascripts/tex-mml-chtml.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.cs/net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>